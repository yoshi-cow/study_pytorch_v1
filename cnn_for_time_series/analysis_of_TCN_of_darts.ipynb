{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMoOqHudtbYrmSU0IbbcfsT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a85b0d7995064bccb0b2fd8f5d050893":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7b0afdb1c56464f8ced26d04bf17164","IPY_MODEL_6fcea5613ccf4d00a53583a21ae1ab54","IPY_MODEL_3508a57a26d84e43ad9331d82b4b5f5a"],"layout":"IPY_MODEL_599ea2d5aa6246be852c858ebf956c86"}},"a7b0afdb1c56464f8ced26d04bf17164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83366902c10345fc8007962902704e30","placeholder":"​","style":"IPY_MODEL_f25aed20b6ea47ec882a861e0d29cf39","value":"Epoch 99: 100%"}},"6fcea5613ccf4d00a53583a21ae1ab54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23bbea8fa2e4b23b76d9763ca33285e","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c3a8d2f40bc4ceeb9648f78c891f717","value":3}},"3508a57a26d84e43ad9331d82b4b5f5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fd859e93cd0488ea9a993c7c47303d0","placeholder":"​","style":"IPY_MODEL_8a722b5b74f34fddbd2696230e97f473","value":" 3/3 [00:00&lt;00:00, 26.26it/s, train_loss=763.0]"}},"599ea2d5aa6246be852c858ebf956c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"83366902c10345fc8007962902704e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f25aed20b6ea47ec882a861e0d29cf39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e23bbea8fa2e4b23b76d9763ca33285e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c3a8d2f40bc4ceeb9648f78c891f717":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fd859e93cd0488ea9a993c7c47303d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a722b5b74f34fddbd2696230e97f473":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bff48165bddd4642ad454fe9cd062b61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d3c0d56603f49efaee30799bb873d4d","IPY_MODEL_fc0a721835fe434080ba1c77d4f7d156","IPY_MODEL_936b0f3cc9244283b1ff546c43f4b748"],"layout":"IPY_MODEL_60be8436c67d4164a61c7c1a308f0f00"}},"3d3c0d56603f49efaee30799bb873d4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_732c13424d46447d98e95e60e3aa281a","placeholder":"​","style":"IPY_MODEL_868ac47e4ac94edbb05f2adbd3a41143","value":"Predicting DataLoader 0: 100%"}},"fc0a721835fe434080ba1c77d4f7d156":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_443ace0ada534273ab4bffe41c7c829e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b6414b10d2f4cfeb8333d5deca5f041","value":1}},"936b0f3cc9244283b1ff546c43f4b748":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e97df36f32614efe91ae8526a5e3df1a","placeholder":"​","style":"IPY_MODEL_b80fd885362f4567826b421c16312f2d","value":" 1/1 [00:00&lt;00:00, 70.22it/s]"}},"60be8436c67d4164a61c7c1a308f0f00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"732c13424d46447d98e95e60e3aa281a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"868ac47e4ac94edbb05f2adbd3a41143":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"443ace0ada534273ab4bffe41c7c829e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b6414b10d2f4cfeb8333d5deca5f041":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e97df36f32614efe91ae8526a5e3df1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b80fd885362f4567826b421c16312f2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# analysis_of_TCN_of_darts\n","* Understanding the contents of TCN model of darts\n","\n","* https://unit8co.github.io/darts/generated_api/darts.models.forecasting.tcn_model.html\n","* https://unit8co.github.io/darts/_modules/darts/models/forecasting/tcn_model.html\n","\n","```python\n","class darts.models.forecasting.tcn_model.TCNModel(input_chunk_length, output_chunk_length,\n","    output_chunk_shift=0, kernel_size=3, num_filters=3, num_layers=None, dilation_base=2, weight_norm=False,\n","     dropout=0.2, **kwargs)\n","```"],"metadata":{"id":"omwOTas1a61E"}},{"cell_type":"markdown","source":["## original codes"],"metadata":{"id":"RnviYl5rd7NW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jO4pVhuaw-f"},"outputs":[],"source":["\"\"\"\n","Temporal Convolutional Network\n","------------------------------\n","\"\"\"\n","\n","import math\n","from typing import Optional, Sequence, Tuple\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from darts.logging import get_logger, raise_if_not\n","from darts.models.forecasting.pl_forecasting_module import (\n","    PLPastCovariatesModule,\n","    io_processor,\n",")\n","from darts.models.forecasting.torch_forecasting_model import PastCovariatesTorchModel\n","from darts.timeseries import TimeSeries\n","from darts.utils.data import PastCovariatesShiftedDataset\n","from darts.utils.torch import MonteCarloDropout\n","\n","logger = get_logger(__name__)\n","\n","\n","class _ResidualBlock(nn.Module):\n","    def __init__(\n","        self,\n","        num_filters: int,\n","        kernel_size: int,\n","        dilation_base: int,\n","        dropout: float,\n","        weight_norm: bool,\n","        nr_blocks_below: int,\n","        num_layers: int,\n","        input_size: int,\n","        target_size: int,\n","    ):\n","        \"\"\"PyTorch module implementing a residual block module used in `_TCNModule`.\n","\n","        Parameters\n","        ----------\n","        num_filters\n","            The number of filters in a convolutional layer of the TCN.\n","        kernel_size\n","            The size of every kernel in a convolutional layer.\n","        dilation_base\n","            The base of the exponent that will determine the dilation on every level.\n","        dropout\n","            The dropout to be applied to every convolutional layer.\n","        weight_norm\n","            Boolean value indicating whether to use weight normalization.\n","        nr_blocks_below\n","            The number of residual blocks before the current one.\n","        num_layers\n","            The number of convolutional layers.\n","        input_size\n","            The dimensionality of the input time series of the whole network.\n","        target_size\n","            The dimensionality of the output time series of the whole network.\n","\n","        Inputs\n","        ------\n","        x of shape `(batch_size, in_dimension, input_chunk_length)`\n","            Tensor containing the features of the input sequence.\n","            in_dimension is equal to `input_size` if this is the first residual block,\n","            in all other cases it is equal to `num_filters`.\n","\n","        Outputs\n","        -------\n","        y of shape `(batch_size, out_dimension, input_chunk_length)`\n","            Tensor containing the output sequence of the residual block.\n","            out_dimension is equal to `output_size` if this is the last residual block,\n","            in all other cases it is equal to `num_filters`.\n","        \"\"\"\n","        super().__init__()\n","\n","        self.dilation_base = dilation_base\n","        self.kernel_size = kernel_size\n","        self.dropout1 = MonteCarloDropout(dropout)\n","        self.dropout2 = MonteCarloDropout(dropout)\n","        self.num_layers = num_layers\n","        self.nr_blocks_below = nr_blocks_below\n","\n","        input_dim = input_size if nr_blocks_below == 0 else num_filters\n","        output_dim = target_size if nr_blocks_below == num_layers - 1 else num_filters\n","        self.conv1 = nn.Conv1d(\n","            input_dim,\n","            num_filters,\n","            kernel_size,\n","            dilation=(dilation_base**nr_blocks_below),\n","        )\n","        self.conv2 = nn.Conv1d(\n","            num_filters,\n","            output_dim,\n","            kernel_size,\n","            dilation=(dilation_base**nr_blocks_below),\n","        )\n","        if weight_norm:\n","            self.conv1, self.conv2 = (\n","                nn.utils.weight_norm(self.conv1),\n","                nn.utils.weight_norm(self.conv2),\n","            )\n","\n","        if input_dim != output_dim:\n","            self.conv3 = nn.Conv1d(input_dim, output_dim, 1)\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        # first step\n","        left_padding = (self.dilation_base**self.nr_blocks_below) * (\n","            self.kernel_size - 1\n","        )\n","        x = F.pad(x, (left_padding, 0))\n","        x = self.dropout1(F.relu(self.conv1(x)))\n","\n","        # second step\n","        x = F.pad(x, (left_padding, 0))\n","        x = self.conv2(x)\n","        if self.nr_blocks_below < self.num_layers - 1:\n","            x = F.relu(x)\n","        x = self.dropout2(x)\n","\n","        # add residual\n","        if self.conv1.in_channels != self.conv2.out_channels:\n","            residual = self.conv3(residual)\n","        x = x + residual\n","\n","        return x\n","\n","\n","class _TCNModule(PLPastCovariatesModule):\n","    def __init__(\n","        self,\n","        input_size: int,\n","        kernel_size: int,\n","        num_filters: int,\n","        num_layers: Optional[int],\n","        dilation_base: int,\n","        weight_norm: bool,\n","        target_size: int,\n","        nr_params: int,\n","        target_length: int,\n","        dropout: float,\n","        **kwargs,\n","    ):\n","        \"\"\"PyTorch module implementing a dilated TCN module used in `TCNModel`.\n","\n","\n","        Parameters\n","        ----------\n","        input_size\n","            The dimensionality of the input time series.\n","        target_size\n","            The dimensionality of the output time series.\n","        nr_params\n","            The number of parameters of the likelihood (or 1 if no likelihood is used).\n","        target_length\n","            Number of time steps the torch module will predict into the future at once.\n","        kernel_size\n","            The size of every kernel in a convolutional layer.\n","        num_filters\n","            The number of filters in a convolutional layer of the TCN.\n","        num_layers\n","            The number of convolutional layers.\n","        weight_norm\n","            Boolean value indicating whether to use weight normalization.\n","        dilation_base\n","            The base of the exponent that will determine the dilation on every level.\n","        dropout\n","            The dropout rate for every convolutional layer.\n","        **kwargs\n","            all parameters required for :class:`darts.models.forecasting.pl_forecasting_module.PLForecastingModule`\n","            base class.\n","\n","        Inputs\n","        ------\n","        x of shape `(batch_size, input_chunk_length, input_size)`\n","            Tensor containing the features of the input sequence.\n","\n","        Outputs\n","        -------\n","        y of shape `(batch_size, input_chunk_length, target_size, nr_params)`\n","            Tensor containing the predictions of the next 'output_chunk_length' points in the last\n","            'output_chunk_length' entries of the tensor. The entries before contain the data points\n","            leading up to the first prediction, all in chronological order.\n","        \"\"\"\n","\n","        super().__init__(**kwargs)\n","\n","        # Defining parameters\n","        self.input_size = input_size\n","        self.n_filters = num_filters\n","        self.kernel_size = kernel_size\n","        self.target_length = target_length\n","        self.target_size = target_size\n","        self.nr_params = nr_params\n","        self.dilation_base = dilation_base\n","\n","        # If num_layers is not passed, compute number of layers needed for full history coverage\n","        if num_layers is None and dilation_base > 1:\n","            num_layers = math.ceil(\n","                math.log(\n","                    (self.input_chunk_length - 1)\n","                    * (dilation_base - 1)\n","                    / (kernel_size - 1)\n","                    / 2\n","                    + 1,\n","                    dilation_base,\n","                )\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        elif num_layers is None:\n","            num_layers = math.ceil(\n","                (self.input_chunk_length - 1) / (kernel_size - 1) / 2\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        self.num_layers = num_layers\n","\n","        # Building TCN module\n","        self.res_blocks_list = []\n","        for i in range(num_layers):\n","            res_block = _ResidualBlock(\n","                num_filters=num_filters,\n","                kernel_size=kernel_size,\n","                dilation_base=dilation_base,\n","                dropout=dropout,\n","                weight_norm=weight_norm,\n","                nr_blocks_below=i,\n","                num_layers=num_layers,\n","                input_size=self.input_size,\n","                target_size=target_size * nr_params,\n","            )\n","            self.res_blocks_list.append(res_block)\n","        self.res_blocks = nn.ModuleList(self.res_blocks_list)\n","\n","    @io_processor\n","    def forward(self, x_in: Tuple):\n","        x, _ = x_in\n","        # data is of size (batch_size, input_chunk_length, input_size)\n","        batch_size = x.size(0)\n","        x = x.transpose(1, 2)\n","\n","        for res_block in self.res_blocks_list:\n","            x = res_block(x)\n","\n","        x = x.transpose(1, 2)\n","        x = x.view(\n","            batch_size, self.input_chunk_length, self.target_size, self.nr_params\n","        )\n","\n","        return x\n","\n","    @property\n","    def first_prediction_index(self) -> int:\n","        return -self.output_chunk_length\n","\n","\n","[docs]class TCNModel(PastCovariatesTorchModel):\n","    def __init__(\n","        self,\n","        input_chunk_length: int,\n","        output_chunk_length: int,\n","        output_chunk_shift: int = 0,\n","        kernel_size: int = 3,\n","        num_filters: int = 3,\n","        num_layers: Optional[int] = None,\n","        dilation_base: int = 2,\n","        weight_norm: bool = False,\n","        dropout: float = 0.2,\n","        **kwargs,\n","    ):\n","        \"\"\"Temporal Convolutional Network Model (TCN).\n","\n","        This is an implementation of a dilated TCN used for forecasting, inspired from [1]_.\n","\n","        This model supports past covariates (known for `input_chunk_length` points before prediction time).\n","\n","        Parameters\n","        ----------\n","        input_chunk_length\n","            Number of time steps in the past to take as a model input (per chunk). Applies to the target\n","            series, and past and/or future covariates (if the model supports it).\n","        output_chunk_length\n","            Number of time steps predicted at once (per chunk) by the internal model. Also, the number of future values\n","            from future covariates to use as a model input (if the model supports future covariates). It is not the same\n","            as forecast horizon `n` used in `predict()`, which is the desired number of prediction points generated\n","            using either a one-shot- or autoregressive forecast. Setting `n <= output_chunk_length` prevents\n","            auto-regression. This is useful when the covariates don't extend far enough into the future, or to prohibit\n","            the model from using future values of past and / or future covariates for prediction (depending on the\n","            model's covariate support).\n","        output_chunk_shift\n","            Optionally, the number of steps to shift the start of the output chunk into the future (relative to the\n","            input chunk end). This will create a gap between the input and output. If the model supports\n","            `future_covariates`, the future values are extracted from the shifted output chunk. Predictions will start\n","            `output_chunk_shift` steps after the end of the target `series`. If `output_chunk_shift` is set, the model\n","            cannot generate autoregressive predictions (`n > output_chunk_length`).\n","        kernel_size\n","            The size of every kernel in a convolutional layer.\n","        num_filters\n","            The number of filters in a convolutional layer of the TCN.\n","        weight_norm\n","            Boolean value indicating whether to use weight normalization.\n","        dilation_base\n","            The base of the exponent that will determine the dilation on every level.\n","        num_layers\n","            The number of convolutional layers.\n","        dropout\n","            The dropout rate for every convolutional layer. This is compatible with Monte Carlo dropout\n","            at inference time for model uncertainty estimation (enabled with ``mc_dropout=True`` at\n","            prediction time).\n","        **kwargs\n","            Optional arguments to initialize the pytorch_lightning.Module, pytorch_lightning.Trainer, and\n","            Darts' :class:`TorchForecastingModel`.\n","\n","        loss_fn\n","            PyTorch loss function used for training.\n","            This parameter will be ignored for probabilistic models if the ``likelihood`` parameter is specified.\n","            Default: ``torch.nn.MSELoss()``.\n","        likelihood\n","            One of Darts' :meth:`Likelihood <darts.utils.likelihood_models.Likelihood>` models to be used for\n","            probabilistic forecasts. Default: ``None``.\n","        torch_metrics\n","            A torch metric or a ``MetricCollection`` used for evaluation. A full list of available metrics can be found\n","            at https://torchmetrics.readthedocs.io/en/latest/. Default: ``None``.\n","        optimizer_cls\n","            The PyTorch optimizer class to be used. Default: ``torch.optim.Adam``.\n","        optimizer_kwargs\n","            Optionally, some keyword arguments for the PyTorch optimizer (e.g., ``{'lr': 1e-3}``\n","            for specifying a learning rate). Otherwise the default values of the selected ``optimizer_cls``\n","            will be used. Default: ``None``.\n","        lr_scheduler_cls\n","            Optionally, the PyTorch learning rate scheduler class to be used. Specifying ``None`` corresponds\n","            to using a constant learning rate. Default: ``None``.\n","        lr_scheduler_kwargs\n","            Optionally, some keyword arguments for the PyTorch learning rate scheduler. Default: ``None``.\n","        use_reversible_instance_norm\n","            Whether to use reversible instance normalization `RINorm` against distribution shift as shown in [2]_.\n","            It is only applied to the features of the target series and not the covariates.\n","        batch_size\n","            Number of time series (input and output sequences) used in each training pass. Default: ``32``.\n","        n_epochs\n","            Number of epochs over which to train the model. Default: ``100``.\n","        model_name\n","            Name of the model. Used for creating checkpoints and saving tensorboard data. If not specified,\n","            defaults to the following string ``\"YYYY-mm-dd_HH_MM_SS_torch_model_run_PID\"``, where the initial part\n","            of the name is formatted with the local date and time, while PID is the processed ID (preventing models\n","            spawned at the same time by different processes to share the same model_name). E.g.,\n","            ``\"2021-06-14_09_53_32_torch_model_run_44607\"``.\n","        work_dir\n","            Path of the working directory, where to save checkpoints and Tensorboard summaries.\n","            Default: current working directory.\n","        log_tensorboard\n","            If set, use Tensorboard to log the different parameters. The logs will be located in:\n","            ``\"{work_dir}/darts_logs/{model_name}/logs/\"``. Default: ``False``.\n","        nr_epochs_val_period\n","            Number of epochs to wait before evaluating the validation loss (if a validation\n","            ``TimeSeries`` is passed to the :func:`fit()` method). Default: ``1``.\n","        force_reset\n","            If set to ``True``, any previously-existing model with the same name will be reset (all checkpoints will\n","            be discarded). Default: ``False``.\n","        save_checkpoints\n","            Whether to automatically save the untrained model and checkpoints from training.\n","            To load the model from checkpoint, call :func:`MyModelClass.load_from_checkpoint()`, where\n","            :class:`MyModelClass` is the :class:`TorchForecastingModel` class that was used (such as :class:`TFTModel`,\n","            :class:`NBEATSModel`, etc.). If set to ``False``, the model can still be manually saved using\n","            :func:`save()` and loaded using :func:`load()`. Default: ``False``.\n","        add_encoders\n","            A large number of past and future covariates can be automatically generated with `add_encoders`.\n","            This can be done by adding multiple pre-defined index encoders and/or custom user-made functions that\n","            will be used as index encoders. Additionally, a transformer such as Darts' :class:`Scaler` can be added to\n","            transform the generated covariates. This happens all under one hood and only needs to be specified at\n","            model creation.\n","            Read :meth:`SequentialEncoder <darts.dataprocessing.encoders.SequentialEncoder>` to find out more about\n","            ``add_encoders``. Default: ``None``. An example showing some of ``add_encoders`` features:\n","\n","            .. highlight:: python\n","            .. code-block:: python\n","\n","                def encode_year(idx):\n","                    return (idx.year - 1950) / 50\n","\n","                add_encoders={\n","                    'cyclic': {'future': ['month']},\n","                    'datetime_attribute': {'future': ['hour', 'dayofweek']},\n","                    'position': {'past': ['relative'], 'future': ['relative']},\n","                    'custom': {'past': [encode_year]},\n","                    'transformer': Scaler(),\n","                    'tz': 'CET'\n","                }\n","            ..\n","        random_state\n","            Control the randomness of the weights initialization. Check this\n","            `link <https://scikit-learn.org/stable/glossary.html#term-random_state>`_ for more details.\n","            Default: ``None``.\n","        pl_trainer_kwargs\n","            By default :class:`TorchForecastingModel` creates a PyTorch Lightning Trainer with several useful presets\n","            that performs the training, validation and prediction processes. These presets include automatic\n","            checkpointing, tensorboard logging, setting the torch device and more.\n","            With ``pl_trainer_kwargs`` you can add additional kwargs to instantiate the PyTorch Lightning trainer\n","            object. Check the `PL Trainer documentation\n","            <https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html>`_ for more information about the\n","            supported kwargs. Default: ``None``.\n","            Running on GPU(s) is also possible using ``pl_trainer_kwargs`` by specifying keys ``\"accelerator\",\n","            \"devices\", and \"auto_select_gpus\"``. Some examples for setting the devices inside the ``pl_trainer_kwargs``\n","            dict:rgs``\n","            dict:\n","\n","            - ``{\"accelerator\": \"cpu\"}`` for CPU,\n","            - ``{\"accelerator\": \"gpu\", \"devices\": [i]}`` to use only GPU ``i`` (``i`` must be an integer),\n","            - ``{\"accelerator\": \"gpu\", \"devices\": -1, \"auto_select_gpus\": True}`` to use all available GPUS.\n","\n","            For more info, see here:\n","            https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-flags , and\n","            https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu_basic.html#train-on-multiple-gpus\n","\n","            With parameter ``\"callbacks\"`` you can add custom or PyTorch-Lightning built-in callbacks to Darts'\n","            :class:`TorchForecastingModel`. Below is an example for adding EarlyStopping to the training process.\n","            The model will stop training early if the validation loss `val_loss` does not improve beyond\n","            specifications. For more information on callbacks, visit:\n","            `PyTorch Lightning Callbacks\n","            <https://pytorch-lightning.readthedocs.io/en/stable/extensions/callbacks.html>`_\n","\n","            .. highlight:: python\n","            .. code-block:: python\n","\n","                from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","\n","                # stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n","                # a period of 5 epochs (`patience`)\n","                my_stopper = EarlyStopping(\n","                    monitor=\"val_loss\",\n","                    patience=5,\n","                    min_delta=0.05,\n","                    mode='min',\n","                )\n","\n","                pl_trainer_kwargs={\"callbacks\": [my_stopper]}\n","            ..\n","\n","            Note that you can also use a custom PyTorch Lightning Trainer for training and prediction with optional\n","            parameter ``trainer`` in :func:`fit()` and :func:`predict()`.\n","        show_warnings\n","            whether to show warnings raised from PyTorch Lightning. Useful to detect potential issues of\n","            your forecasting use case. Default: ``False``.\n","\n","        References\n","        ----------\n","        .. [1] https://arxiv.org/abs/1803.01271\n","        .. [2] T. Kim et al. \"Reversible Instance Normalization for Accurate Time-Series Forecasting against\n","                Distribution Shift\", https://openreview.net/forum?id=cGDAkQo1C0p\n","\n","        Examples\n","        --------\n","        >>> from darts.datasets import WeatherDataset\n","        >>> from darts.models import TCNModel\n","        >>> series = WeatherDataset().load()\n","        >>> # predicting atmospheric pressure\n","        >>> target = series['p (mbar)'][:100]\n","        >>> # optionally, use past observed rainfall (pretending to be unknown beyond index 100)\n","        >>> past_cov = series['rain (mm)'][:100]\n","        >>> # `output_chunk_length` must be strictly smaller than `input_chunk_length`\n","        >>> model = TCNModel(\n","        >>>     input_chunk_length=12,\n","        >>>     output_chunk_length=6,\n","        >>>     n_epochs=20,\n","        >>> )\n","        >>> model.fit(target, past_covariates=past_cov)\n","        >>> pred = model.predict(6)\n","        >>> pred.values()\n","        array([[-80.48476824],\n","               [-80.47896667],\n","               [-41.77135603],\n","               [-41.76158729],\n","               [-41.76854107],\n","               [-41.78166819]])\n","\n","        .. note::\n","            `DeepTCN example notebook <https://unit8co.github.io/darts/examples/09-DeepTCN-examples.html>`_ presents\n","            techniques that can be used to improve the forecasts quality compared to this simple usage example.\n","        \"\"\"\n","\n","        raise_if_not(\n","            kernel_size < input_chunk_length,\n","            \"The kernel size must be strictly smaller than the input length.\",\n","            logger,\n","        )\n","        raise_if_not(\n","            output_chunk_length < input_chunk_length,\n","            \"The output length must be strictly smaller than the input length\",\n","            logger,\n","        )\n","\n","        super().__init__(**self._extract_torch_model_params(**self.model_params))\n","\n","        # extract pytorch lightning module kwargs\n","        self.pl_module_params = self._extract_pl_module_params(**self.model_params)\n","\n","        self.kernel_size = kernel_size\n","        self.num_filters = num_filters\n","        self.num_layers = num_layers\n","        self.dilation_base = dilation_base\n","        self.dropout = dropout\n","        self.weight_norm = weight_norm\n","\n","    @property\n","    def supports_multivariate(self) -> bool:\n","        return True\n","\n","    def _create_model(self, train_sample: Tuple[torch.Tensor]) -> torch.nn.Module:\n","        # samples are made of (past_target, past_covariates, future_target)\n","        input_dim = train_sample[0].shape[1] + (\n","            train_sample[1].shape[1] if train_sample[1] is not None else 0\n","        )\n","        output_dim = train_sample[-1].shape[1]\n","        nr_params = 1 if self.likelihood is None else self.likelihood.num_parameters\n","\n","        return _TCNModule(\n","            input_size=input_dim,\n","            target_size=output_dim,\n","            nr_params=nr_params,\n","            kernel_size=self.kernel_size,\n","            num_filters=self.num_filters,\n","            num_layers=self.num_layers,\n","            dilation_base=self.dilation_base,\n","            target_length=self.output_chunk_length,\n","            dropout=self.dropout,\n","            weight_norm=self.weight_norm,\n","            **self.pl_module_params,\n","        )\n","\n","    def _build_train_dataset(\n","        self,\n","        target: Sequence[TimeSeries],\n","        past_covariates: Optional[Sequence[TimeSeries]],\n","        future_covariates: Optional[Sequence[TimeSeries]],\n","        sample_weight: Optional[Sequence[TimeSeries]],\n","        max_samples_per_ts: Optional[int],\n","    ) -> PastCovariatesShiftedDataset:\n","        return PastCovariatesShiftedDataset(\n","            target_series=target,\n","            covariates=past_covariates,\n","            length=self.input_chunk_length,\n","            shift=self.output_chunk_length + self.output_chunk_shift,\n","            max_samples_per_ts=max_samples_per_ts,\n","            use_static_covariates=self.uses_static_covariates,\n","            sample_weight=sample_weight,\n","        )"]},{"cell_type":"markdown","source":["## Explanation\n","\n","### Overview\n","The TCN model in Darts is used for time series forecasting. The provided code defines several classes and functions to implement this model. Here, we'll go through the main components:\n","\n","1. **_ResidualBlock** class: Implements a residual block used in the TCN.\n","\n","2. **_TCNModule**: class: Implements the TCN using residual blocks.\n","\n","3. **TCNModel** class: The main class that integrates with Darts for time series forecasting."],"metadata":{"id":"TLWzAmSMd_NW"}},{"cell_type":"code","source":[],"metadata":{"id":"7IJprn8o5POm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## １. `_ResidualBlock` Class\n","This class implements a residual block, a key building block in the TCN architecture. A residual block helps to preserve information from earlier layers, making training deep networks easier.\n","\n","### Initialization\n","\n","```python\n","class _ResidualBlock(nn.Module):\n","    def __init__(self, num_filters, kernel_size, dilation_base, dropout, weight_norm, nr_blocks_below, num_layers, input_size, target_size):\n","```\n","\n","* **num_filters**: Number of filters in the convolutional layers.\n","* **kernel_size**: Size of the convolutional kernels.\n","* **dilation_base**: Base of the dilation rate for the covolutions. (dilation_baseのnr_brocks_below乗がdilationの数になるので、これは基数？)\n","* **dropout**: Dropout rate for regularization.\n","* **weight_norm**: Whether to apply weight normalization.\n","* **nr_blocks_below**: Number of blocks below the current block. (CNN1dの層が複数有る時に、そのCNNが何層目かを表す)\n","* **num_layers**: Total number of covolutional layers.\n","* **input_size**: Size of the input time series.\n","* **target_size**: Size of the outpu time series.\n","\n","### Components\n","\n","```python\n","self.conv1 = nn.Conv1d(input_dim, num_filters, kernel_size, dilation=(dilation_base**nr_blocks_below))\n","self.conv2 = nn.Conv1d(num_filters, output_dim, kernel_size, dilation=(dilation_base**nr_blocks_below))\n","```\n","\n","The convolutional layers are defined with dilation rates that increase exponentially based on the **dilation_base**\n","\n","### Forward Pass\n","\n","```python\n","def forward(self, x):\n","    residual = x\n","    left_padding = (self.dilation_base**self.nr_blocks_below) * (self.kernel_size - 1)\n","    x = F.pad(x, (left_padding, 0))\n","    x = self.dropout1(F.relu(self.conv1(x)))\n","    x = F.pad(x, (left_padding, 0))\n","    x = self.conv2(x)\n","    if self.nr_blocks_below < self.num_layers - 1:\n","        x = F.relu(x)\n","    x = self.dropout2(x)\n","    if self.conv1.in_channels != self.conv2.out_channels:\n","        residual = self.conv3(residual)\n","    x = x + residual\n","    return x\n","```\n","\n","1. **Padding**: Adds padding to the input to maintain the outpu size.\n","2. **First Convolution**: Applies the first convolutional layer with ReLU activation and dropout.\n","3. **Second Convolution**: Applies the second convolutional layer.\n","4. **Residual Connection**: Adds the original input (residual) to the output, ensuring dimensions match.\n","\n","\n"],"metadata":{"id":"Jm30fp3fheVq"}},{"cell_type":"code","source":[],"metadata":{"id":"U46rwXyYNrjU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What is `num_filters` in `_ResidualBlock`\n","\n","**num_filters** in the **_ResidualBlock** class represents the number of filters (or channels) used in the convolutional layers within the block. In the context of a convolutional neural network (CNN), filters are used to detect different features in the input data by applying operations.\n","\n","#### Detailed Explanation:\n","##### Role of Filters in Convolutional Layers:\n","1. **Feature Detection**: Each filter in a convolutional layer is designed to detect a specific type of feature in the input data, such as edges, textures, or other patterns.\n","2. **Learned Parameters**: During training, the filters learn the optimal parameteers (weights) to extract relevant features from the input data.\n","3. **Output Channels**: The number of filters determines the number of output channels produced by convolutional layer. For example, if you have 64 filters in a convolutional layer, the output of that layer will have 64 channels.\n","\n","##### In the _ResidualBlock Class:\n","```python\n","self.conv1 = nn.Conv1d(input_dim, num_filters, kernel_size, dilation=(dilation_base**nr_blocks_below))\n","self.conv2 = nn.Conv1d(num_filters, output_dim, kernel_size, dilation=(dilation_base**nr_blocks_below))\n","```\n","\n","* **self.conv1**: The first convolutional layer has **num_filters** output channels.\n","* **self.conv2**: The second convolutional layer takes **num_filters** input channels (from **self.conv1**) and produces **output_dim** output channels.\n","\n","##### Parameters:\n","* **num_filters**: The number of filters in the convolutional layers of the residual block. This parameter controls the number of output channels produced by a convolutional layers within the block. Increasing the number of filters generally allows the network to capture more detailed and complex features but also increase the computational cost and the number of parameters in the model.\n","\n","#### Example:\n","If **num_filters** is set to 64, then both convolutional layers in the residual block will use 64 filters. This means:\n","\n","* The first convolutional layer (**self.conv1) will output 64 feature maps.\n","* The second convolutional layer (**self.conv2**) will take 64 input feature maps (from **self.conv1**) and produce **output_dim** feature maps.\n","\n","#### Importance of `num_filters`:\n","* **Capacity of the Model**: The number of filters directly affects the capacity of the model to learn and represent features in the data. More filters can capture more detailed features but require more computational resources.\n","* **Performance**: The choice of the number of filters is a crucial hyperparameter that can significantly impact the performance of the model. It is typically determined through experimentation and hyperparameter tuning.\n","\n","\n","In summary, **num_filters** in the **_ResidualBlock** class defines the number of convolutional filters used in the block's convolutional layers, directly influencing the feature extraction capability and the output dimensions of those layers."],"metadata":{"id":"FGv_ffq_kmEg"}},{"cell_type":"code","source":[],"metadata":{"id":"-_OLwSTlNvIb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### detail of `left_padding = (self.dilation_base**self.nr_blocks_below) * (self.kernel_size - 1)`\n","\n","### Purpose of Padding in Convolutional Networks\n","In convolutional neural networks (CNNs), padding is oftern applied to the input data to cotrol the spatial dimensions of the output feature maps. Padding helps in preserving the spatial dimensions of the input, which is important for ensuring that the output feature maps have the desired dimensions.\n","\n","### Dilated Convolutions\n","Dilated convolutions are a type of convolution where the filter is applied over a larger area than its length by skipping unput values with a certain step size. The dilation rate determines the spacing between the values in the filter.\n","\n","For a convolutional layer with:\n","\n","* **kernel_size**: $k$\n","* **dilation**: $d$\n","\n","    * The effective receptive field of the filter is increasing by the dilation rate.\n","\n","### Understanding the Padding Formula\n","The formula **`left_padding = (self.dilation_base ** self.nr_blocks_below) * (self.kernel_size - 1)`** is used to calculate the amount of padding needed to maintain the size of the input after the convolution operation. Let's break it down:\n","\n","*  **self.dilation_base\\*\\*self.nr_blocks_below**: This calculates the dilation rate for the current block. The dilation rate increases exponentially with the block index (**self.nr_blocks_below**).\n","\n","* **self.kernel_size - 1**: This term represents the number of positions the filter covers minus one. For example, with a kernel size of 3, the filter covers 3 positions, so this term would be 2.\n","\n","\n","The overall paddin ensures that the convolutional layer can process the input without reducing its size, which is crucial for maintaining the temporal dimension throughout the network.\n","\n","### Data Shape Changes\n","Let's go through an example to see how the data shape changes with padding and convolution.\n","\n","#### Example Prameters\n","* **kernel_size = 3**\n","* **dilation_base = 2**\n","* **nr_blocks_below = 1**\n","* input shape: **(batch_size, input_channels, input_length)**\n","\n","#### Calculating Padding\n","For **nr_blocks_below = 1**\n","\n","* Dilation rate = **2\\*\\*1 = 2**\n","* **left_padding = 2 * (3 - 1) = 4**\n","\n","#### Applying Padding\n","1. **Initial Input Shape**: Let's assume the input tensor shape is **(batch_size, input_channels, input_length)**.\n","2. **Padding**: When padding is applied to the left (start of the sequence), the new shape becomes **(batch_size, input_channels, input_length + left_padding)**.\n","3. **Convolution Operation**: The padding input is then passed through a convolutional layer. The shape of the output depends on the convolutionall parameters (filters, stride, etc.), but with proper padding, the length dimension is preserved.\n","\n","### Step-by-Step Example\n","#### 1. Initial Input Shape:\n","* Shape: **(batch_size, 16, 10)** (assuming `input_channels=16` and `input_length=10`)\n","\n","#### 2. Padding Calculation:\n","* **dilation_rate = 2**\n","* **left_padding = 2 * (3 - 1) = 4**\n","\n","#### 3. Applying Padding:\n","* Shape after padding: **(batch_size, 16, 10 + 4) = (batch_size, 16, 14)**\n","\n","#### 4. Convolution:\n","* Let's assume the convolution uses **num_filters = 32** and **kernel_size = 3** with dilation rate **2**.\n","* The convolution operation processes the input with the given kernel size and dilation.\n","* If stride is 1 and proper padding is applied, the output length remains **14**.\n","\n","### Summary\n","The formula **`left_padding = (self.dilation_base ** self.nr_blocks_below) * (self.kernel_size - 1)**` ensures that the input sequence's length is preserved after applying dilated convolutions. The padding compensates for the larger receptive field introduced by the dilation, preventing the reduction in the temporal dimension of the data. By maintaining the shape, the network can stack multiple residual blocks without altering the input length, which is essential for deep temporal convolutional networks."],"metadata":{"id":"-b6heLyKp5PE"}},{"cell_type":"code","source":[],"metadata":{"id":"taO9UrsId9oo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### detail of `def forward(self, x)` in _ResidualBlock\n","\n","It takes an input tensor `x` and processes it through a series of convolutional, activation, dropout, and residual addintion operations.\n","\n","```python\n","def forward(self, x)\n","```\n","\n","This defines the **forward** method, which takes a single argument **x** (the input tensor).\n","\n","### 1. Save the Residual\n","\n","```python\n","    residual = x\n","```\n","\n","* The input tensor **x** is saved as **residual**. This is the original input that will be added back to the output after processing through the convolutional layers. This addition helps preserve the input information and stabilize training.\n","\n","### 2. Calculate Padding\n","\n","```python\n","    left_padding = (self.dilation_base**self.nr_blocks_below) * (self.kernel_size - 1)\n","```\n","\n","* **left_padding** is calculated based on the dilation rate and kernel size. This padding ensures the output tensor has the same length as the input tensor after the convolution operation, which is crucial for maintaining the temporal dimension in a TCN.\n","\n","### 3. Apply Padding and First Convolution\n","\n","```python\n","    x = F.pad(x, (left_padding, 0))\n","    x = self.dropout1(F.relu(self.conv1(x)))\n","```\n","\n","* **Padding**: **F.pad(x, (left_padding, 0))** pads the input tensor **x** on the left with **left_padding** zeros. The shape of **x** changes from **(batch_size, input_channels, input_length)** to **(batch_size, input_channels, input_length + left_padding)**.\n","\n","* **First Convolution**: **self.conv1(x)** applies the first convolutional layer to the padded input. The convolution operation reduces the input length back to its original size, so the shape is **(batch_size, num_filters, input_length)**.\n","\n","* **ReLU Activation**: **F.relu(...)** applies the ReLU activation function to the output of the first convolutional layer, introducing non-linearity.\n","\n","* **Dropout**: **self.dropout1(...)** applies dropout for regularization, helping prevent overfitting during training.\n","\n","### 4. Apply Padding and Second Convolution\n","\n","```python\n","    x = F.pad(x, (left_padding, 0))\n","    x = self.conv2(x)\n","```\n","\n","* **Padding**: **F.pad(x, (left_padding, 0))** again pads the input tensor **x** on the left with **left_padding** zeros.\n","\n","* **Second Convolution**: **self.conv2(x)** applies the second convolutional layer. This layer reduces the length back to its original size, so the shape is **(batch_size, output_dim, input_length))**, where **output_dim** depends on whether it's the last residual block.\n","\n","### 5. Conditional ReLU Activation\n","\n","```python\n","    if self.nr_blocks_below < self.num_layers - 1:\n","        x = F.relu(x)\n","```\n","\n","* **ReLU Activation**: If the current block is not the last block in the TCN (**self.nr_blocks_below < self.num_layers - 1**), the ReLU activtion function is applied to the output of the second convolutional layer.\n","\n","### 6. Apply Second Dropout\n","\n","```python\n","    x = self.dropout2(x)\n","```\n","\n","* **Dropout**: **self.dropout2(x)** applies dropout to the output of the second convolutional layer.\n","\n","### 7. Adjust Residual if Needed\n","\n","```python\n","    if self.conv1.in_channels != self.conv2.out_channels:\n","        residual = self.conv3(residual)\n","```\n","\n","* **Adjust Residual**: If the number of input channels to the first convolution (**self.conv1.in_channels**) is different from the number of output channels of the second convolution (**self.conv2.out_channels**), the residual is passed through a third convolutional layer (**self.conv3**) to match the dimensions. This ensures that the residual and the output of the second convolution have compatible shapes for addition.\n","\n","### 8. Add Residual\n","\n","```python\n","    x = x + residual\n","```\n","\n","* **Add Residual**: The original input tensor (or the adjusted residual) is added to the output of the second convolution. This is the core idea of a residual block, which helps in preserving the input information and stabilizing the training of deep networks.\n","\n","### 9. Return the Output\n","\n","```python\n","    return x\n","```\n","\n","* The final output tensor **x**, which is the result of the convolutions, activations, dropout, and residual addition, is returned.\n","\n","\n","### Summary\n","\n","The **foward** method processes the input tensor **x** through a series of operations, including:\n","\n","1. Saving the input as residual.\n","2. Calculating and applying padding to maintain the temporal dimension.\n","3. Passing the padded input through two convolutional layers with ReLU activations and dropout.\n","4. Conditionally applying a third convolution to the residual if the dimensions do not match.\n","5. Adding the (possibly adjusted) residual to the output of the second convolution.\n","\n","This structure helps in capturing temporal features in the input data while preserving the original information, making it easier to  train deep networks."],"metadata":{"id":"6jyuh6zFyn8C"}},{"cell_type":"code","source":[],"metadata":{"id":"DGIgmDccd9kl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### the Shape of `x` in forward() process\n","\n","### Assumptions:\n","* **batch_size**: Number of sequences in a batch\n","* **input_channels**: Number of channels in the input sequence (or input dimension).\n","* **input_length**: Length of the input sequence.\n","* **num_filters**: Number of filters in the convolutional layers.\n","* **output_dim**: Number of output channels after the second convolution (could be **num_filters** or **targete_size * nr_params** depending on the block's position).\n","\n","### Initial Shape\n","\n","```python\n","def forward(self, x):\n","    residual = x\n","```\n","\n","* **Initial Shape: (batch_size, input_channels, input_length)**\n","* The residual is stored with the same shape as the input tensor **x**.\n","\n","### Padding Calculation\n","\n","```python\n","    left_padding = (self.dilation_base**self.nr_blocks_below) * (self.kernel_size - 1)\n","```\n","\n","* Padding does not change the shape but is used in the next step for padding the tensor.\n","\n","### First Padding and Convolution\n","\n","```python\n","    x = F.pad(x, (left_padding, 0))\n","```\n","\n","* **After Padding**: The tensor **x** is padded on the left.\n","* New Shape: **(batch_size, input_channels, input_length + left_padding)**\n","\n","\n","```python\n","    x = self.dropout1(F.relu(self.conv1(x)))\n","```\n","\n","* **After First Convolution**: The first convolutional layer reduces the length of the sequence back to its original size.\n","\n","* Shape after convolution: **(batch_size, num_filters, input_length)**\n","\n","* **After ReLU and Dropout**: The shape remains the same after applying ReLU and dropout.\n","\n","* Shape: **(batch_size, num_filters, input_length)**\n","\n","### Second Padding and Convolution\n","\n","```python\n","    x = F.pad(x, (left_padding, 0))\n","```\n","\n","* **After Padding**: The tensor **x** is padded again on the left.\n","* New Shape: **(batch_size, num_filters, input_length + left_padding)**\n","\n","```python\n","    x = self.conv2(x)\n","```\n","\n","* **After Second Convolution**: The second convolutional reduces the length of the sequence back to its original size.\n","\n","* Shape after convolution: **(batch_size, output_dim, input_length)**\n","\n","* **output_dim** is **target_size * nr_params** if it's the last residual block, otherwise **num_filters**.\n","\n","\n","### Conditional ReLU Activation\n","\n","```python\n","    if self.nr_blocks_below < self.num_layers - 1:\n","        x = F.relu(x)\n","```\n","\n","* **After Conditional ReLU**: If this is not the last block, ReLU is applied.\n","* Shape remains: **(batch_size, output_dim, input_length)**\n","\n","### Second Dropout\n","\n","```python\n","    x = self.dropout2(x)\n","```\n","\n","* **After Dropout**: Dropout is applied to the output.\n","* Shape remains: **(batch_size, output_dim, input_length)**\n","\n","### Adjust Residual if Needed\n","\n","```python\n","    if self.conv1.in_channels != self.conv2.out_channels:\n","        residual = self.conv3(residual)\n","```\n","\n","* **Adjust Residual**: If the input and output dimensions differ, the residual is passed through a 1×1 convolution to match the output dimensions.\n","* Shape of residual after adjustment: **(batch_size, output_dim, input_length)**\n","\n","### Add Residual\n","\n","```python\n","    x = x + residual\n","```\n","\n","* **Add Residual**: The residual is added to the output tensor **x**.\n","* Shape remains: **(batch_size, output_dim, input_length)**\n","\n","### Return the Output\n","\n","```python\n","    return x\n","```\n","\n","* The final output tensor **x** has the shape: **(batch_size, output_dim, input_length)**\n","\n","### Summary of Shape Changes\n","1. Initial Shape: (batch_size, input_channels, input_length)\n","2. After First Padding: (batch_size, input_channels, input_length + left_padding)\n","3. After First Convolution, ReLU, and Dropout: (batch_size, num_filters, input_length)\n","4. After Second Padding: (batch_size, num_filters, input_length + left_padding)\n","5. After Second Convolution: (batch_size, output_dim, input_length)\n","6.After Conditional ReLU: (batch_size, output_dim, input_length)\n","7.After Second Dropout: (batch_size, output_dim, input_length)\n","8.After Adjusting Residual (if needed): (batch_size, output_dim, input_length)\n","9. After Adding Residual: (batch_size, output_dim, input_length)\n","\n","\n","Throughout the forward pass, the padding ensures that the temporal dimension (sequence length) is preserved after each convolution, and the residual connection helps in stabilizing the network training."],"metadata":{"id":"kZgXfnJo9XHE"}},{"cell_type":"code","source":[],"metadata":{"id":"wV5kTLK4d9g_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### role of `nr_blocks_below` parameter\n","\n","The **`nr_blocks_below`** parameter in the **`_ResidualBlock`** class plays a crucial role in determining the dilation rate and, consequenctly, the receptive field of the convolutional layers within each residual block.\n","\n","### Role of `nr_blocks_below`\n","#### 1. Determining the Dilation Rate:\n","* The dilation rate for each convolutional layer in the residual block is calculated using **self.dilation_base \\*\\* self.nr_blocks_below**.\n","* The dilation rate controls how the filter is applied over the input sequence, effectively increasing the receptive field without increasing the number of parameters.\n","* As **nr_blocks_below** increases, the dilation rate increases exponentially, allowing each successive residual block to capture patterns over a larger temporal span.\n","\n","#### 2. Calculating the Left Padding:\n","* The left padding is calculated as **(self.dilaton_base\\*\\*self.nr_blocks_below) * (self.kernel_size - 1)**.\n","* This padding ensures that the input sequence length is preserved after the convolution, considering the dilation rate.\n","\n","### Explanation with Example\n","Let's take an example to illustrate the role of **nr_blocks_below**.\n","\n","#### Parameters\n","* **dilation_base = 2**\n","* **kernel_size = 3**\n","\n","For different values of **nr_blocks_below**:\n","\n","##### 1. When **`nr_blocks_below = 0`**\n","* Dilation rate = **2\\*\\*0 = 1**\n","* Left padding = **1 * (3 - 1) = 2**\n","* The convolution acts as a standard convolution with no dilation.\n","\n","##### 2. When **`nr_blocks_below = 1`**\n","* Dilation rate = **2\\*\\*1 = 1**\n","* Left padding = **2 * (3 - 1) = 4**\n","* The convolution skips every other input value, effectively increasing the receptive field.\n","\n","##### 3. When **`nr_blocks_below = 2`**\n","* Dilation rate = **`2\\*\\*2 = 4**\n","* Left padding = **4 * (3 - 1) = 8**\n","* The convolution skips three input values between each filter application, further increasing the receptive field.\n","\n","### Why is `nr_blocks_below` Important?\n","\n","#### 1. Increasing Receptive Field:\n","* By increasing the dilation rate with each residual block, the netwrok can capture long-term dependencies in the time series data. This is essential for time series forecasting, where patterns might span over long periods.\n","\n","#### 2. Efficient Parameter Usage:\n","* Dilated convolutions allow the network to have a large receptive field without a proportional increase in the number of parameters. This makes the model more efficient and helps in preventing overfitting.\n","\n","#### 3. Layer Differentiation:\n","* Each residual block operates at a different temporal resolution due to the varying dilation rates. This differentiation allows the network to learn features at multiple scales, improving its ability to generalize across diffenrent types of temporal patterns.\n","\n","### Summary\n","The **nr_blocks_below** parameter in the **_ResidualBlock** class is critical for controlling the dilation rate of the convolutional layers within each block. By exponentially increasing the dilation rate with the number of blocks, the network can capture patterns over various temporal scales, leading to better performance in time series forecasting tasks. This parameter ensures that the model can learn both short-term and long-term dependencies efficiently."],"metadata":{"id":"2d6SqAZz92qx"}},{"cell_type":"code","source":[],"metadata":{"id":"PWIa7k3xd9dK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### about `weight_norm`\n","\n","```python\n","if weight_norm:\n","            self.conv1, self.conv2 = (\n","                nn.utils.weight_norm(self.conv1),\n","                nn.utils.weight_norm(self.conv2),\n","            )\n","```\n","\n","The code snippet you provided is applying weight normalization to the convolutional layers in the **_ResidualBlock** class if the **weight_norm** parameter is set to **True**.\n","\n","### Weight Normalization\n","Weight normalization is a technique for reparameterizing the weights of a neural network layer to improve training dynamics. This technique was introduced by Tim Salimans and Diederik P. Kingma in their paper \"Weight Normalization: A Simple Reparametrization to Accelerate Training of Deep Neural Networks\".\n","\n","#### Key Concepts of Weight Normalization\n","##### 1. Normalization:\n","Weight normalization decouples the length (norm) of weight vectors from their direction. This helps in stabilizing the training process.\n","\n","#### 2. Reparametrization:\n","Instead of directry using the weight matrix **`W`**, it is reparametetrized into two separate components:\n","\n","* A vector **g** representing the scaling factor (norm of the weights).\n","\n","* A matrix **v** representing the direction of the weights (normalized weights).\n","\n","The weight matrix **W** is computed as:\n","   $$\n","   W = \\frac{v}{\\|v\\|} \\cdot g\n","   $$\n","   where $||v||$ is the L2 norm of `v`.\n","\n","### 3. Training Dynamics:\n","By normalizing the weights, gradients are better scaled, leading to more stable and faster convergence during training.\n","\n","### Apply Weight Normalization in `_ResidualBlock`\n","The code snippet checks if weight normalization should be applied to the convolutional layers:\n","\n","```python\n","if weight_norm:\n","    self.conv1, self.conv2 = (\n","        nn.utils.weight_norm(self.conv1),\n","        nn.utils.weight_norm(self.conv2),\n","    )\n","```\n","\n","#### Detailed Explanation:\n","1. **Condition Check**: **if weight_norm** cheks whether the **weight_norm** parameter is set to **True**.\n","\n","2. **Applying Weight Normalization**:\n","    * **nn.utils.weight_norm(self.conv1)**: This applies weight normalization to the first convolutional layer **self.conv1**.\n","    * **nn.utils.weight_norm(self.conv2)**: This applies weight normalization to the second convolutional layer **self.conv2**.\n","\n","By reassigning **self.conv1** and **self.conv2** with their weight-normalized version, the model ensures that these layers use the weight normalization technique during training and inference.\n","\n","### Benefits of Weight Normalization in TCN\n","1. **Improved Training Stability**: Weight normalizatin helps in stabilizing the gradients during training, leading to more stable and faster convergence.\n","2. **Better Performance**: By normalizaing the weights, the model can achieve better performance in terms of both training speed and final accuracy.\n","3. **Reduced Internal Covariate Shift**: Similar to batch normalization, weight normalization helps in reducing the internal covariate shift, which is the change in the distribution of network acitivations due to the update of network parameters during training.\n","\n","### Summary\n","In the **_ResidualBlock** class, the weight normalization process is applied to the convolutional layers if the **weight_norm** parameter is set to **True**. This involves reparameterizing the weights of the convolutional layers to separate the norm and direction, leading to more stable and efficient training. The main benefits of using weight normlaization include improved training stability, faster convergence, and better overall performance of the model."],"metadata":{"id":"r2ooMx0gnV3l"}},{"cell_type":"code","source":[],"metadata":{"id":"FrX9lAOFd9Zc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### relation between the number of `padding` and `dilation`\n","Let's clarify the relationship between padding and dilation in the context of a Temporal Convolutional Network(TCN).\n","\n","### Dilation in Convolutional Layers\n","Dilation is a technique used in convolutional layers to increase the receptive field without increasing the number of parameters. Dilation introduces gaps between the kernel elements, allowing the convolutional layer to cover a larger area of the input data.\n","\n","### Padding in Convolutional Layers\n","Padding is used to control the spatial dimensions of the output feature map. It adds extra pixels (usually zeros) to the input data before applying the convolution. The main reasons for padding are:\n","\n","1. To preserve the spatial dimensions of the input (same padding).\n","2. To control the size reduction caused by the convolution operation (valid padding).\n","\n","### Relationship Between Padding and Dilation\n","In the context of a TCN, padding and dilation work together to ensure that the convolutional operations maintain the desired properties of the model, such as the length of the input sequence.\n","\n","### Formula for Padding\n","The formula for padding in the **`_ResidualBlock`** class is:\n","\n","```python\n","left_padding = (self.dilation_base**self.nr_blocks_below) * (self.kernel_size - 1)\n","```\n","\n","#### Detailed Explanation\n","* **Dilation Rate**: The dilation rate is calculated as **self.dilation_base\\*\\*self.nr_blocks_below**.\n","    * **self.dilation_base**: The base dilation rage (e.g., 2).\n","    * **self.nr_blocks_below**: The index of the current residual block.\n","\n","* **Effective Kernel Size**: The effective size of the kernel after considering the dilation is **(self.kernel_size - 1) * dilation_rate + 1**.\n","\n","* **Padding Calculation**: To ensure that the output length is the same as the input length, we need to pad the input appropriately. The amount of padding required is calculated as **(self.dilation_base\\*\\*self.nr_blocks_below) * (self.kernel_size - 1)**. This padding ensures that each element in the input sequence has a corresponding element in the output sequence, even with the gaps introduced by the dialtion.\n","\n","### Example\n","\n","#### Parameters\n","* **kernel_size = 3**\n","* **dilation_base = 2**\n","* **nr_blocks_below = 1**\n","\n","#### Calculation\n","1. **Dilation Rate**:\n","    * Dilation rate = **2\\*\\*1 = 2**\n","2. **Effective Kernel Size**:\n","    * Effective Kernel size = **(3 - 1) * 2 + 1 = 5**\n","3. **Padding Calculation**:\n","    * Left padding = **2 * (3 - 1) = 4**\n","\n","#### Input and Output Shapes\n","* **Initaial Input Shape**: Let's assume the input tensor shape is **(batch_size, input_channels, input_length)**.\n","* **After Padding**: The input tensor is padded on the left, changing the shape to **(batch_size, input_channels, input_length + 4)**.\n","* **After Convolution**: The convolution operation reduces the length back to its original size, so the output shape is **(batch_size, num_filters, input_length)**.\n","\n","### Summary\n","* **Padding** and **dilation** are closely related in the context of a TCN.\n","* The dilation rate affects the spacing between elements in the kernel, effectively increasing the receptive field.\n","* The padding ensures that the length of the input sequence is preserved after the convolution operation, even with the increased receptive field due to dilation.\n","\n","By understanding this relationship, you can better grasp how TCNs maintain structure and capture long-term dependencies in time series data.\n"],"metadata":{"id":"WZBw1smY22Ds"}},{"cell_type":"code","source":[],"metadata":{"id":"XUWie6eCd9V6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The importanceof `Left Padding`\n","The idea of using left padding (also known as causal padding) in a TCN for time series prediction is indeed a common practice. This approach ensures that the model does not have access to future information when making predictions, thus maintaining the causality of the time series data.\n","\n","### Left Padding (Causal Padding)\n","In left padding, the input sequence is padded only on the left side (i.e., the beggining of the seuqnece). This ensures that each time step's prediction is based solely on the past and present data, without any leakage of future information. This is particularly important for time series forecasting, where we aim to predict future values based on past observations.\n","\n","### Symmetric Padding\n","In symmetric padding (used in the initial model), padding is applied equally on both sides of the input sequence. While this can help maintain the sequence length through convolutional layers, it allows the model to access future information, which is not desirable for time series forecasting tasks.\n","\n","### Comparison\n","#### Left Padding (Causal Padding) Model:\n","1. **Causality**: Ensures that predictions are made using only past and present data.\n","2. **Receptive Field**: The receptive field grows to the left, covering past time steps.\n","3. **Implementation**: Requires careful adjustment of padding to ensure causal convolutions.\n","\n","#### Symmetric Padding Model:\n","1. **Causality**: Potentially allows the model to access future information, which is not ideal for forecasting.\n","2. **Receptive Field**: Grows symmetrically around each time step.\n","3. Implementation**: Easier to implement with standard padding, but not suitable for forecasting.\n","\n","### Summary\n","* **Symmetric Padding**: Easier to implement but allows future information leakage.\n","* **Left Padding (Causal Padding)**: Ensures causality by using only past and present information for predictions, which is crucial for time series forecasting."],"metadata":{"id":"6nDSfRzUc_10"}},{"cell_type":"code","source":[],"metadata":{"id":"doR59Q3Hc_oD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"joHUH-chc_es"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ２. _TCNModule Class\n","\n","### Overvier\n","The **_TCNModule** class in the provided code is a PyTorch module that implements a Temporal Convolutional Network (TCN) using dilated convolutions and residual blocks. It extends the **PLPastCovariatesModule** class from the Darts libraly, which is a base class for PyTorch Lightning modules that support past covariates.\n","\n","### Code Breakdown\n","Class Definition and Initialization\n","\n","```python\n","class _TCNModule(PLPastCovariatesModule):\n","    def __init__(\n","        self,\n","        input_size: int,\n","        kernel_size: int,\n","        num_filters: int,\n","        num_layers: Optional[int],\n","        dilation_base: int,\n","        weight_norm: bool,\n","        target_size: int,\n","        nr_params: int,\n","        target_length: int,\n","        dropout: float,\n","        **kwargs,\n","    ):\n","        super().__init__(**kwargs)\n","```\n","\n","#### Parameters:\n","* `input_size`: The dimensionality of the input time series. (特徴量の数)\n","* `kernel_size`: The size of the kernels in the convolutional layers.\n","* `num_filters`: The number of filters (or channels) in the convolutional layers. (モデルの中間outputの次元数)\n","* `num_layers`: The number of convolutional layers. If `None`, it is computed based on the input length.\n","* `dilation_base`: The base of the dilation rate.\n","* `weight_norm`: A boolean indicating whether to apply weight normalization.\n","* `target_size`: The dimensionality of the output time series.\n","* `dropout`: The dropout rate for regularization.\n","* `**kwargs`: Additional parameters passed to the base class.\n","\n","#### Base Class Initialization:\n","* `super().\\_\\_init\\_\\_(\\*\\*kwargs): Initializes the base class `PLPastCovariatesModule`.\n","\n","### Setting Module Parameters\n","```python\n","        self.input_size = input_size\n","        self.n_filters = num_filters\n","        self.kernel_size = kernel_size\n","        self.target_length = target_length\n","        self.target_size = target_size\n","        self.nr_params = nr_params\n","        self.dilation_base = dilation_base\n","```\n","* These lines set the class attributes based on the parameters passed to the constructor.\n","\n","### Computing the Number of Layers\n","```python\n"," if num_layers is None and dilation_base > 1:\n","            num_layers = math.ceil(\n","                math.log(\n","                    (self.input_chunk_length - 1)\n","                    * (dilation_base - 1)\n","                    / (kernel_size - 1)\n","                    / 2\n","                    + 1,\n","                    dilation_base,\n","                )\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        elif num_layers is None:\n","            num_layers = math.ceil(\n","                (self.input_chunk_length - 1) / (kernel_size - 1) / 2\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        self.num_layers = num_layers\n","```\n","* **Dynamic Layer Calculation**: If `num_layers` is not specified, it is calculated based on the `dilation_base` and `input_chunk_length`. This ensures that the network has enough layers to cover the input sequence.\n","\n","### Building Residual Blocks\n","\n","```python\n","self.res_block_list = []\n","for i in range(num_layers):\n","    res_block = _ResidualBlock(\n","        num_filters=num_filters,\n","        kernel_size=kernel_size,\n","        dilation_base=dilation_base,\n","        dropout=dropout,\n","        weight_norm=weight_norm,\n","        nr_blocks_below=i,\n","        num_layers=num_layers,\n","        input_size=self.input_size,\n","        target_size=target_size * nr_params,\n","    )\n","    self.res_blocks_list.append(res_block)\n","self.res_blocks = nn.ModuleList(self.res_blocks_list)\n","```\n","\n","* **Residual Blocks**: A list of residual blocks (`_ResidualBlock`) is created. Each block is initialized with increasing dilation rates (determined by `nr_blocks_below`).\n","* **ModuleList**: The list of residual blocks is converted to a **nn.ModuleList**, which is a container for holding submodules.\n","\n","### Forward Method\n","```python\n","@io_processor\n","def forward(self, x_in: Tuple):\n","    x, _ = x_in\n","    x = x.transpose(1, 2)\n","```\n","* **Input Transformation**: The input tensor `x` is transposed to match the expected input shape for the convolutional layers. The shape changes from (`batch_size, input_chunk_length, input_size`) to (`batch_size, input_size, input_chunk_length`).\n","\n","```python\n","for res_block in self.res_blocks_list:\n","    x = res_block(x)\n","```\n","* **Residual Block Processing**: The input tensor `x` is passed through each residual block in the `self.res_blocks_list`. Each block applies its convolutions, activations, and residual connections.\n","\n","```python\n","x = x.transpose(1, 2)\n","x = x.view(\n","    batch_size, self.input_chunk_length, self.target_size, self.nr_params)\n","```\n","* **Output Transformation**: The output tensor `x` is transposed back to its original shape and reshaped to the desired output dimensions. The shape changes from (`batch_size, num_filters, input_length`) to (`batch_size, input_chunk_length, target_size, nr_params`)\n","\n","```python\n","return x\n","```\n","* **Return Output**: The final output tensor is returned.\n","\n","### Property: First Prediction Index\n","```python\n","@property\n","def first_prediction_index(self) -> int:\n","    return -self.output_chunk_length\n","```\n","* **First Prediction Index**: This property returns the index of the first prediction in the output tensor. It is used to determine where the predictions start in the output sequence.\n","\n","### Summary\n","* The `_TCNModule` class defines the core architecture of the TCN using dilated convolutions and residual blocks.\n","* It dynamically computes the number of layers if not specified.\n","* It builds a list of residual blocks, each with increasing dilation rates, and processed the input tensor through these blocks.\n","* The input tensor is transformed to match the expected shapes for convolutional operations, and the output tensor is transformed back to the desired shape.\n","* The `first_prediction_index` property helps determine the starting point of the predictions in the output sequence.\n"],"metadata":{"id":"ZYFrxVonQICX"}},{"cell_type":"code","source":[],"metadata":{"id":"tlPoTRzId9TD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### detail of `Computing Number of Layers`\n","```python\n","if num_layers is None and dilation_base > 1:\n","            num_layers = math.ceil(\n","                math.log(\n","                    (self.input_chunk_length - 1)\n","                    * (dilation_base - 1)\n","                    / (kernel_size - 1)\n","                    / 2\n","                    + 1,\n","                    dilation_base,\n","                )\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        elif num_layers is None:\n","            num_layers = math.ceil(\n","                (self.input_chunk_length - 1) / (kernel_size - 1) / 2\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        self.num_layers = num_layers\n","```\n","\n","This code is used to determine the number of layers in the TCN based on the input parameters. The purpose is to ensure that the network has enough layers to cover the entire input sequence given the dilation base and kernel size.\n","\n","### Explanation\n","#### 1. Input Parameters:\n","* **self.input_chunk_length**: The length of the input sequence.\n","* **dilation_base**: The base of the dilation rate.\n","* **kernel_size**: The size of the convolutional kernel.\n","* **num_layers**: The number of layers (if specified).\n","\n","#### 2. Calculation with `dilation_base > 1`:\n","* When the **dilation_base** is greater than 1, the formula used is:\n","```python\n","num_layers = math.ceil(\n","    math.log(\n","        (self.input_chunk_length - 1)\n","        * (dilation_base - 1)\n","        / (kernel_size - 1)\n","        / 2\n","        + 1,\n","        dilation_base,\n","    )\n",")\n","```\n","* Explanation:\n","    * **Goal**: To ensure the receptive field of the network covers the entire input sequence.\n","    * **Receptive Field**: The range of input sequence indices that affect the output at a particular index.\n","    * **Formula Breakdown**:\n","        * **(self.input_chunk_length - 1)**: The length of the input seuquence minus one.\n","        * **(dilation_base - 1)**: The increment in the receptive field for each additional layer when the dilation base is greater than 1.\n","    * **/ (kernel_size - 1)**: The effective receptive field per layer is scaled by the kernel_size minus one.\n","    * **/ 2 + 1**: Adjustments to ensure the calculation is valid.\n","    * **math.log(..., dilation_base)**: The logarithm base **dilation_base** determines how many layers are needed to cover the entire input sequence.\n","    * **math.ceil(...)**: Rounds up to the nearest interger to ensure full coverage.\n","\n","\n","#### 3. Calculation with `dilation_base <= 1`\n","* When the **dilation_base** is 1 or less, the formula used is:\n","```python\n","num_layers = math.ceil(\n","    (self.input_chunk_length - 1) / (kernel_size - 1) / 2\n",")\n","```\n","\n","* Explanation:\n","    * **Goal**: To ensure that the receptive field covers the input sequence.\n","    * **Formula Breakdown**:\n","        * **(self.input_chunk_length - 1)**: The length of the input sequence minus one.\n","        * **/ (kernel_size - 1)**: The effective receptive field per layer is scaled by the kernel size minus one.\n","        * **/ 2**: Ensures sufficient layers are added to cover the input.\n","        * **math.ceil(...)**: Rounds up to the nearest interger.\n","\n","\n","### Choosing the Number of Layers\n","The formulas aim to ensure that the network's field can cover the entire input sequence. The choice of layers depends on:\n","* **Input Chunk Length**: The length of the input sequence.\n","* **Kernel Size**: The size of the convolutional kernel.\n","* **Dilation Base**: The base of the dilation rate, which affects how the receptive field grows with each layer.\n","\n","### Practical Cosiderations:\n","* **Receptive Field**: The receptive field should ideally cover the entire input sequence to capture dependencies across the sequence.\n","* **Dilation**: Dilation helps to exponentially increase the receptive field with each layer without increasing the number of parameters significantly.\n","\n","### Example Calculation\n","Assume:\n","* **input_chunk_length = 24**\n","* **kernel_size = 3**\n","* **dilation_base = 2**\n","\n","Using the first formula:\n","\n"],"metadata":{"id":"JSR3yHhrTHWE"}},{"cell_type":"code","source":["import math\n","num_layers = math.ceil(\n","    math.log(\n","        (24 - 1) * (2 - 1) / (3 - 1) / 2 + 1,\n","        2,\n","    )\n",")\n","print(num_layers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwJO5FFUTGip","executionInfo":{"status":"ok","timestamp":1721718462312,"user_tz":-540,"elapsed":326,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"657fe1be-1a71-46ce-ec9f-0ff0bed36929"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n"]}]},{"cell_type":"markdown","source":["This calculate the number of layers required to cover the input sequence given the specified kernel size and dilation base.\n","\n","This approach ensures that the model has enough layers to capture the dependencies across the input sequence while using the dilation mechanism to efficiently expand the receptive field.\n","\n","### ※ unit8のブログでの注意点\n","* kernel_sizeとdilation_baseの数で、捕捉できるinput_lengthの数が決まるので、自分で、input_lengthの数に合わせて、kernel_sizeとdilation_baseの数を計算して指定しないといけない。\n","* kernel_size=3, dilation_base=2の時はinput_lengthは15までしか捕捉できない。\n","    * ブログ： https://unit8.com/resources/temporal-convolutional-networks-and-forecasting/"],"metadata":{"id":"uyFGKuypavXV"}},{"cell_type":"code","source":[],"metadata":{"id":"VYFwvIZYTGfG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### additional explanation of above formula to calculate layer's number\n","\n","To under stand why the formula ensures that the chosen number of layers can cover the whole input sequence, let's deeper into the concept of the receptive field and how the dilation factor impacts it.\n","\n","### Receptive Field and Dilation\n","#### 1. Receptive Field:\n","* The receptive field of a convolutinal neural network (CNN) layer is the range of input values that affect a single output value.\n","* For a single convolutional layer with kernel size **k** and no dilation, the receptive field is **k**.\n","\n","#### 2. Dilation:\n","* Dilation increase the receptive field exponentially without increasing the number of parameters.\n","* For a convolutional layer with kernel size **k** and dilation factor **d**, the receptive field is **k + (k - 1) * (d - 1)**.\n","* For multiple layers, the receptive field grows multiplicatively.\n","\n","### Example Calculation Breakdown\n","Given:\n","* **input_chunk_length = 24**\n","* **kernel_size = 3**\n","* **dilation_base = 2**\n","\n","Let's calculate the number of layers using the formula:\n"],"metadata":{"id":"j6y6xckGb2AA"}},{"cell_type":"code","source":["import math"],"metadata":{"id":"DzYfh9wb_k3Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_layers = math.ceil(\n","    math.log(\n","        (24 - 1) * (2 - 1) / (3 - 1) / 2 + 1,\n","        2,\n","    )\n",")\n","print(num_layers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIOrNaJTTGaM","executionInfo":{"status":"ok","timestamp":1721720236311,"user_tz":-540,"elapsed":10,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"a186cf60-45c6-4811-ed3b-26abc1ffa72d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n"]}]},{"cell_type":"markdown","source":["##### Step-by-Step Calculation\n","1. **Calculate the Effective Input Length**:\n","```python\n","effective_input_length = (24 - 1) * (2 - 1) / (3 - 1) / 2 + 1\n","                       = 23 * 1 / 2 / 2 + 1\n","                       = 23 / 4 + 1\n","                       = 5.75 + 1\n","                       = 6.75\n","```\n","\n","2. **Calculate the Number of Layers**:\n","```python\n","num_layers = math.ceil(math.log(6.75, 2))\n","          = math.ceil(2.7548875021634687)\n","          = 3\n","```\n","\n","#### Explanation\n","This ensures that the network's receptive field is sufficient to cover the entire input sequence length. Let's break down why this work.\n","\n","#### Step-by-Step Calculation\n","\n","1. **Calculate the Effective Input Length**:\n","   $$\n","   \\text{effective_input_length} = \\left( \\frac{(24 - 1) \\times (2 - 1)}{(3 - 1)} \\right) / 2 + 1\n","   $$\n","   $$\n","   \\text{effective_input_length} = \\left( \\frac{23 \\times 1}{2} \\right) / 2 + 1\n","   $$\n","   $$\n","   \\text{effective_input_length} = \\left( 11.5 \\right) / 2 + 1\n","   $$\n","   $$\n","   \\text{effective_input_length} = 5.75 + 1\n","   $$\n","   $$\n","   \\text{effective_input_length} = 6.75\n","   $$\n","\n","2. **Calculate the Number of Layers**:\n","   $$\n","   \\text{num_layers} = \\left\\lceil \\log_2 (6.75) \\right\\rceil\n","   $$\n","   $$\n","   \\text{num_layers} = \\left\\lceil 2.7548875021634687 \\right\\rceil\n","   $$\n","   $$\n","   \\text{num_layers} = 3\n","   $$\n","\n","\n","#### How 3 Layers Cover the Input Sequence\n","\n","#### Receptive Field with Dilation\n","\n","The receptive field $ R $ for a TCN with $ L $ layers, dilation factor $ d $, and kernel size $ k $ is calculated as:\n","\n","$$ R = 1 + (k - 1) \\sum_{i=0}^{L-1} d^i $$\n","\n","Given:\n","- $ k = 3 $\n","- $ d = 2 $\n","- $ L = 3 $\n","\n","#### Calculate the Sum of Dilations\n","$$\n","\\sum_{i=0}^{2} d^i = 2^0 + 2^1 + 2^2 = 1 + 2 + 4 = 7\n","$$\n","\n","#### Effective Receptive Field Calculation\n","$$\n","R = 1 + (3 - 1) \\times 7 = 1 + 2 \\times 7 = 1 + 14 = 15\n","$$\n","\n","### Ensuring Coverage\n","To ensure the entire input sequence of 24 time steps, the receptive field should ideally be equal to or greater than 24. Since 15 is less than 24, we need to re-evaluate the number of layers:\n","\n","### Correct Calculation for Coverage\n","\n","The formula used in the code calculates the minimum number of layers needed to ensure the receptive field covers the input sequence length:\n","$$\n","L \\geq \\log_d \\left( \\frac{(input\\_chunk\\_length - 1) \\times (dilation\\_base - 1)}{(kernel\\_size - 1)} / 2 + 1 \\right)\n","$$\n","\n","Given:\n","$$\n","L \\geq \\log_2 \\left( \\left( \\frac{23 \\times 1}{2} \\right) / 2 + 1 \\right)\n","$$\n","\n","$$\n","L \\geq \\log_2 (6.75) \\approx 2.7548875021634687\n","$$\n","\n","$$\n","L \\approx 3\n","$$\n","\n","### Effective Receptive Field Calculation for 4 Layers\n","\n","Since the calculated number of layers (3) does not cover the input length, the next logical step would be to evaluate with 4 layers:\n","\n","1. **Layer 4**:\n","   - Dilation: $ 2^3 = 8 $\n","   - Receptive field: $ 8 \\times (3 - 1) + 1 = 8 \\times 2 + 1 = 17 $\n","\n","#### Combined Receptive Field for 4 Layers\n","$$\n","\\sum_{i=0}^{3} d^i = 2^0 + 2^1 + 2^2 + 2^3 = 1 + 2 + 4 + 8 = 15\n","$$\n","\n","$$\n","R = 1 + (3 - 1) \\times 15 = 1 + 2 \\times 15 = 1 + 30 = 31\n","$$\n","\n","With 4 layers, the effective receptive field becomes 31, which covers the input sequence length of 24.\n","\n","### Conclusion\n","\n","The code uses the formula to calculate the minimum number of layers required to cover the input sequence length. In the given example, the formula calculates 3 layers, but to ensure full coverage of the input sequence of 24 time steps, 4 layers would be needed. This ensures that the receptive field of the network covers the entire input sequence, allowing the model to capture dependencies across all time steps."],"metadata":{"id":"8pU4Yrx9hfKK"}},{"cell_type":"code","source":[],"metadata":{"id":"BXFj7DW-FonW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ※ num_layerに関する結論\n","補足できるinput_lengthの長さは、kernel_sizeとdilation_baseに制限されるので、kernel_sizee=3, dilation_base=2の時のinput_lengthの上限は15まで。よって、input_length=24までを補足した時は、kernel_sizeの数を増やさないといけない。\n","\n","### kernel_sizeとdilation_baseの条件\n","* kernel_sizeはdilation_rateより大きくないといけない!!!"],"metadata":{"id":"U4XfVFMXFo_5"}},{"cell_type":"code","source":[],"metadata":{"id":"BNVTimWsfbVD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Is Darts formula to calculate number of layers wrong?\n","※※※ 上記質問は、Dartsでのnum_layersの計算方法を理解していないために生じた。ここでは、kernel_size=3, dilation_base=2で何故input_length=24のカバーができないかについて理解していなかった。kernel_sizeとdilation_baseの数で補足できるinput_lengthの最大値は決まるので、input_lengthに合わせて、自分で、kernel_sizeとdilation_baseの数を計算しないといけない。\n","\n","The forumula used in Darts to calculate the number of layers is indeed correct for many practical purpose, but it may not guarantee that receptive field always covers the entire input sequence length. Let's delve into the practical usage and limitaions of the formula.\n","\n","### Analysis of the Darts Formula\n","The Darts formula for calculating the number of layers is:\n","\n","```python\n","if num_layers is None and dilation_base > 1:\n","    num_layers = math.ceil(\n","        math.log(\n","            (self.input_chunk_length - 1)\n","            * (dilation_base - 1)\n","            / (kernel_size - 1)\n","            / 2\n","            + 1,\n","            dilation_base,\n","        )\n","    )\n","```\n","\n","This formula aims to provide a reasonable number of layers to cover the input sequence length given the dilation and kernel size. Let's re-examine the calculations for clarity.\n","\n","### Re-examination of the Calculation\n","Given:\n","* **input_chunk_length = 24**\n","* **dilation_base = 2**\n","* **kernel_sie = 3**\n","\n","#### Effective Input Length Calculation\n","$$\n","\\text{effective_input_length} = \\left( \\frac{(24 - 1) \\times (2 - 1)}{(3 - 1)} \\right) / 2 + 1\n","$$\n","$$\n","\\text{effective_input_length} = \\left( \\frac{23 \\times 1}{2} \\right) / 2 + 1\n","$$\n","$$\n","\\text{effective_input_length} = 5.75 + 1\n","$$\n","$$\n","\\text{effective_input_length} = 6.75\n","$$\n","\n","#### Number of Layers Calculation\n","$$\n","\\text{num_layers} = \\left\\lceil \\log_2 (6.75) \\right\\rceil\n","$$\n","$$\n","\\text{num_layers} = \\left\\lceil 2.7548875021634687 \\right\\rceil\n","$$\n","$$\n","\\text{num_layers} = 3\n","$$\n","\n","### Practical Receptive Field Coverage\n","With 3 layers, the combined receptive field:\n","1. **Layer 1**: 3 steps\n","2. **Layer 2**: 5 steps\n","3. **Layer 3**: 9 steps\n","\n","The combined effective receptive field is 15 steps, which is less than the input sequence length of 24 steps.\n","\n","### Receptive Field Coverage with Additional Layer\n","By using 4 layers, we can cover the input sequence length more effectively:\n","* **Layer 4**: Receptive field covers 17 steps\n","* Combined effective receptive field: 31 steps\n","\n","### Conclusion\n","The Darts formula provides a heuristic(発見的な、直感的な) to calculate the number of layers, which works well for many practival cases. However, it may not always guaarantee full coverage of the input sequence length, especially for longer sequences. For the given parameters, while the formula suggests 3 layers, practical coverage requires 4 layers to ensure the receptive field spans the entire input sequence.\n","\n","### Ensuring Full Coverage\n","To ensure full coverage, you can manually adjust the number of layers based on the receptive field calculation:\n","1. **Calculate the combined receptive filed** for the desired number of layers.\n","2. **Verify(確かめる) that the receptive field** is equal to or greater than the input sequence length.\n","3. **Adjust the number of layers** if necessary to ensure full coverage.\n","\n","### Final Code with Adjustments\n","\n","```python\n","# Adjusting the number of layers to ensure full coverage\n","if num_layers is None and dilation_base > 1:\n","    num_layers = math.ceil(\n","        math.log(\n","            (input_chunk_length - 1)\n","            * (dilation_base - 1)\n","            / (kernel_size - 1)\n","            / 2\n","            + 1,\n","            dilation_base\n","        )\n","    )\n","    if (1 * (kernel_size - 1) * sum([dilation_base**i for i in range(num_layers])) < input_chunk_length:\n","        num_layers += 1 # Add one more layer if the coverage is not enough\n","else:\n","    num_layers = math.ceil(\n","        (input_chunk_length - 1) / (kernel_size - 1) / 2\n","    )\n","```\n","\n","This approach ensures that the number of layers calculated will always cover the input sequence length.\n","\n","\n"],"metadata":{"id":"RxeqUdxInnYQ"}},{"cell_type":"code","source":[],"metadata":{"id":"lYO9b_Y1fbSQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### input_length=90の時の、dilationの決め方の例\n","* pytorch版において、input_length=90の時のdilationの決め方\n","\n","Let's delve into how dilation expands the receptive field in a TCN to cover 90 days in input data.\n","\n","### Understanding Dilation\n","Dilation is a technique in convolutional layers to increase the receptive field without increasing the number of parameters or the computational cost. A dilation rate of $d$ means that each filter is applied to every $d$-th element of the input, effectively spreading the filter out over a larger area of the input.\n","\n","### Receptive Field Calculation\n","To calculate the receptive field, we need to consider the kernel size, dilation rate, and the number of layers. The receptive field $R$ of a layer in a TCN can be calculated using the following formula:\n","$$\n","R = 1 + (k - 1) \\times \\sum_{i=0}^{L-1} d_i\n","$$\n","\n","where:\n","* $k$ is the kernel size\n","* $L$ is the number of layers\n","* $d_i$ is the dilation rate of the $i$-th\n","\n","### Example with 90 Days Input\n","Let's assume we have the following TCN configuration:\n","* kernel size ($k$): 2\n","* Number of layers ($L$): 4\n","* Dilation rate: increasing exponentially as $2^i$ (i.e., 1,2,4,8 for four layers)\n","\n","#### Receptive Field Expansion\n","For each layer, the dilation rate and the receptive field are calculated as follows:\n","1. **Layer 1**:\n","    * Dilation ($d_0$): 1\n","    * Receptive Field: $R_1 = 1 + (2 - 1) \\times 1 = 2$\n","2. **Layer 2**:\n","    * Dilation ($d_1$): 2\n","    * Receptive Field: $R_2 = 1 + (2 - 1) \\times (1 + 2) = 3$\n","3. **Layer 3**:\n","    * Dilation ($d_2$): 4\n","    * Receptive Field: $R_3 = 1 + (2 - 1) \\times (1 + 2 + 4) = 7$\n","4. **Layer 4**:\n","    * Dilation ($d_3$): 8\n","    * Receptive Field: $R_4 = 1 + (2 - 1) \\times (1 + 2 + 4 + 8) = 15$\n","\n","\n","As we cann see, with only 4 layers, the receptive field covers 15 time steps. To cover 90 days, we need more layers. Let's calculate how many layers we need:\n","$$\n","\\text{Receptive Field} = 1 + (k - 1) \\times \\sum_{i=0}^{L-1} 2^i\n","$$\n","\n","For the sum of powers of 2:\n","$$\n","\\sum_{i=0}^{L-1} 2^i = 2^L - 1\n","$$\n","\n","Thus, the receptive field becomes:\n","$$\n"," \\text{Receptive Field} = 1 + (k - 1) \\times (2^L - 1)\n","$$\n","\n","For $k = 2$\n","$$\n","1 + (2 - 1) \\times (2^L - 1) = 1 + 2^L - 1 = 2^L\n","$$\n","\n","We need $2^L \\geq 90$\n","$$\n","L \\geq \\log_2(90) \\approx 6.49\n","$$\n","\n","So, we need at least 7 layers to cover 90 days.\n","\n","### Sample Code to Cover 90 Days with Dilation"],"metadata":{"id":"1r2b7EdyJva4"}},{"cell_type":"code","source":["import torch\n","import torch.nn\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset"],"metadata":{"id":"ijIHdzmPJvH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Custom Dataset Class\n","class StockDataset(Dataset):\n","    def __init__(self, data, input_length):\n","        self.data = data\n","        self.input_length = input_length\n","\n","    def __len__(self):\n","        return len(self.data) - self.input_length\n","\n","    def __getitem__(self, index):\n","        x = self.data[index:index+self.input_length]\n","        y = self.data[index+self.input_length]\n","        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n","\n","# Create a sample dataset\n","np.random.seed(42)\n","dates = pd.date_range(start='2023-01-01', periods=500, freq='D')\n","prices = np.cumsum(np.random.randn(500)) + 100 # Simulate stock prices\n","data = pd.DataFrame({'date': dates, 'price': prices})\n","\n","# Prepare the dataset\n","input_length = 90\n","prices = data['price'].values\n","dataset = StockDataset(prices, input_length)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n","\n","for x, y in dataloader:\n","    print(x.shape, y.shape)\n","    break"],"metadata":{"id":"KCe3VIxxJvBm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722254848933,"user_tz":-540,"elapsed":289,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"b6aab787-7603-4773-cd5c-c904e0d52b79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 90]) torch.Size([32])\n"]}]},{"cell_type":"code","source":["class TemporalBlock(nn.Module):\n","    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n","                               stride=stride, padding=0, dilation=dilation)\n","        self.left_padding = nn.ConstantPad1d((padding, 0), 0) # Left padding\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.net = nn.Sequential(\n","            self.left_padding,\n","            self.conv1,\n","            self.relu,\n","            self.dropout\n","        )\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        self.conv1.weight.data.normal_(0, 0.01)\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","class TemporalConvnet(nn.Module):\n","    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n","        super(TemporalConvnet, self).__init__()\n","        layer = []\n","        num_levels = len(num_channels)\n","        for i in range(num_levels):\n","            dilation_size = 2 ** i\n","            in_channels = num_inputs if i == 0 else num_channels[i-1]\n","            out_channels = num_channels[i]\n","            layer += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n","                                    padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n","\n","        self.network = nn.Sequential(*layer)\n","\n","    def forward(self, x):\n","        return self.network(x)\n","\n","\n","class TCN(nn.Module):\n","    def __init__(self, input_size, output_size, num_channels, kernel_size=2, dropout=0.2):\n","        super(TCN, self).__init__()\n","        self.tcn = TemporalConvnet(input_size, num_channels, kernel_size, dropout)\n","        self.linear = nn.Linear(num_channels[-1], output_size)\n","\n","    def forward(self, x):\n","        y1 = self.tcn(x)\n","        y1 = y1[:, :, -1] # We want the last time step's output\n","        return self.linear(y1)"],"metadata":{"id":"rOoqp4wBZrrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the model, loss function, and optimizer\n","input_size = 1\n","output_size = 1\n","num_channels = [25, 25, 25, 25, 25, 25, 25] # 7 layers to cover 90 days\n","kernel_size = 2\n","dropout = 0.2\n","\n","model = TCN(input_size, output_size, num_channels, kernel_size, dropout)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 100\n","model.train()\n","for epoch in range(num_epochs):\n","    for inputs, targets in dataloader:\n","        inputs = inputs.unsqueeze(1)  # Add a channel dimension\n","        targets = targets.unsqueeze(1)  # Add a channel dimension\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","    if (epoch+1) % 10 == 0:\n","        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')"],"metadata":{"id":"EzGiVNCQjUiq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722255066347,"user_tz":-540,"elapsed":25301,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"afc3a2f0-9a08-4482-b3c1-b0cf56b12b3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10/100, Loss: 512.7353\n","Epoch 20/100, Loss: 582.1553\n","Epoch 30/100, Loss: 240.9484\n","Epoch 40/100, Loss: 962.4811\n","Epoch 50/100, Loss: 511.9600\n","Epoch 60/100, Loss: 556.6605\n","Epoch 70/100, Loss: 564.3285\n","Epoch 80/100, Loss: 666.3497\n","Epoch 90/100, Loss: 333.7607\n","Epoch 100/100, Loss: 388.0709\n"]}]},{"cell_type":"code","source":["# Make predictions\n","model.eval()\n","result_list = []\n","with torch.no_grad():\n","    for inputs, targets in dataloader:\n","        inputs = inputs.unsqueeze(1)  # Add a channel dimension\n","        targets = targets.unsqueeze(1)  # Add a channel dimension\n","\n","        outputs = model(inputs)\n","        result_list.extend(outputs.squeeze().tolist())"],"metadata":{"id":"rA-ayOp3Zrk1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(result_list)"],"metadata":{"id":"zZqx7fNjZrdK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722255362533,"user_tz":-540,"elapsed":288,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"b22d078d-e622-4eff-b641-26745079a272"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["410"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["result_df = data.iloc[90:]\n","result_df['predicted_price'] = result_list\n","result_df.set_index('date', inplace=True)"],"metadata":{"id":"ylRyPjx5Ju0o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722255451460,"user_tz":-540,"elapsed":379,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"7499e0b5-3b32-4e1c-8e52-d81a2a2088d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-32-e04b6af16c56>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  result_df['predicted_price'] = result_list\n"]}]},{"cell_type":"code","source":["result_df.plot()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"id":"YiYHAejbbELJ","executionInfo":{"status":"ok","timestamp":1722255509920,"user_tz":-540,"elapsed":1660,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"0296f492-fc3e-49a7-a14a-da7b3fdeff80"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='date'>"]},"metadata":{},"execution_count":35},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"dOWDBfLrbEF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n7S4MxIebD-z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What is `nr_params` parameter\n","The `nr_params` parameter in the `class _TCNModlue` refers to the number of parameters of the likelihood function, or simply the number of parameters the model outputs for each time step.\n","\n","### Role of `nr_params`\n","#### 1. Deterministic vs. Probabilistic Models:\n","* In deterministic forecasting models, each output time step typically corresponds to a single value (e.g., the predicted value at that time step).\n","* In probabilistic forecasting models, each output time step might correspond to multiple values representing a probability distribution (e.g., the mean and variance of a Gaussian distribution).\n","\n","#### 2. Number of Parameters:\n","* `nu_params` determines how many values are predicted for each time step in the output sequence.\n","* For deterministic models, `nr_params` is usually `1` (one predicted value per time step).\n","* For probabilistic models, `nr_params` might `2` or more, depending on the type of distribution being modeled (e.g., `2` for a Gaussian distibution with mean and variance).\n","\n","### Example in the Context of TCN\n","In the `TCNModule`:\n","* `nr_params` is used to define the number of output parameters per time step.\n","* The model's output dimension is influenced by this parameter to accommodate the number of parameters being predicted for each time step.\n","\n","### Code Snippet for Context\n","Here is how `nr_params` might be used in the `TCNModule`:\n","```python\n","class _TCNModule(PLPastCovariatesModule):\n","    def __init__(\n","        self,\n","        input_size: int,\n","        kernel_size: int,\n","        num_filters: int,\n","        num_layers: Optional[int],\n","        dilation_base: int,\n","        weight_norm: bool,\n","        target_size: int,\n","        nr_params: int,\n","        target_length: int,\n","        dropout: float,\n","        **kwargs,\n","    ):\n","        super().__init__(**kwargs)\n","        self.input_size = input_size\n","        self.n_filters = num_filters\n","        self.kernel_size = kernel_size\n","        self.target_length = target_length\n","        self.target_size = target_size\n","        self.nr_params = nr_params\n","        self.dilation_base = dilation_base\n","\n","        # If num_layers is not passed, compute number of layers needed for full history coverage\n","        if num_layers is None and dilation_base > 1:\n","            num_layers = math.ceil(\n","                math.log(\n","                    (self.input_chunk_length - 1)\n","                    * (dilation_base - 1)\n","                    / (kernel_size - 1)\n","                    / 2\n","                    + 1,\n","                    dilation_base,\n","                )\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        elif num_layers is None:\n","            num_layers = math.ceil(\n","                (self.input_chunk_length - 1) / (kernel_size - 1) / 2\n","            )\n","            logger.info(\"Number of layers chosen: \" + str(num_layers))\n","        self.num_layers = num_layers\n","\n","        # Building TCN module\n","        self.res_blocks_list = []\n","        for i in range(num_layers):\n","            res_block = _ResidualBlock(\n","                num_filters=num_filters,\n","                kernel_size=kernel_size,\n","                dilation_base=dilation_base,\n","                dropout=dropout,\n","                weight_norm=weight_norm,\n","                nr_blocks_below=i,\n","                num_layers=num_layers,\n","                input_size=self.input_size,\n","                target_size=target_size * nr_params,  # Note the use of nr_params here\n","            )\n","            self.res_blocks_list.append(res_block)\n","        self.res_blocks = nn.ModuleList(self.res_blocks_list)\n","\n","    @io_processor\n","    def forward(self, x_in: Tuple):\n","        x, _ = x_in\n","        # data is of size (batch_size, input_chunk_length, input_size)\n","        batch_size = x.size(0)\n","        x = x.transpose(1, 2)\n","\n","        for res_block in self.res_blocks_list:\n","            x = res_block(x)\n","\n","        x = x.transpose(1, 2)\n","        x = x.view(\n","            batch_size, self.input_chunk_length, self.target_size, self.nr_params  # Note the use of nr_params here\n","        )\n","\n","        return x\n","\n","    @property\n","    def first_prediction_index(self) -> int:\n","        return -self.output_chunk_length\n","```\n","\n","### Summary\n","THe `nr_parms` parameter determines how many values the model outputs for each time step. It is particularly relevant for probabilistic models where each time step prediction may involve multiple parameters to describe a probability distribution. This parameter ensures that the output dimensions are set correctly to accommodate the number of predicted parameters per time step.\n"],"metadata":{"id":"8Cu12xoCFVSW"}},{"cell_type":"code","source":[],"metadata":{"id":"mKRISO7nfbPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Example result by using `nr_params`\n","\n","Let's explore an example where `nr_params` is used in both deterministic and probabilistic forecasting contexts.\n","\n","### Deterministic Forecasting Example\n","In deterministic forecasting, each time step output corresponds to a single predicted vale.\n","\n","#### Example:\n","* **nr_params = 1**\n","* Input sequence length: 24\n","* Output sequence length: 12\n","* Output for each time step: 1 predicted vale\n","\n","#### Result:\n","For a single batch (assuming **batch_size = 32**), the model output shape would be:\n","\n","$$ Output Shape = (32, 12, 1) $$\n","\n","Each batch contains 32 sequences, each sequence predicts 12 future time steps, and each time step has a single predicted value.\n","\n","### Probabilistic Forecasting Example\n","In probabilistic forecasting, each time step output corresponds to multiple predicted values, such as the parameters of a probability distribution (e.g., mean and variance for a Gaussian distribution).\n","\n","#### Example:\n","* **nr_params = 2** (e.g., mean and variance for a Gaussian distribution)\n","* Input sequence length: 24\n","* Output sequence length: 12\n","* Output for each time step: 2 predicted values (mean and variance)\n","\n","#### Result:\n","For a single batch (assuming **batch_size = 32**), the model output shape would be:\n","\n","$$ Output Shape = (32, 12, 2) $$\n","\n","Each batch contains 32 sequences, each sequence predicts 12 future time steps, and each time step has two predicted values (mean and variance).\n","\n","### Example Code Snippet\n"],"metadata":{"id":"CeC5f6fGJDFP"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Dummy data\n","batch_size = 32\n","input_chunk_length = 24\n","output_chunk_length = 12\n","input_size = 10  # Number of features\n","num_samples = 100\n","\n","# Generating random data\n","X = torch.randn(num_samples, input_chunk_length, input_size)\n","y = torch.randn(num_samples, output_chunk_length, 1)\n","\n","# Create a DataLoader\n","dataset = TensorDataset(X, y)\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","for batch_x, batch_y in loader:\n","    print(f\"Batch X Shape: {batch_x.shape}\")\n","    print(f\"Batch Y Shape: {batch_y.shape}\")\n","    break"],"metadata":{"id":"5r0E5UjNfbK3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722053672349,"user_tz":-540,"elapsed":334,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"1bf9d7f3-f6d1-435c-8d9d-e2aabce406c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch X Shape: torch.Size([32, 24, 10])\n","Batch Y Shape: torch.Size([32, 12, 1])\n"]}]},{"cell_type":"code","source":["# Define a simple TCN model\n","class SimpleTCN(nn.Module):\n","    def __init__(self, input_size, output_chunk_length, num_layers, num_filters, kernel_size, dilation_base, nr_params):\n","        super(SimpleTCN, self).__init__()\n","        self.num_layers = num_layers\n","        self.nr_params = nr_params\n","        self.output_chunk_length = output_chunk_length\n","\n","        self.res_blocks = nn.ModuleList([\n","            nn.Conv1d(\n","                in_channels=input_size if i == 0 else num_filters,\n","                out_channels=num_filters,\n","                kernel_size=kernel_size,\n","                dilation=dilation_base ** i,\n","                padding=(dilation_base ** i) * (kernel_size - 1) // 2\n","            ) for i in range(num_layers)\n","        ])\n","\n","        self.final_layer = nn.Conv1d(num_filters, nr_params, kernel_size=1)\n","\n","    def forward(self, x):\n","        x = x.transpose(1, 2)  # Change to (batch_size, input_size, input_chunk_length)\n","        for layer in self.res_blocks:\n","            x = F.relu(layer(x))\n","        x = self.final_layer(x)\n","        x = x.transpose(1, 2)  # Change back to (batch_size, input_chunk_length, nr_params)\n","\n","        # Slice the last output_chunk_length steps\n","        x = x[:, -self.output_chunk_length:, :]  # (batch_size, output_chunk_length, nr_params)\n","\n","        return x"],"metadata":{"id":"_qSOfyklfbCK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example with deterministic forecasting (nr_params = 1)\n","nr_params = 1\n","model = SimpleTCN(input_size, output_chunk_length, num_layers=3, num_filters=16, kernel_size=3, dilation_base=2, nr_params=nr_params)\n","\n","for batch_x, batch_y in loader:\n","    output = model(batch_x)\n","    print(f\"Deterministic Output Shape: {output.shape}\")\n","    # Expected shape: (batch_size, output_chunk_length, nr_params)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lE3iyhnlNAwD","executionInfo":{"status":"ok","timestamp":1722053987644,"user_tz":-540,"elapsed":289,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"7dbe0adc-3018-4923-9c1d-49597413b397"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deterministic Output Shape: torch.Size([32, 12, 1])\n"]}]},{"cell_type":"code","source":["# Example with probabilistic forecasting (nr_params = 2)\n","nr_params = 2\n","model = SimpleTCN(input_size, output_chunk_length, num_layers=3, num_filters=16, kernel_size=3, dilation_base=2, nr_params=nr_params)\n","\n","for batch_x, batch_y in loader:\n","    output = model(batch_x)\n","    print(f\"Probabilistic Output Shape: {output.shape}\")\n","    # Expected shape: (batch_size, output_chunk_length, nr_params)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6k11_RQZNAsC","executionInfo":{"status":"ok","timestamp":1722053994245,"user_tz":-540,"elapsed":307,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"e5d08899-be5c-4818-fc63-d79637a22dfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilistic Output Shape: torch.Size([32, 12, 2])\n"]}]},{"cell_type":"markdown","source":["#### Explanation:\n","1. **Model Definition**:\n","    * **self.final_layer** is defined to output **nr_params** channels.\n","2. **Forward Pass**:\n","    * The input tensor is transposed for the convolutional layers.\n","    * After passing through the residual blocks and the final layer, the tensor is transposed back.\n","    * The output tensor is sliced to select the last **output_chunk_length** steps, ensuring the shape is **(batch_size, output_chunk_length, nr_params)**.\n","\n","#### Expected Results:\n","1. **Deterministic Forecasting**:\n","    * **output_chunk_length = 12**\n","    * **nr_params = 1**\n","    * Expected output shape: **[32, 12, 1]**\n","\n","2. **Probabilistic Forecasting**:\n","    * **output_chunk_length = 12**\n","    * **nr_params = 2**\n","    * Expected output shape: **[32, 12, 2]**\n"],"metadata":{"id":"dlbo4kZyIpxd"}},{"cell_type":"code","source":[],"metadata":{"id":"aREgQ32MNAoI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### about `x_in` parameter in forward()\n","\n","### Context of `x_in`\n","In the Darts library, the **forward** method of a PyTorch module is where the input data passes through the network layers to produce the output. In the **class _TCNModule**, the **forward** method looks like this:\n","```python\n","@io_processor\n","def forward(self, x_in: Tuple):\n","    x, _ = x_in\n","    # data is of size (batch_size, input_chunk_length, input_size)\n","    batch_size = x.size(0)\n","    x = x.transpose(1, 2)\n","\n","    for res_block in self.res_blocks_list:\n","        x = res_block(x)\n","\n","    x = x.transpose(1, 2)\n","    x = x.view(\n","        batch_size, self.input_chunk_length, self.target_size, self.nr_params\n","    )\n","\n","    return x\n","```\n","\n","### Structure of `x_in`\n","The **x_in**paramter is a tuple, which typically contains multiple elements. In this specific case:\n","* **x_in** contains **(x, some_other_value)**.\n","* **x** is the primary input tensor.\n","* **some_other_value** can be additional information required for processing, such as past covariates, future covariates, or any other relevant data. However, in this context, is is not used directly in the forward pass.\n","\n","### Why Use a Tuple?\n","#### 1. Multiple Inputs:\n","* Time series forecasting models often require multiple inputs. For example, a model might need past covariates along with the target series.\n","* Using a tuple allows passing multiple inputs conveniently.\n","\n","#### 2. Flexibility:\n","* By structuring inputs as a tuple, the forward method can easily handle and extend to different types of inputs without changing the method signature.\n","* This is particularly useful in frameworks like Darts, which aim to provide flexible and reusable model components.\n","\n","### Extracting the First Value\n","In the **forward** method, only the first value of the tuple (**x**) is used:\n","```python\n","x, _ = x_in\n","```\n","\n","### Reason for Using Only the First Value\n","#### 1. Primary Input:\n","* The primary input tensor **x** is the main data that the model processes to produce predictions.\n","* In this cotext, **x** contains the historical time series data that the TCN uses to make forecasts.\n","\n","#### 2. Ignoring Additional Inputs:\n","* The underscore **_** is a convention in Python indicating that the additional value is not used.\n","* This approach keeps the method signature flexible, allowing for potential future use of the second value if needed without altering the interface.\n","\n","### Example of `x_in` Cntents\n","Assume we have:\n","* **batch_size = 32**\n","* **input_chunk_length = 24**\n","* **input_size = 10**\n","\n","Then, **x** might be a tensor of shape **(32, 24, 10)** representing the input data.\n","\n","```python\n","x_in = (torch.randn(32, 24, 10), some_other_value)\n","```\n","\n","### Practical Explanation\n","* The **forward** method extracts **x** from **x_in** and processes it through the TCN layers.\n","* The second value (**some_other_value**) is present but not used in this specific implementation.\n","\n","### Summary\n","The **x_in** parameter in the **forward** method Of **class _TCNModule** is a tuple to allow multiple inputs, providing flexibility and scalability in handling different types of data. The primary input tensor **x** is extracted and used for the forward pass, while the second value is ignored in this context but provides a placeholder for additional data if needed in the future. This design pattern helps keep the model interface clean and adaptable.\n"],"metadata":{"id":"rqZ6p6VIcXUD"}},{"cell_type":"code","source":[],"metadata":{"id":"kYgNn8OMNAkJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### the role of `def first_prediction_index()`\n","The `firtst_prediction_index` function in the `class _TCNModule` plays an important role in determining where the predictions start in the output sequence.\n","\n","### Context of `first_prediciton_index`\n","In time series forecasting, especially with sequence models like TCNs, it is crucial to know from which point in the output sequence the model's predictions are considered valid.\n","\n","### Function Definition\n","```python\n","def first_prediction_index(self) -> int:\n","    return -self.output_chunk_length\n","```\n","\n","### Explanation\n","#### 1. Output Sequence Length:\n","* **self.output_chunk_length** is the length of the output sequence that the model predicts at each forward pass.\n","* For instance, if **outout_chunk_length = 12**, the model is predicting 12 future time steps for each input sequence.\n","\n","#### 2. Negative Indexing:\n","* The function returns **-self.output_chunk_length**, which is the negative value of the output chunk length.\n","* In Python, negative indexing is used to count from the end of a list or sequence.\n","* **-self.output_chunk_length** essentially points to the start of the valid prediction window within the output sequence.\n","\n","### Role in Time Series Forecasting\n","#### 1. Valid Prediction Start:\n","* The **first_prediction_index** function tells the system where the valid predictions start in the output sequence.\n","* This is useful for aligning the model's predictions with the actual time steps in the input sequence.\n","#### 2. Prediction Alignment:\n","* When the model makes a prediction, the output sequence might contain some values that are not immediately part of the valid prediction window.\n","* By returning **-self.output_chunk_length**, the function ensures that only the last **output_chunk_length** values in the output sequence are considered as valid predictions.\n","#### 3. Model Integration:\n","* This function can be used by other parts of the model or the forecasting framework to correctly align the predictions with the actual future time steps.\n","* It helps in slicing the output tensor to retrieve the valid predicted values, ignoring any padding or intial sequence values that are not part of the forecast.\n","\n","### Practical Example\n","Assume **output_chunk_length = 12**. The function **first_prediction_index** will return **-12**.\n","\n","* If the model's output sequence (before slicing) looks like **[... some initial values ..., valid_prediction]**, the valid predictions start from index **-12**.\n","* This ensures that only the last 12 values are considered for the final forecast.\n","\n","### Conclusion\n","The **first_prediction_index** function is crucial for aligning and validating the model's predictions in time series forecasting. It helps in determining the starting point of the valid predictions within the output sequence, ensuring that the predictions correspond accurately to the intended future time steps. This alignment is essential for the correct interpretation and utilization of the model's forecasts."],"metadata":{"id":"g928nViEorjW"}},{"cell_type":"code","source":[],"metadata":{"id":"Q-zL1JVyNAey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9sg67xMrNAVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VNIlzvhAfZ7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rH4LtaanTF5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What is `Past Covariates`\n","\n","Dartsでは、特徴量を`past_covariates`という引数に別に渡して、モデルを構築するので、Dartsの**PLPastCovariatesModule**を継承している。\n","\n","In the context of time series forecasting and models like the Temporal Convolutional Network (TCN), \"past covariates\" refer to additional time-dependent variables (or features) that are available for the same time periods as the target time series and can be used to improve the accuracy of the forecast.\n","\n","### Understanding Covariates\n","Covariates are additional variables that provide context or supplementary information about the target variable you are trying to forecast. They can be classified into two main types:\n","\n","1. **Past Covariates**: Histrical values of variables that are known for the same time period as the target series.\n","2. **Future Covariates**: Known future values of variables that can be used to predict the target variable.\n","\n","### Example of Past Covariates\n","Consider a time series forecasting problem where the target variable is the sales of a product. Past covariates could include:\n","\n","* Historical weather data (e.g., temperature, humidity) if weather impacts sales.\n","* Historical promotional activities (e.g., discounts, advertising).\n","* Historical economic indicators (e.g., consumer confidence index).\n","* Other related time series (e.g., sales of related products).\n","\n","### Why Use Past Covariates?\n","1. **Improved Forecasting Accuracy**: By incorporating relevalt past covariates, the model can capture more complex patterns and relationships in the data, leading to better forecasts.\n","2. **Contextual Information**: Covariates provide additional context that can help the model understand the factors driving the target variable's behavior.\n","3. **Captureing External Influences**: Covariates can capture external influences that directly or indirectly affects the target variable.\n","\n","### Incorporating Past Covariates in a Model\n","In models like the TCN, past covariates are included as additional input features. The model processes both the target time series and the past covariates to generate forecasts.\n","\n","#### Example in Darts\n","Here's an example of how past covariates can be used with a TCN model in the Darts library:\n"],"metadata":{"id":"dKAfxMaYQ5Kx"}},{"cell_type":"code","source":["!pip install darts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"w-HnNLXMVI7V","executionInfo":{"status":"ok","timestamp":1721649985139,"user_tz":-540,"elapsed":89566,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"1059b177-fced-4823-cbe0-891e525e42fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting darts\n","  Downloading darts-0.30.0-py3-none-any.whl (917 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.3/917.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from darts) (0.53)\n","Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from darts) (1.4.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from darts) (3.7.1)\n","Collecting nfoursid>=1.0.0 (from darts)\n","  Downloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from darts) (1.25.2)\n","Collecting pmdarima>=1.8.0 (from darts)\n","  Downloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyod>=0.9.5 (from darts)\n","  Downloading pyod-2.0.1.tar.gz (163 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.31.0)\n","Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from darts) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from darts) (1.11.4)\n","Collecting shap>=0.40.0 (from darts)\n","  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting statsforecast>=1.4 (from darts)\n","  Downloading statsforecast-1.7.6-py3-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from darts) (0.14.2)\n","Collecting tbats>=1.1.0 (from darts)\n","  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.10/dist-packages (from darts) (4.66.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from darts) (4.12.2)\n","Requirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2023.7.0)\n","Requirement already satisfied: xgboost>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.0.3)\n","Collecting pytorch-lightning>=1.5.0 (from darts)\n","  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboardX>=2.1 (from darts)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.3.1+cu121)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from darts) (2.0.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from holidays>=0.11.1->darts) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->darts) (3.1.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->darts) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->darts) (2024.1)\n","Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts) (3.0.10)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts) (2.0.7)\n","Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=1.8.0->darts) (67.7.2)\n","Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod>=0.9.5->darts) (0.58.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.5.0->darts) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts)\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.5.0->darts)\n","  Downloading lightning_utilities-0.11.5-py3-none-any.whl (26 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (2024.7.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->darts) (3.5.0)\n","Collecting slicer==0.0.8 (from shap>=0.40.0->darts)\n","  Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.40.0->darts) (2.2.1)\n","Collecting coreforecast>=0.0.12 (from statsforecast>=1.4->darts)\n","  Downloading coreforecast-0.0.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n","  Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts)\n","  Downloading utilsforecast-0.2.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.14.0->darts) (0.5.6)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.1->darts) (3.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->darts)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->darts)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->darts)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->darts)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->darts) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->darts)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (3.9.5)\n","Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n","  Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n","  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.14.0->darts) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->darts) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->darts) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (4.0.3)\n","Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (14.0.2)\n","Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n","  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Building wheels for collected packages: pyod\n","  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyod: filename=pyod-2.0.1-py3-none-any.whl size=193267 sha256=d9f055713839db1312ea3b0231ca7b4367560b6b944befbd1df12f1449efedbc\n","  Stored in directory: /root/.cache/pip/wheels/94/75/88/b853cf33b0053b0a001dca55b74d515048b7656e736364eb57\n","Successfully built pyod\n","Installing collected packages: appdirs, tensorboardX, slicer, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, fs, coreforecast, nvidia-cusparse-cu12, nvidia-cudnn-cu12, utilsforecast, triad, shap, pyod, nvidia-cusolver-cu12, nfoursid, pmdarima, adagio, torchmetrics, tbats, fugue, statsforecast, pytorch-lightning, darts\n","Successfully installed adagio-0.2.4 appdirs-1.4.4 coreforecast-0.0.12 darts-0.30.0 fs-2.4.16 fugue-0.9.1 lightning-utilities-0.11.5 nfoursid-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pmdarima-2.0.4 pyod-2.0.1 pytorch-lightning-2.3.3 shap-0.46.0 slicer-0.0.8 statsforecast-1.7.6 tbats-1.1.3 tensorboardX-2.6.2.2 torchmetrics-1.4.0.post0 triad-0.9.8 utilsforecast-0.2.0\n"]}]},{"cell_type":"code","source":["from darts.models import TCNModel\n","from darts.datasets import AirPassengersDataset\n","from darts.utils.timeseries_generation import datetime_attribute_timeseries\n","from darts import TimeSeries\n","import matplotlib.pyplot as plt\n","\n","# Load the target time series (e.g., monthly air passengers data)\n","series = AirPassengersDataset().load()\n","\n","# Generate a past covariate (e.g., month of the year as a cyclic feature)\n","covariates = datetime_attribute_timeseries(\n","    series.time_index, attribute=\"month\", cyclic=True, one_hot=False\n",")\n","\n","# Create the TCN model\n","model = TCNModel(\n","    input_chunk_length=24,\n","    output_chunk_length=12,\n","    kernel_size=3,\n","    num_filters=16,\n","    num_layers=3,\n","    dropout=0.2,\n","    weight_norm=True,\n","    random_state=42\n",")\n","\n","# Split the data into training and validation sets\n","train_series = series[:-36]\n","val_series = series[-36:]\n","\n","# Ensure covariates cover the required range for training and prediction\n","train_covariates = covariates[:len(train_series)]\n","val_covariates = covariates[-(len(val_series) + model.output_chunk_length):]\n","\n","# Fit the model with the past covariates\n","model.fit(train_series, past_covariates=train_covariates)\n","\n","# Make predictions\n","pred_series = model.predict(n=12, series=train_series, past_covariates=covariates)\n","\n","# Plot the results\n","series.plot(label='True Series')\n","pred_series.plot(label='Predictions', linestyle='dashed')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"yw5zsEUzd9MS","colab":{"base_uri":"https://localhost:8080/","height":945,"referenced_widgets":["a85b0d7995064bccb0b2fd8f5d050893","a7b0afdb1c56464f8ced26d04bf17164","6fcea5613ccf4d00a53583a21ae1ab54","3508a57a26d84e43ad9331d82b4b5f5a","599ea2d5aa6246be852c858ebf956c86","83366902c10345fc8007962902704e30","f25aed20b6ea47ec882a861e0d29cf39","e23bbea8fa2e4b23b76d9763ca33285e","4c3a8d2f40bc4ceeb9648f78c891f717","5fd859e93cd0488ea9a993c7c47303d0","8a722b5b74f34fddbd2696230e97f473","bff48165bddd4642ad454fe9cd062b61","3d3c0d56603f49efaee30799bb873d4d","fc0a721835fe434080ba1c77d4f7d156","936b0f3cc9244283b1ff546c43f4b748","60be8436c67d4164a61c7c1a308f0f00","732c13424d46447d98e95e60e3aa281a","868ac47e4ac94edbb05f2adbd3a41143","443ace0ada534273ab4bffe41c7c829e","2b6414b10d2f4cfeb8333d5deca5f041","e97df36f32614efe91ae8526a5e3df1a","b80fd885362f4567826b421c16312f2d"]},"executionInfo":{"status":"ok","timestamp":1721650611012,"user_tz":-540,"elapsed":14231,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"009dd0ef-4e03-445e-905e-32a36d4d8232"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n","  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name            | Type             | Params | Mode \n","-------------------------------------------------------------\n","0 | criterion       | MSELoss          | 0      | train\n","1 | train_criterion | MSELoss          | 0      | train\n","2 | val_criterion   | MSELoss          | 0      | train\n","3 | train_metrics   | MetricCollection | 0      | train\n","4 | val_metrics     | MetricCollection | 0      | train\n","5 | res_blocks      | ModuleList       | 3.5 K  | train\n","-------------------------------------------------------------\n","3.5 K     Trainable params\n","0         Non-trainable params\n","3.5 K     Total params\n","0.014     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a85b0d7995064bccb0b2fd8f5d050893"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff48165bddd4642ad454fe9cd062b61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["#### Explanation:\n","\n","1. **Load Data**: Load the target time series (e.g., monthly air passengers data).\n","2. **Generate Past Covariates**: Create a time series of past covariates (e.g., month of the year as a cyclic feature).\n","3. **Create Model**: Initialize the TCN model with specified hyperparameters.\n","4. **Train-Validation Split**: Split the data into training and validation sets.\n","5. **Fit Model**: Train the model using the target series and the past covariates.\n","6. **Make Predictions**: Generate forecasts using the trained model and past covariates.\n","\n","#### Summary\n","\n","- **Past Covariates**: Additional historical time-dependent variables that provide supplementary information about the target series.\n","- **Purpose**: Improve forecasting accuracy by capturing more complex patterns and relationships.\n","- **Implementation**: Incorporated as additional input features in the model, processed along with the target series to generate forecasts.\n","\n","Using past covariates effectively can significantly enhance the performance of time series forecasting models. If you have any further questions or need more details, feel free to ask!"],"metadata":{"id":"KYOyiuuYWXSj"}},{"cell_type":"markdown","source":["※ 上記、Dartsでの追加特徴量コードのpytorch版は、以下のnotebook参照\n","\n","* difference_of _dealing_with_features_in_Darts.ipynb"],"metadata":{"id":"AKjOeCkEfurv"}},{"cell_type":"code","source":[],"metadata":{"id":"tl1OagwVWGef"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ３. TCNModel class"],"metadata":{"id":"oEDnpkcm8Kmq"}},{"cell_type":"markdown","source":["# ※※※ここから"],"metadata":{"id":"sHPa0KVA8XXc"}},{"cell_type":"code","source":[],"metadata":{"id":"okrIpcdH8KYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YTaEV2jI8KU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tPwmjO4e8KQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1-E9o7HR8KMr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gqQC_ALV8KHz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3GQ8wwtH8J_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"knLnyw7HZQqP"},"execution_count":null,"outputs":[]}]}