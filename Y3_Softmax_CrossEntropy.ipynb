{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1V3m11ALtPcOFpBaTSrFvUNzsvIkaUiRG","authorship_tag":"ABX9TyMgicaypqR/Laeht6z/TJWA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# SoftmaxとCross Entropyについて学ぶ\n","* https://www.youtube.com/watch?v=7q7E91pHoW4&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=11"],"metadata":{"id":"e134Dt28YLpZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5p-d2gbNYFqR"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"code","source":["def softmax(x):\n","  return np.exp(x) / np.sum(np.exp(x), axis=0)\n","\n","x = np.array([2.0, 1.0, 0.1])\n","outputs = softmax(x)\n","print('softmax numpy: ', outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PR-fHncgYLME","executionInfo":{"status":"ok","timestamp":1709977279090,"user_tz":-540,"elapsed":10,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"de48f457-910a-48f5-ec50-a048b57f151e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["softmax numpy:  [0.65900114 0.24243297 0.09856589]\n"]}]},{"cell_type":"code","source":["x = torch.tensor([2.0, 1.0, 0.1])\n","outputs = torch.softmax(x, dim=0)\n","print(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHX-H8vqYK81","executionInfo":{"status":"ok","timestamp":1709977371897,"user_tz":-540,"elapsed":14,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"f9d48f21-8b5d-44fd-ba37-99dee1e0444d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.6590, 0.2424, 0.0986])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cMRhnnISYK49"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["v = torch.tensor(np.array([[1.,3.,6.]]))\n","print(v)\n","m = nn.Softmax(dim=1)\n","s = m(v)\n","print(s)"],"metadata":{"id":"YhVw_MUspiPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["v = torch.tensor(np.array([[-1.,-3.,-6.]]))\n","print(v)\n","m = nn.Softmax(dim=1)\n","s = m(v)\n","print(s)"],"metadata":{"id":"46O-n1fYpiLx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b42caj_RpiIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZXTrI7r_piFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cross_entropy(actual, predicted):\n","  loss = -np.sum(actual * np.log(predicted))\n","  return loss # / float(predicted.shape[0])\n","\n","# y must be one hot encoded\n","# if class 0: [1 0 0]\n","# if class 1: [0 1 0]\n","# if class 2: [0 0 1]\n","Y = np.array([1, 0 ,0])\n","\n","# y_pred has probabilities\n","Y_pred_good = np.array([0.7, 0.2, 0.1])\n","Y_pred_bad = np.array([0.1, 0.3, 0.6])\n","l1 = cross_entropy(Y, Y_pred_good)\n","l2 = cross_entropy(Y, Y_pred_bad)\n","print(f'loss1 numpy: {l1:.4f}')\n","print(f'loss2 numpy: {l2:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haWo0Xk2YK0l","executionInfo":{"status":"ok","timestamp":1709977872316,"user_tz":-540,"elapsed":636,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"2dd16f24-0ae5-40be-d145-f0cb0f5f40d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss1 numpy: 0.3567\n","loss2 numpy: 2.3026\n"]}]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","\n","Y = torch.tensor([0])\n","# nsamples * nclasses = 1*3\n","Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n","Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n","\n","l1 = loss(Y_pred_good, Y)\n","l2 = loss(Y_pred_bad, Y)\n","\n","print(l1.item())\n","print(l2.item())\n","\n","_, predictions1 = torch.max(Y_pred_good, 1)\n","_, predictions2 = torch.max(Y_pred_bad, 1)\n","print(predictions1)\n","print(predictions2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnpEimZYYKwa","executionInfo":{"status":"ok","timestamp":1709978538898,"user_tz":-540,"elapsed":602,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"0def6973-4e87-4442-ad66-575e02b459db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.4170299470424652\n","1.840616226196289\n","tensor([0])\n","tensor([1])\n"]}]},{"cell_type":"code","source":["# 3 samples !!!!\n","\n","loss = nn.CrossEntropyLoss()\n","\n","# 3 samples\n","Y = torch.tensor([2, 0, 1])\n","\n","# nsamples * nclasses = 3*3\n","Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n","Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n","\n","l1 = loss(Y_pred_good, Y)\n","l2 = loss(Y_pred_bad, Y)\n","\n","print(l1.item())\n","print(l2.item())\n","\n","_, predictions1 = torch.max(Y_pred_good, 1)\n","_, predictions2 = torch.max(Y_pred_bad, 1)\n","print(predictions1)\n","print(predictions2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bY33LW6YKsJ","executionInfo":{"status":"ok","timestamp":1709978773528,"user_tz":-540,"elapsed":481,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"eab0274b-9e33-4101-e9f9-3a30ca91448c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3018244206905365\n","1.6241613626480103\n","tensor([2, 0, 1])\n","tensor([0, 2, 1])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2-r1RDQaYKnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Multiclass problem (Softmaxの例)\n","class NeuralNet2(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_classes):\n","    self.linear1 = nn.Linear(input_size, hidden_size)\n","    self.relu = nn.ReLU()\n","    self.linear2 = nn.Linear(hidden_size, num_classes)\n","\n","  def forward(self, x):\n","    out = self.linear1(x)\n","    out = self.relu(out)\n","    out = self.linear2(out)\n","    # no softmax at the end\n","    return out\n","\n","model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n","criterion = nn.CrossEntropyLoss() # (applies Softmsx)"],"metadata":{"id":"oXj2AS1TuSh2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Binary classification (Sigmoidの例)\n","class NeuralNet1(nn.Module):\n","  def __init__(self, input_size, hidden_size):\n","    super(NeuralNet1, self).__init__()\n","    self.linear1 = nn.Linear(input_size, hidden_size)\n","    self.relu = nn.ReLU()\n","    self.linear2 = nn.Linear(hidden_size, 1)\n","\n","  def forward(self, x):\n","    out = self.linear1(x)\n","    out = self.relu(out)\n","    out = self.linear2(out)\n","    # sigmoid at the end\n","    y_pred = torch.sigmoid(out)\n","    return y_pred\n","\n","model = NeuralNet1(input_size=28*28, hidden_size=5)\n","criterion = nn.BCELoss() # Binary class Entropy Loss"],"metadata":{"id":"jNLlmO_TuXk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vDuI-RkpuXas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XIJpbY5EYKhJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6CYBwCCGYKdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wHJUJhPPYKac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4rTtECorYKWI"},"execution_count":null,"outputs":[]}]}