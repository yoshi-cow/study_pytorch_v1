{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPbULu41ThUdqjmbaMeoDgL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["* another notebook explain the early stopping more in detail\n","    * check \"pytorch_youtube\" -> **01_Early_Stopping.ipynb**"],"metadata":{"id":"u9uByeKqZDHx"}},{"cell_type":"markdown","source":["# Early Stopping during Learning\n","Early stopping is a form of regularization used to avoid overfitting when training a machine learning model. It works by monitoring the model's performance on a validation dataset and stopping the training process if the model's performance ceases to improve after a certain number of epochs. this technique not only helps in preventing overfitting but also can save computational resources by stopping the training early if further training does not lead to better results.\n"],"metadata":{"id":"TzKgKtXnp9H4"}},{"cell_type":"markdown","source":["## Implementing Early Stopping in PyTorch\n","PyTorch doesn't have built-in early stopping support like some other libraries (e.g., Keras), but it can be impleneted easily with a few lines of custom code. Here's a basic outline of how you can implenet early stopping:\n","\n","1. **Monitor a performance metric** on a validation set.\n","2. **Stop training** if this metirc does not improve for a set number of epochs.\n","3. Optionally, **restore the weights** from when the validation loss was at its minimum.\n","\n","Here's how you could implenet this:"],"metadata":{"id":"GvCfss4RqhEE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJcmp39up1yu"},"outputs":[],"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define your model\n","model = nn.Linear(1, 1)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Assuming x_val and y_val are your validation dataset\n","def validate(model, data_loader):\n","    model.eval()  # Set model to evaluation mode\n","    total_loss = 0\n","    with torch.no_grad():  # No need to track gradients\n","        for x_batch, y_batch in data_loader:\n","            y_pred = model(x_batch)\n","            loss = criterion(y_pred, y_batch)\n","            total_loss += loss.item()\n","    return total_loss / len(data_loader)\n","\n","# Training setup\n","num_epochs = 100\n","patience = 10\n","best_loss = np.inf\n","trigger_times = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()  # Set model to training mode\n","    # Training code (forward, loss, backward, step)\n","    # ...\n","\n","    # Validate the model\n","    val_loss = validate(model, val_data_loader)\n","    print(f'Epoch {epoch}, Validation loss: {val_loss}')\n","\n","    # Check if current validation loss is less than the best loss\n","    if val_loss < best_loss:\n","        print(f\"Validation loss decreased {best_loss} -> {val_loss}\")\n","        best_loss = val_loss\n","        best_model_wts = model.state_dict()  # Save the best model weights\n","        trigger_times = 0  # reset trigger times\n","    else:\n","        trigger_times += 1\n","        print(f\"Validation loss did not decrease, count: {trigger_times}\")\n","\n","    # Early stopping condition\n","    if trigger_times >= patience:\n","        print(\"Early stopping!\")\n","        model.load_state_dict(best_model_wts)  # Restore best model weights\n","        break\n","\n","# Further code, e.g., testing or saving the model\n"]},{"cell_type":"markdown","source":["** Key Components of the Early stopping Logic**:\n","* **Validation Loss Calculation**: The current loss is evaluated on the validation dataset after each epoch.\n","* **Loss improvement Check**: the current loss is compared with the best observed loss so far. If it's better, the model weights are saved, and the patience couter reset.\n","* **Patience Counter**: If the validation loss doesn't improve for a given number of consecutive epochs (**patience**), the training stops.\n","* **Model State Restoration**: If early stopping is triggered, the model's weights are restored to the state when it achieved the best validation loss.\n","\n","\n","This approach allows you to integrate early stopping into your training loop, providing control over how long you allow training to continue without improvement and ensuring you keep the best performing model as judged by the validation loss."],"metadata":{"id":"KeXAUITdr16m"}},{"cell_type":"code","source":[],"metadata":{"id":"z-o053dDtSms"},"execution_count":null,"outputs":[]}]}