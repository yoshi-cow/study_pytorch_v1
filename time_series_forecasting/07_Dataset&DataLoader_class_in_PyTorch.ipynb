{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1-s1J7ItCWnmF0auVbdkPI9tCcaW230ka","authorship_tag":"ABX9TyP1Aaka3xrX4tB6BocVqywp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Dataset class in PyTroch"],"metadata":{"id":"2xxP8y9bLyiS"}},{"cell_type":"markdown","source":["The `Dataset` class in PyTorch is a fundamental component for management for managing and utilizing large datasets. It provides a standard way to create iterable datasets and is especially useful when you're dealing with complex data types like time series. When working with time series data, the goal is often to predict future values based on past observations, which requires the data to be sequenced into fixed-length inputs for the model."],"metadata":{"id":"oCejejSAL2LH"}},{"cell_type":"markdown","source":["## Understanding the `Dataset` Class\n","The **Dataset** class is an abstract class in PyTorch, meaning you typically subclass it to implement custom behavior for loading and processing your data. The two primary methods you need to override are:\n","\n","\n","* **__len__(self)**: Return the size of the dataset.\n","* **__getitem__(self, index)**: Retrieves an item at the specific index."],"metadata":{"id":"W2yd-iDbMZ5N"}},{"cell_type":"markdown","source":["## Implementing a Timse Series **`Dataset`**\n","Here's a step-by-step guide on how to subclass **Dataset** for a time series dataset:\n","\n","\n","1. **Define Your Dataset Class**: Extend the **Dataset** class to fit your specific needs, implmenting the required **__len__** and **__getitem__** methods.\n","2. **Prepare Your Data**: For time series data, you usually have sequences of values over time. You'll need to decide how to split theses sequences for training, such as using a sliding window approach to create fixed-length subsequences.\n","3. **Implement __getitem__**: This method should return a single training sample (and possibly a label, for supervised tasks) from your dataset at a specified index. For time series, this might mean <u>returning a sequence of values as your input and the next value in the series as your label</u>.\n","\n","<br><br>\n","Let's look at a concreate example of how you might set up a **Dataset** for a simple univariate time series task, where the goal is to predict the next value based on a sequence of previous values:"],"metadata":{"id":"EnRffr8RNB5N"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZ_bkh_dLtdD","executionInfo":{"status":"ok","timestamp":1712119292078,"user_tz":-540,"elapsed":217,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"4d091514-28e3-44bd-f520-6db51dfcf099"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 5])\n","torch.Size([10])\n","tensor([[-1.6335,  0.3526, -0.3992,  0.2826, -0.7692],\n","        [ 0.3526, -0.3992,  0.2826, -0.7692,  0.8167],\n","        [-0.3992,  0.2826, -0.7692,  0.8167,  0.5386],\n","        [ 0.2826, -0.7692,  0.8167,  0.5386, -0.9178],\n","        [-0.7692,  0.8167,  0.5386, -0.9178,  0.7416],\n","        [ 0.8167,  0.5386, -0.9178,  0.7416, -1.2861],\n","        [ 0.5386, -0.9178,  0.7416, -1.2861, -0.1797],\n","        [-0.9178,  0.7416, -1.2861, -0.1797,  1.1192],\n","        [ 0.7416, -1.2861, -0.1797,  1.1192, -2.5261],\n","        [-1.2861, -0.1797,  1.1192, -2.5261,  0.6301]])\n","tensor([ 0.8167,  0.5386, -0.9178,  0.7416, -1.2861, -0.1797,  1.1192, -2.5261,\n","         0.6301,  1.4682])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-1b3e190d9cbf>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(sequence), torch.tensor(label)\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class TimeSeriesDataset(Dataset):\n","    def __init__(self, sequences, sequence_length):\n","        self.sequences = sequences # dataが入る\n","        self.sequence_length = sequence_length\n","\n","    def __len__(self):\n","        return len(self.sequences) - self.sequence_length\n","\n","    def __getitem__(self, index):\n","        # Fetch a sequence and the next value (label)\n","        sequence = self.sequences[index:index+self.sequence_length]\n","        label = self.sequences[index+self.sequence_length]\n","        return torch.tensor(sequence), torch.tensor(label)\n","\n","# Example usage\n","sequence_length = 5\n","# Assuming `data` is your time series data, a 1D tensor (or numpy array) of sequential values\n","data = torch.randn(100) # Example data\n","\n","dataset = TimeSeriesDataset(data, sequence_length)\n","dataloader = DataLoader(dataset, batch_size=10)\n","\n","for sequence, label in dataloader:\n","    # Each `sequence` is a batch of sequences, and `label` is the next value\n","    print(sequence.shape)\n","    print(label.shape)\n","    print(sequence)\n","    print(label)\n","    break"]},{"cell_type":"code","source":["data[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKI6gJtuQ2ha","executionInfo":{"status":"ok","timestamp":1712119317675,"user_tz":-540,"elapsed":8,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"8887ab9c-66c0-4fdb-f8d2-ac6ee2222af2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-1.6335,  0.3526, -0.3992,  0.2826, -0.7692,  0.8167,  0.5386, -0.9178,\n","         0.7416, -1.2861, -0.1797,  1.1192, -2.5261,  0.6301,  1.4682,  0.4238,\n","        -0.1102, -1.1154, -0.2161,  0.3630])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["In this example, `TimeSeriesDataset` takes a time series andd a sequence length as input. The **__geteitem__** method returns a slice of the time series data of the specified length(**sequence_length**) and the next value in the series as the label. The **DataLoader** can then be used to iterate over the dataset in bathces, which is especailly useful for training neural networks on the data.\n","\n","\n","This approach is quite flexible and can be adapted to various types of time series data and tasks, such as multivariate forecasting, classification, and more, by adjusting how sequences and labels are generated and returned by **__getitem__**."],"metadata":{"id":"n4Q84mNnQ-m0"}},{"cell_type":"markdown","source":["## \\_\\_len__ function\n","\n","\n","**The `__len__` function in PyTorch Datasets**\n","\n","In PyTorch, the `__len__` function plays a crucial role within custom datasets you create using `torch.utils.data.Dataset`. It's a special method inherited from Python's built-in `len()` function and serves the following key purpose:\n","\n","**1. Determines Dataset Length:**\n","\n","- When you use a custom dataset with a DataLoader object (e.g., `data_loader = torch.utils.data.DataLoader(my_dataset, batch_size=32)`), PyTorch calls the `__len__` method on your dataset instance.\n","- The `__len__` method's responsibility is to return an integer value that represents the total number of samples (data points) in your dataset.\n","- This information is essential for the DataLoader to effectively iterate through your dataset during training or evaluation. It allows the DataLoader to:\n","    - Split the dataset into batches of the specified size (provided by the `batch_size` argument).\n","    - Determine the number of iterations required to process the entire dataset.\n","\n","**Example:**"],"metadata":{"id":"y3OAYwwOjT36"}},{"cell_type":"code","source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)  # Assuming 'data' is a list or other iterable\n","\n","# Usage\n","my_dataset = MyDataset(...)\n","data_loader = torch.utils.data.DataLoader(my_dataset, batch_size=64)"],"metadata":{"id":"NKSJMbJPQhA4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this example, the `__len__` method simply returns the length of the `self.data` list, which is assumed to hold your dataset samples.\n","\n","**Key Points to Remember:**\n","\n","- The `__len__` method should be a straightforward implementation that reflects the actual size of your dataset.\n","- For datasets with a finite number of samples, it's typically implemented by returning the length of an underlying list, array, or other iterable containing your data.\n","- If your dataset represents an infinite or dynamically generated data stream, you might need to return a pre-defined large value (e.g., `sys.maxsize`) or implement a custom logic to determine the dataset size on the fly. However, exercise caution in such scenarios, as infinite data streams might not be suitable for all use cases with PyTorch dataloaders.\n","\n","**In essence, the `__len__` function acts as a contract between your custom dataset and PyTorch's DataLoader, enabling efficient data iteration and batching during training and evaluation.**"],"metadata":{"id":"WrM25qiRjnKI"}},{"cell_type":"markdown","source":["### \\_\\_len__ function to DataLoader\n","When creating a PyTorch Dataset class for LSTM sequence data, the `__len__` function needs to consider the way you're structuring your sequences. Here's how you can set it up along with an example:\n","\n","**Understanding Sequence Structure:**\n","\n","There are two common approaches to representing sequence data for LSTMs in PyTorch datasets:\n","\n","1. **Single Sequence per Sample:**\n","   - Each sample in your dataset is a single, complete sequence.\n","   - The `__len__` function simply returns the total number of sequences in your dataset.\n","\n","2. **Sequences as Subsets of a Larger Data Source:**\n","   - You might have a larger data source (e.g., entire file, list of all data points), and your dataset extracts subsequences of a fixed or variable length for training.\n","   - The `__len__` function needs to account for how many subsequences you can create from the data source.\n","\n","**Example Code (Single Sequence per Sample):**"],"metadata":{"id":"BQCb2-IdkEwq"}},{"cell_type":"code","source":["class LSTMSequenceDataset(torch.utils.data.Dataset):\n","    def __init__(self, sequences, labels):\n","        self.sequences = sequences\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        sequence = self.sequences[idx]\n","        label = self.labels[idx]\n","        # Convert sequence and label to tensors (if needed)\n","        return sequence, label"],"metadata":{"id":"64ui1JfukWn-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- This example assumes you have two lists: `sequences` (containing individual sequences) and `labels` (corresponding labels for each sequence).\n","- The `__len__` function returns the length of the `sequences` list, representing the number of samples in the dataset.\n","\n","**Example Code (Sequences as Subsets):**"],"metadata":{"id":"lW_ovdibjpkJ"}},{"cell_type":"code","source":["class LSTMSequenceSubsetDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, sequence_length):\n","        self.data = data\n","        self.sequence_length = sequence_length\n","\n","    def __len__(self):\n","        # Assuming 'data' is a long list (larger than sequence_length)\n","        return (len(self.data) - self.sequence_length) + 1  # Account for all possible subsequences\n","\n","    def __getitem__(self, idx):\n","        sequence = self.data[idx:idx + self.sequence_length]\n","        # Convert sequence to tensor (if needed)\n","        return sequence"],"metadata":{"id":"b5LSlRJikzcZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- This example assumes a larger data source (`data`) from which you extract subsequences of a fixed length (`sequence_length`).\n","- The `__len__` function calculates the maximum number of possible subsequences by subtracting the sequence length from the total data length and adding 1 (to account for the first possible subsequence starting at index 0).\n","\n","**Remember to adapt these examples to your specific data structure and sequence processing logic.**\n","\n","By correctly implementing the `__len__` function, you ensure that your PyTorch DataLoader can efficiently iterate through your LSTM sequence data during training and evaluation."],"metadata":{"id":"Gax2XWnTkqEJ"}},{"cell_type":"markdown","source":["<div class=\"md-recitation\">\n","  Sources\n","  <ol>\n","  <li><a href=\"https://github.com/lfranceschetti/data_science_project\">https://github.com/lfranceschetti/data_science_project</a></li>\n","  </ol>\n","</div>"],"metadata":{"id":"FUMbq4AClFUV"}},{"cell_type":"markdown","source":["# Batch precessing"],"metadata":{"id":"zHitSO5QSHl4"}},{"cell_type":"markdown","source":["In deep learning, the term \"batch processing\" refers to the technique of training a neural network using batches of input data at a time, rather than feeding the entire dataset or single data points into the model at once. This approach offers a balance between the computational efficiency of processing many data points at once and the memory constraints that prevent loading the entire dataset into memory.\n","\n","### Key Points About Batch Processing:\n","\n","- **Batch Size**: This is the number of samples of data processed before the model's internal parameters (weights) are updated. It's a crucial hyperparameter that can affect the performance and efficiency of the learning process. Common batch sizes include 32, 64, 128, etc., though the optimal size can vary depending on the specific task and hardware constraints.\n","\n","- **Types of Batches**:\n","  - **Mini-Batch**: The most common approach, where the dataset is divided into small batches. It combines the advantages of both batch and stochastic gradient descent methods.\n","  - **Full Batch**: The entire dataset is processed at once. This is rarely used in practice due to memory limitations and less efficient training dynamics.\n","  - **Stochastic**: A special case where the batch size is 1, meaning the network is updated after every single sample. It's highly efficient in terms of memory but can lead to a lot of noise in the training process.\n","\n","- **Advantages**:\n","  - **Efficiency**: Batch processing is more computationally efficient than stochastic methods, as it can leverage vectorized operations and parallel processing.\n","  - **Generalization**: By averaging the gradient over a batch, it can smooth out some of the noise in the training data, potentially leading to better generalization.\n","  - **Memory Management**: It allows for training on datasets that are too large to fit into memory all at once.\n","\n","- **Disadvantages**:\n","  - **Memory Requirement**: Larger batch sizes require more memory, which can be a limiting factor on some hardware.\n","  - **Hyperparameter Tuning**: Finding the optimal batch size can be a process of trial and error, as it depends on the specific dataset and model architecture.\n","\n","In practice, selecting the right batch size is a balance between training speed, memory limitations, and the stability of the convergence process. It's often determined empirically, as part of the model tuning process."],"metadata":{"id":"wys6Ar7SSKxa"}},{"cell_type":"code","source":[],"metadata":{"id":"rCzgwskUSKY0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DataLoader class"],"metadata":{"id":"s4vCB1VeSZ_h"}},{"cell_type":"markdown","source":["In PyTorch, the `DataLoader` class is a flexible and efficient way of iterating over a dataset. When you use a `DataLoader` to fetch batches of data, it returns each batch as a tuple containing two main elements: the input data and the labels. These elements are organized into tensors.\n","\n","Here's a breakdown of the output structure you can expect from iterating over a `DataLoader` instance:\n","\n","- **Batch of Input Data**: This is typically a tensor (or a collection of tensors if your dataset returns multiple inputs) that contains a batch of input samples. The shape of this tensor usually follows the pattern `(batch_size, feature_dimensions...)`, where `batch_size` is the number of samples in the batch, and `feature_dimensions...` represents the dimensions of the input features. For example, in the case of images, this might be `(batch_size, channels, height, width)`.\n","\n","- **Batch of Labels**: This is a tensor containing the labels corresponding to each input sample in the batch. The shape of the labels tensor often depends on the type of problem you're working on. For classification tasks, it might be a 1D tensor of size `batch_size`, where each entry is the label index for the corresponding input sample. For regression tasks, it could be a tensor of shape `(batch_size, target_dimensions)` if you're predicting multiple values per sample.\n","\n","Here's a simple example to illustrate how you might use a `DataLoader` in PyTorch:\n","\n","```python\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","\n","# Dummy dataset with 100 samples, each sample is a 10-dimensional vector\n","inputs = torch.randn(100, 10)\n","# Dummy labels, one label per sample\n","labels = torch.randint(0, 2, (100,))\n","\n","# Create a TensorDataset and DataLoader\n","dataset = TensorDataset(inputs, labels)\n","dataloader = DataLoader(dataset, batch_size=20)\n","\n","# Iterate over the DataLoader\n","for batch_idx, (data, target) in enumerate(dataloader):\n","    print(f\"Batch {batch_idx}:\")\n","    print(f\" - Data shape: {data.shape}\")  # Should be torch.Size([20, 10])\n","    print(f\" - Target shape: {target.shape}\")  # Should be torch.Size([20])\n","```\n","\n","In this example, each iteration over the `DataLoader` yields a batch where `data` is a tensor of input samples with shape `(20, 10)` (since we specified `batch_size=20`), and `target` is a tensor of labels with shape `(20,)`.\n","\n","It's also worth noting that `DataLoader` can handle more complex data structures through custom `Dataset` classes, allowing for much flexibility in terms of what each batch can contain (e.g., images, text, additional metadata, etc.)."],"metadata":{"id":"82obOYFmS4nc"}},{"cell_type":"code","source":[],"metadata":{"id":"ZDg_wPq_ScQU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# How to create sequence data in PyTorch"],"metadata":{"id":"0-GmR0JgTJOy"}},{"cell_type":"markdown","source":["The **DataLoader** in PyTorch itself does not automatically create sequences from your data. It is designed to efficiently load and iterate over datasets, handling batching, sampling, shuffling, and multiprocessing seamlessly. However, the resposibility of defining how the data should be structured into sequences falls on the dataset being passed to the **DataLoader**.\n","\n","\n","To work with sequential data, like time series or text, you typically need to preprocess your data into the desired sequence format before feeding it into a **DataLoader**. <u>This involves creating a custom **Dataset** class that takes your raw data and transforms it into sequences of the desired length</u>.\n","\n","\n","Here's a simple outline of how might do this:\n","\n","1. **Define a Custom Dataset**: Subclass **torch.utils.data.Dataset** to create a dataset that returns data in the sequence format you need. This involves implementing the **__init__**, **__len__**, and **__getitem__** methods to handle your data's loading, length reporting, and item acessing, respectively.\n","2. **Preprocess Data into Sequences**: In the **__getitem__ method, <u>you can define logic to convert your data into sequences. For example, if you're working with time series data, you could create sequences of a specific length based on the time steps</u>.\n","3. **Use DataLoader**: Once you have a **Dataset** that outputs data in the correct sequence format, you can pass it to a **DataLoader** to handle batching and further processing like shuffling or parallel loading.\n","\n","\n","Here's a basic example of what this might look like:"],"metadata":{"id":"YB1DjgPuTPty"}},{"cell_type":"code","source":["### 5つの銘柄について過去1週間のシーケンスデータにて5銘柄の翌日の値を予測するためのdataloader\n","\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","\n","class sequenceDataset(Dataset):\n","    def __init__(self, data, sequence_length):\n","        # ここでは、クラスにデータを渡すだけなので、xとyに分ける必要性は無い\n","        # ただし、わかりやすくするためにここで分けても問題ない\n","        self.data = data\n","        self.sequence_length = sequence_length\n","\n","    def __len__(self):\n","        return len(self.data) - self.sequence_length\n","\n","    def __getitem__(self, index):\n","        # 特徴量5の次の値を予測するので、targetの戻り値は次の5特徴量の値になる\n","        # ここで、sequence data を都度作成して返す\n","        return (self.data[index:index+self.sequence_length],\n","                self.data[index+self.sequence_length])\n","\n","# Example usage\n","data = torch.randn(100, 5)  # Example data: 100 samples, each with 5 features\n","sequence_length = 7\n","dataset = sequenceDataset(data, sequence_length)\n","dataloader = DataLoader(dataset, batch_size=20)\n","\n","for batch_idx, (data, target) in enumerate(dataloader):\n","    print(f\"Batch {batch_idx}:\")\n","    print(f\" - Data shape: {data.shape}\")  # Expected to be torch.Size([20, 7, 5])\n","    print(f\" - Target shape: {target.shape}\")  # Expected to be torch.Size([20, 5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qguzyZXWTNnL","executionInfo":{"status":"ok","timestamp":1712122057409,"user_tz":-540,"elapsed":265,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"e915650d-c8f5-43ce-b3fb-0f66f7b2f849"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0:\n"," - Data shape: torch.Size([20, 7, 5])\n"," - Target shape: torch.Size([20, 5])\n","Batch 1:\n"," - Data shape: torch.Size([20, 7, 5])\n"," - Target shape: torch.Size([20, 5])\n","Batch 2:\n"," - Data shape: torch.Size([20, 7, 5])\n"," - Target shape: torch.Size([20, 5])\n","Batch 3:\n"," - Data shape: torch.Size([20, 7, 5])\n"," - Target shape: torch.Size([20, 5])\n","Batch 4:\n"," - Data shape: torch.Size([13, 7, 5])\n"," - Target shape: torch.Size([13, 5])\n"]}]},{"cell_type":"code","source":["target\n","# (batch_size, 5_stock_prices)\n","# この場合は、5つの特徴量(銘柄)の株価を予測する - multi forecasting"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUSdxH7VdGvl","executionInfo":{"status":"ok","timestamp":1712122529749,"user_tz":-540,"elapsed":13,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"a85f818f-a123-4590-8196-887389924283"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.2391,  1.8495, -0.1951,  2.0985,  1.3999],\n","        [ 1.2587, -0.5700, -0.6957,  0.9828, -0.3854],\n","        [-1.1010,  0.3142,  0.3250,  2.0819,  2.0572],\n","        [-1.5021, -0.0376,  1.2581, -0.0857, -0.6342],\n","        [ 0.6008, -0.6819,  0.7142, -1.5600,  0.1330],\n","        [-0.4801, -1.3448,  0.2064,  0.2305,  1.3192],\n","        [-0.7040,  0.1032, -0.6216, -1.4984, -0.4733],\n","        [ 0.7143,  0.9961, -1.5333,  0.1347,  1.6404],\n","        [ 1.1530,  0.7484,  0.2664,  0.9285,  1.4625],\n","        [-0.4010,  0.5652, -1.3499,  1.0218, -1.3819],\n","        [-1.6391,  1.1850, -0.4324, -1.1582, -1.4239],\n","        [ 2.1294,  2.1211,  0.2142, -0.5402, -0.0328],\n","        [-0.1397,  2.2330, -0.3432,  0.9062,  1.4824]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["In this example, `SequenceDataset` is designed to take a dataset of continuous data and generate sequences of a specified length (**sequence_length**). The **DataLoader** then handles these sequences, providing batches of them for training or inference."],"metadata":{"id":"O8HOXtxpbjkE"}},{"cell_type":"markdown","source":["## conclusion of sequencing"],"metadata":{"id":"qgsiJlHfdjw2"}},{"cell_type":"markdown","source":["When modeling with sequence data in PyTorch, especially when using the `Dataset` and `DataLoader` classes for handling your data, you generally need to implement the logic for generating sequences within the `__getitem__()` method of your custom `Dataset` class.\n","\n","The `__getitem__()` method is called by the `DataLoader` for each index requested. By defining how data is transformed into sequences within `__getitem__()`, you ensure that each call retrieves a correctly formatted sequence along with its associated label (if applicable). This setup allows you to dynamically convert your dataset into sequences on-the-fly during the training or inference process, making it a powerful approach for working with sequential data such as time series, sentences, or any ordered sequence of data points.\n","\n","Here's a brief overview of the steps involved:\n","\n","1. **Prepare Your Raw Data**: This could be anything from a series of measurements over time, text data, or any sequential data where the order of data points matters.\n","\n","2. **Define Your Custom Dataset Class**: Subclass `torch.utils.data.Dataset` and implement the `__init__()`, `__len__()`, and `__getitem__()` methods. In `__getitem__()`, you include your logic to transform a portion of your raw data into a sequence.\n","\n","3. **Generate Sequences in `__getitem__()`**: Within this method, slice your raw data into sequences of the desired length based on the index parameter. This is where you decide how to handle the start and end of your dataset, how to pair inputs with labels (if doing supervised learning), and any other preprocessing steps like normalization.\n","\n","4. **Use DataLoader to Fetch Batches**: Pass your custom dataset to a `DataLoader` instance to easily fetch batches of sequences for training or evaluation. The `DataLoader` will handle the details of batching, shuffling (if desired), and parallel data loading.\n","\n","By customizing the `__getitem__()` method, you have full control over how your data is presented to the model, allowing for a wide range of sequence-based tasks to be tackled efficiently."],"metadata":{"id":"jxxu-PNSdtrz"}},{"cell_type":"code","source":[],"metadata":{"id":"mA_jP7X0TlBw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Example2: Dataset and DataLoader for one stock price pridiction by 4 features(week, CPI, GDP, FX)"],"metadata":{"id":"2z71sDYLeqzP"}},{"cell_type":"code","source":["## create dummy data\n","import pandas as pd\n","import numpy as np\n","\n","# Assuming each feature is randomly generated for demonstration\n","np.random.seed(42)  # For reproducibility\n","data = pd.DataFrame({\n","    'Amazon stock price': np.random.rand(100) * 100,  # Dummy stock prices\n","    'week': np.arange(100) % 52,  # Weeks in a year, repeating\n","    'CPI': np.random.rand(100),  # Dummy CPI values\n","    'GDP': np.random.rand(100),  # Dummy GDP values\n","    'FX': np.random.rand(100)  # Dummy FX rates\n","})\n","data.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"HWeuC2qvTlpK","executionInfo":{"status":"ok","timestamp":1712123020326,"user_tz":-540,"elapsed":21,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"2ae6f488-fd68-405b-cf15-6faa123359c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Amazon stock price  week       CPI       GDP        FX\n","0           37.454012     0  0.031429  0.642032  0.051682\n","1           95.071431     1  0.636410  0.084140  0.531355\n","2           73.199394     2  0.314356  0.161629  0.540635"],"text/html":["\n","  <div id=\"df-b3bcf3b6-31fb-4d1d-8ff0-3d3d1ef10373\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Amazon stock price</th>\n","      <th>week</th>\n","      <th>CPI</th>\n","      <th>GDP</th>\n","      <th>FX</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37.454012</td>\n","      <td>0</td>\n","      <td>0.031429</td>\n","      <td>0.642032</td>\n","      <td>0.051682</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>95.071431</td>\n","      <td>1</td>\n","      <td>0.636410</td>\n","      <td>0.084140</td>\n","      <td>0.531355</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>73.199394</td>\n","      <td>2</td>\n","      <td>0.314356</td>\n","      <td>0.161629</td>\n","      <td>0.540635</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3bcf3b6-31fb-4d1d-8ff0-3d3d1ef10373')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b3bcf3b6-31fb-4d1d-8ff0-3d3d1ef10373 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b3bcf3b6-31fb-4d1d-8ff0-3d3d1ef10373');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d286fe94-5a89-48ee-b5ac-6528c75ecd6e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d286fe94-5a89-48ee-b5ac-6528c75ecd6e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d286fe94-5a89-48ee-b5ac-6528c75ecd6e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Amazon stock price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.748941101531926,\n        \"min\": 0.5522117123602399,\n        \"max\": 98.68869366005173,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          6.355835028602364,\n          89.48273504276489,\n          77.22447692966574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 51,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          19,\n          41,\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2931112525150842,\n        \"min\": 0.006952130531190703,\n        \"max\": 0.9856504541106007,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.877339353380981,\n          0.489452760277563,\n          0.6775643618422824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GDP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29342624706090614,\n        \"min\": 0.005061583846218687,\n        \"max\": 0.9900538501042633,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.093981939840869,\n          0.31692200515627766,\n          0.8093611554785136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.293452218636701,\n        \"min\": 0.014393488629755868,\n        \"max\": 0.9905051420006733,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.877472013527053,\n          0.1629344270814297,\n          0.10077800137742665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["## Implement the Custom Dataset Class\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class StockPriceDataset(Dataset):\n","    def __init__(self, dataframe, sequence_length=7):\n","        self.dataframe = dataframe\n","        self.sequence_length = sequence_length\n","\n","        # Normalize your features as needed\n","        # Here, we're skipping normalization for simplicity\n","\n","    def __len__(self):\n","        # Subtracting sequence_length to avoid out-of-bounds\n","        return len(self.dataframe) - self.sequence_length\n","\n","    def __getitem__(self, index):\n","        # Extract the sequence of features\n","        features = self.dataframe[['week', 'CPI', 'GDP', 'FX']].iloc[index:index+self.sequence_length].values\n","        # Traget: Amazon stock price of the next day\n","        target = self.dataframe['Amazon stock price'].iloc[index+self.sequence_length]\n","\n","        return torch.tensor(features, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)"],"metadata":{"id":"jwDVL1SrTlmD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create the dataset\n","sequence_length = 7 # Previous 7 days\n","dataset = StockPriceDataset(data, sequence_length)\n","\n","# Create the DataLoader\n","batch_size = 20\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) # Shuffle for training\n","\n","# Example of iterating over the DataLoader\n","for features, target in dataloader:\n","    print(f\"Features shape: {features.shape}\")\n","    print(f\"Target shape: {target.shape}\")\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnPbGgY3Tlix","executionInfo":{"status":"ok","timestamp":1712123741696,"user_tz":-540,"elapsed":15,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"c3dae833-8f09-46c9-f61f-271d0b52b732"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Features shape: torch.Size([20, 7, 4])\n","Target shape: torch.Size([20])\n","\n","Features shape: torch.Size([20, 7, 4])\n","Target shape: torch.Size([20])\n","\n","Features shape: torch.Size([20, 7, 4])\n","Target shape: torch.Size([20])\n","\n","Features shape: torch.Size([20, 7, 4])\n","Target shape: torch.Size([20])\n","\n","Features shape: torch.Size([13, 7, 4])\n","Target shape: torch.Size([13])\n","\n"]}]},{"cell_type":"markdown","source":["In this setup, **features** for each batch will have a shape of **[batch_size, sequence_length, num_features]** (num_features=4 in this case, as 'week', 'CPI', 'GDP', 'FX' are used for prediction), and **target** will have a shape of **[batch_size]**, representing the Amazon stock price you're trying to predict for each sequence.\n","\n","\n","This framework gives you a starting point for developing a model to forecast stock prices based on the past 7 days of data for the given features. Remenber to adjust the normalization and data preprocessing steps according to your specific needs."],"metadata":{"id":"QoXGZsrWiH8h"}},{"cell_type":"code","source":[],"metadata":{"id":"dKCfs60R4NbR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create batch shape by DataLoader"],"metadata":{"id":"F4Q4zNRM4Nvn"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","np.random.seed(42)  # For reproducibility\n","\n","# Generate a DataFrame with datetime information\n","num_hours = 365 * 24  # A year's worth of hourly data\n","date_rng = pd.date_range(start='1/1/2020', end='31/12/2020', freq='H')\n","df = pd.DataFrame(date_rng, columns=['date'])\n","df['weekday'] = df['date'].dt.weekday\n","df['hour'] = df['date'].dt.hour\n","df['season'] = df['date'].dt.month % 12 // 3 + 1\n","\n","# Generate synthetic features and target variable\n","for i in range(7):  # Additional 7 features\n","    df[f'feature_{i}'] = np.random.rand(len(df))\n","df['electricity_consumption'] = np.random.rand(len(df)) * 100  # Target variable\n","\n","# Placeholder split logic (actual logic may vary based on time series considerations)\n","train_df = df[:int(0.8*len(df))]\n","test_df = df[int(0.8*len(df)):]\n","\n","train_df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"id":"Dqoy7evl4Oim","executionInfo":{"status":"ok","timestamp":1712213716476,"user_tz":-540,"elapsed":1804,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"93082296-2c5b-4257-b91f-214179193aa7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 date  weekday  hour  season  feature_0  feature_1  feature_2  \\\n","0 2020-01-01 00:00:00        2     0       1   0.374540   0.671368   0.409980   \n","1 2020-01-01 01:00:00        2     1       1   0.950714   0.523158   0.838483   \n","2 2020-01-01 02:00:00        2     2       1   0.731994   0.898639   0.185176   \n","\n","   feature_3  feature_4  feature_5  feature_6  electricity_consumption  \n","0   0.421576   0.137686   0.120749   0.616654                 1.923384  \n","1   0.280547   0.260339   0.520433   0.003229                47.550482  \n","2   0.895044   0.489540   0.095159   0.792586                26.352564  "],"text/html":["\n","  <div id=\"df-f914fe19-510c-48b4-9487-cec70f582a44\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>weekday</th>\n","      <th>hour</th>\n","      <th>season</th>\n","      <th>feature_0</th>\n","      <th>feature_1</th>\n","      <th>feature_2</th>\n","      <th>feature_3</th>\n","      <th>feature_4</th>\n","      <th>feature_5</th>\n","      <th>feature_6</th>\n","      <th>electricity_consumption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01 00:00:00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.374540</td>\n","      <td>0.671368</td>\n","      <td>0.409980</td>\n","      <td>0.421576</td>\n","      <td>0.137686</td>\n","      <td>0.120749</td>\n","      <td>0.616654</td>\n","      <td>1.923384</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-01 01:00:00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.950714</td>\n","      <td>0.523158</td>\n","      <td>0.838483</td>\n","      <td>0.280547</td>\n","      <td>0.260339</td>\n","      <td>0.520433</td>\n","      <td>0.003229</td>\n","      <td>47.550482</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-01 02:00:00</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0.731994</td>\n","      <td>0.898639</td>\n","      <td>0.185176</td>\n","      <td>0.895044</td>\n","      <td>0.489540</td>\n","      <td>0.095159</td>\n","      <td>0.792586</td>\n","      <td>26.352564</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f914fe19-510c-48b4-9487-cec70f582a44')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f914fe19-510c-48b4-9487-cec70f582a44 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f914fe19-510c-48b4-9487-cec70f582a44');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7fa6af4c-df04-4c2c-a3e6-547256d1bf99\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fa6af4c-df04-4c2c-a3e6-547256d1bf99')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7fa6af4c-df04-4c2c-a3e6-547256d1bf99 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df","summary":"{\n  \"name\": \"train_df\",\n  \"rows\": 7008,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 00:00:00\",\n        \"max\": \"2020-10-18 23:00:00\",\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          \"2020-08-01 06:00:00\",\n          \"2020-05-28 22:00:00\",\n          \"2020-01-11 05:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8,\n          16,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2895729304874716,\n        \"min\": 1.1634755366141114e-05,\n        \"max\": 0.9997176732861306,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.757776560375158,\n          0.8895193110437631,\n          0.9283185625877254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2890793435952475,\n        \"min\": 5.282693229680113e-05,\n        \"max\": 0.9999248268331765,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.9510329247486061,\n          0.10557564221946336,\n          0.30115901978544535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2884688865550287,\n        \"min\": 4.8123894311746795e-05,\n        \"max\": 0.9999009770092316,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.4548864490728314,\n          0.7825056359493593,\n          0.7682759477995226\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2875545787449372,\n        \"min\": 6.749764657443258e-05,\n        \"max\": 0.9997320842956724,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.012020590177249879,\n          0.07222157275550722,\n          0.15148505461207484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2901035519908735,\n        \"min\": 0.0001800389839627936,\n        \"max\": 0.9998905646313925,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.4682569474081265,\n          0.8849530527508368,\n          0.6120767846254114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2887629888791506,\n        \"min\": 9.359385827234501e-05,\n        \"max\": 0.9999569543687702,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.7540201262858824,\n          0.8615676826591921,\n          0.21613064250131997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28771845005052954,\n        \"min\": 8.432211304310044e-06,\n        \"max\": 0.9999396960457185,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          0.6822815134417629,\n          0.6796005638656374,\n          0.6298136637241806\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"electricity_consumption\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.865642645199024,\n        \"min\": 0.027012235672785323,\n        \"max\": 99.96188950868437,\n        \"num_unique_values\": 7008,\n        \"samples\": [\n          68.6015254852777,\n          36.92235033229837,\n          22.611868990374397\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","\n","class TimeSeriesDataset(Dataset):\n","    def __init__(self, dataframe, input_steps, forecast_steps, scaler):\n","        \"\"\"\n","        Initialization of the dataset with a pre-fitted scaler.\n","        input_steps: encoder_lenght\n","        forecast_steps: forecast_length\n","        scaler: MinMaxScaler.fit()などすでにfit済みのscaler\n","        \"\"\"\n","        self.input_steps = input_steps\n","        self.forecast_steps = forecast_steps\n","        self.scaler = scaler\n","\n","        # Separate features and target\n","        features = dataframe.drop(columns=['electricity_consumption'])\n","        target = dataframe[['electricity_consumption']]\n","\n","        # Transform features using the already fitted scaler\n","        self.features = self.scaler.transform(features)\n","        self.target = target.values # Numpyにして渡す ※shape(レコード数, 1)の2次元データ\n","\n","    def __len__(self):\n","        return len(self.features) - self.input_steps - self.forecast_steps\n","\n","    def __getitem__(self, idx):\n","        X = self.features[idx:idx+self.input_steps]\n","        y = self.target[idx+self.input_steps:idx+self.input_steps+self.forecast_steps].flatten()\n","        # flattenで1次元にしている。（この1次元のデータをバッチ化して2次元にするのは、DataLoaderクラスで行われる）\n","        return torch.tensor(X, dtype=torch.float), torch.tensor(y, dtype=torch.float)\n"],"metadata":{"id":"wiborKheTlZy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### flatten() in the __getitem__:\n","The use of **flatten()** in the **__getitem__** method of your **TimeSeriesDataset** class serves an important purpose: it ensures that the labels (targets for prediction) are in the correct shape for comparison against the model's predictions during the loss caluculation phase of training.\n","\n","<br>\n","\n","**UnderStanding the Shapes**\n","\n","* **Model's Prediction Shape**: In the modified **ElecticityConsumptionModel**, the output predictions have a shape of **[batch_size, forecast_length]**. For instance, if you're predicting electricity consumptuon for the next 24 hours **(forecasting_length = 24)** for a batch of 20 samples **(batch_size = 20)**, the output predictions will have a shape of **[20, 24]**.\n","* **Target Labels Shape**: Idealy, the targete labels should match this shape exactly for proper loss computation. However, when slicing arrays or tensors, there's a risk of introducing or retaining an unnecesssary extra dimension, resulting in a shape like **[20, 24, 1]** instead of **[20, 24]**.\n","\n","<br>\n","\n","**The role of flatten()**\n","\n","* **Flattening Labels**: By applying **flatten()**, you remove any extra dimensions in the labels, converting a potential shape of **[20, 24, 1]** to **[20, 24]**. This operation ensures that the labels are directly comparable to the model's output without dimension mismatch issues.\n","* **Why It's Necessary**: During the training phase, specifically in the loss calculation step, PyTorch expects the predictions and labels to have compatible shapes. A mismatch, such as an extra dimension in the labels, can lead to errors or incorrect loss calculations. Using **flatten()** (or similarly **squeeze()**) standardizes the shapes, facilitating correct and efficient tarining.\n","\n","<br>\n","\n","**Example**\n","\n","Suppose your lables tensor initially has a shape of **[20, 24, 1]** due to how the data was sliced or prepared. this shape indicates that each of the 24 forecasted hours has been encapsulated in its own dimension (the extra **1**), which is unnecessary for comparison with the model's output. Flattening adjusts this to **[20, 24]**, aligning it with the prediction shape and allowing for correct loss computation."],"metadata":{"id":"l7nEjJ0S5DD0"}},{"cell_type":"code","source":["encoder_length = 168  # 7 days of hourly records (= sequence length)\n","forecast_length = 24  # Predicting the next 24 hours\n","\n","# Fit scaler on training features\n","scaler = MinMaxScaler()\n","\n","# Drop the 'date' column along with 'electricity_consumption' to prepare features for scaling\n","features_train = train_df.drop(columns=['date', 'electricity_consumption'])\n","scaler.fit(features_train)\n","\n","# When initializing your datasets, ensure the 'date' column is also excluded from the features\n","train_dataset = TimeSeriesDataset(train_df.drop(columns=['date']), encoder_length, forecast_length, scaler)\n","test_dataset = TimeSeriesDataset(test_df.drop(columns=['date']), encoder_length, forecast_length, scaler)\n","\n","# set DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n","\n","for X, y in train_loader:\n","    print(X.shape)\n","    print(y.shape)\n","    break\n","\n","# By using 168 hours records with 10 features, we predict next 24 hours.\n","# 20 is the numbers of batch size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rI7LnKS75A8T","executionInfo":{"status":"ok","timestamp":1712213834008,"user_tz":-540,"elapsed":371,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"4dcd4c6e-7a6f-47b6-f6d7-7fdec92b2d7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 168, 10])\n","torch.Size([20, 24])\n"]}]},{"cell_type":"markdown","source":["### Data Structure of `self.target` in `__getitem__`\n","The data structure of **self.target** in the **__getitem__** method is initially determined by how it's set in the **__init__** method. Since **self.target** is assigned as **target.values**, wehere **target** is a DataFrame containing only the **electicity_consumption** column, **self.target** will be a 2D numpy array with shape **(n, 1)**, where **n** is the number of rows in the DataFrame. This shape corresponds to the total number of data points in your dataset for the target variable.\n","\n","\n","When you access **self.target** within **__getitem__**, for each item, you're slicing this array to get a portion of it based on **idx**, **input_steps**, and **forecast_steps**. This slicing operation for **y**:\n","\n","```\n","y = self.target[idx+self.input_steps:idx+self.input_steps+self.forecast_steps].flatten()\n","```\n","\n","This line takes a slice of **self.target**, corresponding to the forecast period, and then flatten it. The flattening operation changes its **<u>shape from a 2D array to a 1D array</u>**. Therefore, after flattening, if **forecast_steps** were 24, for example, **y** would have a shape of **(24, )**. The flattening is done because your target varialbe (**y**) for each sample is expected to be a 1D tensor representing the series of electricity consumption values you're trying to predict for the forecast period.\n","\n","\n","to summarize, before flattening, each slice of **self.target** that corresponds to a single **y** in **__getitem__** would have a shape like **(forecast_steps, 1)**, after flattening, its shape would be **(forecast_steps, )**.\n"],"metadata":{"id":"EnzjuDQa5gOj"}},{"cell_type":"code","source":["df[['electricity_consumption']].values.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QyEvLXK5A51","executionInfo":{"status":"ok","timestamp":1712213875249,"user_tz":-540,"elapsed":247,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"bb5a720c-3ddc-4841-eca6-e8bb0e4fcc6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8761, 1)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df[['electricity_consumption']].values.flatten().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWzrl0LW5A2a","executionInfo":{"status":"ok","timestamp":1712213879993,"user_tz":-540,"elapsed":225,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"d589bc92-18d2-4c7a-ccd1-b26d9a44d229"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8761,)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### Where is batch size data created?\n","The batch dimension is not explicitly created within the **__getitem__()** method of a PyTorch **Dataset** class. Instead, the batching logic is hadled by the **DataLoader**, which wraps around the **Dataset**.\n","\n","<br>\n","\n","**__getitem__() metohd**:\n","\n","* The **__getitem__()** method is responsible for retrieving a <u>single item</u> from the dataset. When you implement a custom dataset by subclassing PyTorch's **Dataset**, you define how a single sample of data is processed and returned by this method. In your case, for each index **idx**, **__getitem__()** returns a single sample (and its correspoding label or target) where both input(**x**) and target(**y**) are shaped according to the individual sample's requirements. For the target, this means a 1D tensor with th length equal to **forecast_steps**, as per your setup.\n","\n","<br>\n","\n","**DataLoader and Batching**:\n","* The **DataLoader** takes your **Dataset** instance and allows for easy iteration over the dataset in mini-batches. When you use a **DataLoader** with your dataset, it automatically gathers samples into batches. It does this by calling the **__getitem__()** method of your dataset multiple times to fetch individual samples and then stacking these samples together to form a batch.\n","* By default, <u>the **DataLoader** adds an extra dimension (the batch dimension) as the first dimension of the tensors</u> it creates. This means if your **__getitem__()** method returns a target tensor **y** with shape **(forecast_steps, )** for a single sample, and you set your **DataLoader**'s **batch_size** to **N**, the DataLoader will combine these individual samples into a batch where the shape of **y** in each batch will be **(N, forecast_steps)**. This is because it stacks **N** such 1D tensors along a new dimension, resulting in a 2D tensor.\n","\n","\n","For example, if you create a DataLoader with your **TimeSeriesDataset** like this:\n","\n","```\n","dataset = TimseSeriesDataset(dataframe=df, input_steps=12, forecast_steps=24, scaler=scaler)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","```\n","\n","For each iteration over the **dataloader**, it will yield batches where each **X** has the shape **(32, input_steps, number_of_features)** and each **y** has the shape **(32, forecast_steps)**, assuming **input_steps** is the length of the input sequence and **number_of_features** is the number of features per tiemstep.\n","\n","<br>\n","\n","This batching mechanism is crucial for training neural network efficiently, as it allows for parallel processing of multiple data smples, reducing trainig time and leveraging optimization techniques like mini-batch gradient descent."],"metadata":{"id":"i_ym0j5s5nki"}},{"cell_type":"code","source":[],"metadata":{"id":"g-KUlDshhpj-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# shuffle=True or False in time series data\n","\n","When dealing with time series data in machine learning models, especially those designed to capture temporal dependencies like LSTM networks, the order of data points is crucial. Each data point in a time series is typically dependent on previous data points. Therefore, maintaining the chronological order of data is essential for the model to learn the underlying patterns effectively.\n","\n","### Shuffle=False for Time Series\n","\n","For time series datasets, it's generally recommended to set `shuffle=False` in the `DataLoader` for several reasons:\n","\n","- **Preserve Temporal Order**: Time series forecasting relies on the sequence of data points being in their true chronological order. Setting `shuffle=False` ensures that batches of data fed into the model preserve this order, which is necessary for the model to learn from past observations to predict future values accurately.\n","\n","- **Consistency Across Batches**: Keeping the data in sequence allows the model to potentially use information from the end of one batch to inform the beginning of the next, especially if there's overlap between the batches or if statefulness is considered in the model training.\n","\n","- **Validation and Testing Integrity**: For validation and testing sets, it's particularly important to maintain the chronological order to accurately assess the model's performance on unseen data that follows the same temporal sequence as the training set.\n","\n","### When Shuffle=True Might Be Used\n","\n","However, there are scenarios in time series analysis where `shuffle=True` might be useful, particularly during certain types of training:\n","\n","- **Non-Sequential Models**: If the model being trained does not rely on the sequential nature of the data (for example, if you're using time series data in a way that treats each point as independent), shuffling can help to reduce variance and make the model more robust.\n","\n","- **Cross-Validation**: In some types of cross-validation schemes designed specifically for time series (like time series split cross-validation), data is still handled in a way that respects the time series nature but involves selecting different segments of the data for training and validation to ensure the model's generalizability.\n","\n","### Conclusion\n","\n","For most time series forecasting tasks, especially when using models that rely on understanding the sequence of data (like LSTMs), it's best practice to set `shuffle=False` in the DataLoader. This approach respects the inherent order and dependencies within the data, which are vital for the model to make accurate predictions."],"metadata":{"id":"zuS4YdwhhqPz"}},{"cell_type":"code","source":[],"metadata":{"id":"vRORg5lp5Awd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tips: Output another example"],"metadata":{"id":"8nRUsi7liy7d"}},{"cell_type":"markdown","source":["Given your specific setup—stock price data with 5 features, a sequence length of 7, a batch size of 10, and using a DataLoader in PyTorch—the output structure from the DataLoader will be tailored to accommodate sequences of your data.\n","\n","Here’s how the data structure can be conceptualized:\n","\n","- **Input Data Tensor**: The shape of your input data tensor for each batch will reflect the batch size, the sequence length, and the number of features. Specifically, it will be `(batch_size, sequence_length, num_features)`, which translates to `(10, 7, 5)` in your case. This means each batch contains 10 sequences, each sequence is 7 time steps long, and each time step includes 5 features.\n","\n","- **Labels Tensor**: The shape of the labels tensor depends on how you've structured your task (e.g., predicting the next value in the sequence, classifying the sequence, etc.). Assuming you're predicting the next day's stock price or a similar single-value output, and you have one label per sequence, your labels tensor for each batch might have the shape `(10,)`, assuming a single target value per sequence. If you're predicting multiple values or a more complex structure, the shape would adjust accordingly.\n","\n","Here is a simplified example to illustrate this:\n","\n","```python\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","\n","# Simulating stock price data: 100 samples, each with 7 time steps and 5 features per step\n","inputs = torch.randn(100, 7, 5)  # Shape: [100, 7, 5]\n","\n","# Assuming one target value per sequence for simplicity\n","# If your task involves predicting multiple future values or has a different structure, adjust accordingly\n","labels = torch.randn(100)  # Shape: [100]\n","\n","# Create a TensorDataset and DataLoader\n","dataset = TensorDataset(inputs, labels)\n","dataloader = DataLoader(dataset, batch_size=10)\n","\n","# Iterate over the DataLoader\n","for batch_idx, (data, target) in enumerate(dataloader):\n","    print(f\"Batch {batch_idx}:\")\n","    print(f\" - Data shape: {data.shape}\")  # Expected to be torch.Size([10, 7, 5])\n","    print(f\" - Target shape: {target.shape}\")  # Expected to be torch.Size([10])\n","```\n","\n","In this scenario, each iteration over the `DataLoader` will give you a batch where:\n","- `data` is a tensor containing 10 sequences of stock price data, with each sequence being 7 days long and each day having 5 features, thus having a shape of `(10, 7, 5)`.\n","- `target` is a tensor containing 10 labels (one for each sequence in the batch), assuming a single target value per sequence. If your label structure is different (e.g., if you're predicting multiple future values for each sequence), the shape of `target` would vary accordingly."],"metadata":{"id":"vpUlO9Y0Tl6m"}},{"cell_type":"markdown","source":["# check Type if Pandas.DataFrame is OK or not for DataSet class.\n","* DataLoader consume pytorch.tensor, so, we need to transfrom pd.DataFrame into torch.tensor via numpy."],"metadata":{"id":"RyE8yqt6hIoQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler"],"metadata":{"id":"T-VNfB7YhuBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load data\n","data = pd.read_parquet('/content/drive/MyDrive/study_DeepLearning/論文実装/data/price_data_20240409.parquet')\n","# calc return\n","data['AGG_return'] = np.log(data['AGG'] / data['AGG'].shift(1))\n","data['DBC_return'] = np.log(data['DBC'] / data['DBC'].shift(1))\n","data['VTI_return'] = np.log(data['VTI'] / data['VTI'].shift(1))\n","data['^VIX_return'] = np.log(data['^VIX'] / data['^VIX'].shift(1))\n","# exclude nan\n","data = data.iloc[1:]\n","\n","# Splitting into training and testing sets\n","train_data = data.loc[data.index<'2021-01-01']\n","test_data = data.loc[data.index>='2021-01-01']\n","\n","# Initializing the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Fitting the scaler to the training data and transforming training and testing data\n","train_scaled = scaler.fit_transform(train_data.iloc[:, :4])\n","test_scaled = scaler.transform(test_data.iloc[:, :4])\n","\n","# # Converting the scaled data back to a DataFrame\n","train_data.iloc[:, :4] = train_scaled\n","test_data.iloc[:, :4] = test_scaled\n","\n","\n","class FinancialDataset(Dataset):\n","    def __init__(self, data, sequence_length=3):\n","        self.features = data\n","        self.sequence_length = sequence_length\n","\n","    def __len__(self):\n","        return len(self.features) - self.sequence_length\n","\n","    def __getitem__(self, idx):\n","        sequence = self.features[idx:idx+self.sequence_length].to_numpy()\n","        target_return = sequence[:, 4:] # four columns of return to calc sharpe ratio\n","        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(target_return, dtype=torch.float32)\n","\n","train_dataset = FinancialDataset(train_data)\n","train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=False)"],"metadata":{"id":"OGK7i486hQ-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_list = []\n","y_list = []\n","for x, y in train_dataloader:\n","    x_list.append(x)\n","    y_list.append(y)"],"metadata":{"id":"ivz-Rt6Dh5HE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1a6AGH6iFxW","executionInfo":{"status":"ok","timestamp":1712912434896,"user_tz":-540,"elapsed":339,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"2c39bc9a-3ad7-45f9-a755-2508089d6373"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 8])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["x_list[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kl5rpvpriH4W","executionInfo":{"status":"ok","timestamp":1712912437302,"user_tz":-540,"elapsed":304,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"505491ff-5864-4fdb-d888-ed23845b5189"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.3759,  0.3617,  0.1793,  0.0605, -0.0007, -0.0294, -0.0098,\n","           0.0413],\n","         [ 0.3743,  0.3589,  0.1821,  0.0502, -0.0005, -0.0043,  0.0072,\n","          -0.0575],\n","         [ 0.3762,  0.3651,  0.1813,  0.0541,  0.0006,  0.0094, -0.0019,\n","           0.0224]],\n","\n","        [[ 0.3743,  0.3589,  0.1821,  0.0502, -0.0005, -0.0043,  0.0072,\n","          -0.0575],\n","         [ 0.3762,  0.3651,  0.1813,  0.0541,  0.0006,  0.0094, -0.0019,\n","           0.0224],\n","         [ 0.3695,  0.3531,  0.1821,  0.0507, -0.0021, -0.0184,  0.0021,\n","          -0.0192]]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["x_list[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcC-sQvviSFK","executionInfo":{"status":"ok","timestamp":1712912465681,"user_tz":-540,"elapsed":13,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"f6170083-7676-4501-97ec-542c671f9ac1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.3762,  0.3651,  0.1813,  0.0541,  0.0006,  0.0094, -0.0019,\n","           0.0224],\n","         [ 0.3695,  0.3531,  0.1821,  0.0507, -0.0021, -0.0184,  0.0021,\n","          -0.0192],\n","         [ 0.3718,  0.3431,  0.1803,  0.0572,  0.0007, -0.0156, -0.0045,\n","           0.0366]],\n","\n","        [[ 0.3695,  0.3531,  0.1821,  0.0507, -0.0021, -0.0184,  0.0021,\n","          -0.0192],\n","         [ 0.3718,  0.3431,  0.1803,  0.0572,  0.0007, -0.0156, -0.0045,\n","           0.0366],\n","         [ 0.3666,  0.3378,  0.1840,  0.0423, -0.0016, -0.0084,  0.0094,\n","          -0.0860]]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["train_data.head(6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"3KuWdanhifwX","executionInfo":{"status":"ok","timestamp":1712912618517,"user_tz":-540,"elapsed":439,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"6382ac7b-1bb6-4813-9409-37f844adafaf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 AGG       DBC       VTI      ^VIX  AGG_return  DBC_return  \\\n","Date                                                                         \n","2006-02-07  0.375921  0.361714  0.179259  0.060503   -0.000699   -0.029352   \n","2006-02-08  0.374319  0.358932  0.182055  0.050170   -0.000499   -0.004264   \n","2006-02-09  0.376241  0.365053  0.181310  0.054113    0.000599    0.009358   \n","2006-02-10  0.369517  0.353089  0.182118  0.050714   -0.002099   -0.018373   \n","2006-02-13  0.371758  0.343072  0.180347  0.057240    0.000700   -0.015646   \n","2006-02-14  0.366635  0.337785  0.184044  0.042284   -0.001601   -0.008357   \n","\n","            VTI_return  ^VIX_return  \n","Date                                 \n","2006-02-07   -0.009784     0.041313  \n","2006-02-08    0.007169    -0.057548  \n","2006-02-09   -0.001907     0.022352  \n","2006-02-10    0.002065    -0.019239  \n","2006-02-13   -0.004533     0.036617  \n","2006-02-14    0.009441    -0.085990  "],"text/html":["\n","  <div id=\"df-c6dee0ba-cf92-431d-b64b-9d0f5bb2b853\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AGG</th>\n","      <th>DBC</th>\n","      <th>VTI</th>\n","      <th>^VIX</th>\n","      <th>AGG_return</th>\n","      <th>DBC_return</th>\n","      <th>VTI_return</th>\n","      <th>^VIX_return</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2006-02-07</th>\n","      <td>0.375921</td>\n","      <td>0.361714</td>\n","      <td>0.179259</td>\n","      <td>0.060503</td>\n","      <td>-0.000699</td>\n","      <td>-0.029352</td>\n","      <td>-0.009784</td>\n","      <td>0.041313</td>\n","    </tr>\n","    <tr>\n","      <th>2006-02-08</th>\n","      <td>0.374319</td>\n","      <td>0.358932</td>\n","      <td>0.182055</td>\n","      <td>0.050170</td>\n","      <td>-0.000499</td>\n","      <td>-0.004264</td>\n","      <td>0.007169</td>\n","      <td>-0.057548</td>\n","    </tr>\n","    <tr>\n","      <th>2006-02-09</th>\n","      <td>0.376241</td>\n","      <td>0.365053</td>\n","      <td>0.181310</td>\n","      <td>0.054113</td>\n","      <td>0.000599</td>\n","      <td>0.009358</td>\n","      <td>-0.001907</td>\n","      <td>0.022352</td>\n","    </tr>\n","    <tr>\n","      <th>2006-02-10</th>\n","      <td>0.369517</td>\n","      <td>0.353089</td>\n","      <td>0.182118</td>\n","      <td>0.050714</td>\n","      <td>-0.002099</td>\n","      <td>-0.018373</td>\n","      <td>0.002065</td>\n","      <td>-0.019239</td>\n","    </tr>\n","    <tr>\n","      <th>2006-02-13</th>\n","      <td>0.371758</td>\n","      <td>0.343072</td>\n","      <td>0.180347</td>\n","      <td>0.057240</td>\n","      <td>0.000700</td>\n","      <td>-0.015646</td>\n","      <td>-0.004533</td>\n","      <td>0.036617</td>\n","    </tr>\n","    <tr>\n","      <th>2006-02-14</th>\n","      <td>0.366635</td>\n","      <td>0.337785</td>\n","      <td>0.184044</td>\n","      <td>0.042284</td>\n","      <td>-0.001601</td>\n","      <td>-0.008357</td>\n","      <td>0.009441</td>\n","      <td>-0.085990</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6dee0ba-cf92-431d-b64b-9d0f5bb2b853')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c6dee0ba-cf92-431d-b64b-9d0f5bb2b853 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c6dee0ba-cf92-431d-b64b-9d0f5bb2b853');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5f48eff8-62a3-48a2-a08f-a0267678a795\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f48eff8-62a3-48a2-a08f-a0267678a795')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5f48eff8-62a3-48a2-a08f-a0267678a795 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_data","summary":"{\n  \"name\": \"train_data\",\n  \"rows\": 3752,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2006-02-07 00:00:00\",\n        \"max\": \"2020-12-31 00:00:00\",\n        \"num_unique_values\": 3752,\n        \"samples\": [\n          \"2014-08-20 00:00:00\",\n          \"2010-04-01 00:00:00\",\n          \"2019-04-17 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15921398565599254,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1513,\n        \"samples\": [\n          0.7316683189287674,\n          0.6138328783708711,\n          0.6634647472087845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DBC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1838808705965047,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1666,\n        \"samples\": [\n          0.5108514555342036,\n          0.4869226674648449,\n          0.8030050560131106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VTI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2232556209895788,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3169,\n        \"samples\": [\n          0.22073442285518977,\n          0.9894991769862873,\n          0.12476698265004846\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"^VIX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13086961996726826,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1870,\n        \"samples\": [\n          0.16641738230164901,\n          0.045819167769226954,\n          0.2852481291289769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AGG_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0032677581024586114,\n        \"min\": -0.0708463326487949,\n        \"max\": 0.03795814859277399,\n        \"num_unique_values\": 3633,\n        \"samples\": [\n          -0.002717105401155531,\n          0.0020012472196956513,\n          0.00019986649960472924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DBC_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012234200184007523,\n        \"min\": -0.08104120907607643,\n        \"max\": 0.06648438197698457,\n        \"num_unique_values\": 3598,\n        \"samples\": [\n          -0.023232349650902748,\n          0.017512168153437226,\n          0.008626017355984852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VTI_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012814143768730711,\n        \"min\": -0.12082225344955712,\n        \"max\": 0.12071002954441935,\n        \"num_unique_values\": 3735,\n        \"samples\": [\n          0.007110861379729543,\n          0.010374010575334672,\n          0.0009510079299520644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"^VIX_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07640147212946086,\n        \"min\": -0.35058851122248774,\n        \"max\": 0.7682450294663026,\n        \"num_unique_values\": 3721,\n        \"samples\": [\n          0.00583575607764696,\n          -0.028194941206063983,\n          0.002157478903647557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[],"metadata":{"id":"vQPdog1gio1d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset and TensorDataset\n","\n","In PyTorch, `Dataset` and `TensorDataset` are both used to handle data, but they serve different purposes and have different levels of abstraction:\n","\n","### Dataset\n","`Dataset` is an abstract class representing a dataset in PyTorch. To create your own custom dataset, you typically inherit from this class and implement at least two methods:\n","- `__len__`: which returns the size of the dataset (the number of items it contains).\n","- `__getitem__`: which supports the indexing such that `dataset[i]` can be used to get the ith sample from the dataset.\n","\n","This abstract class is designed to be a flexible base for creating datasets where you might need to read files, apply transformations, and perform other custom operations. It does not contain any specific data handling itself but defines a protocol for accessing elements and their number.\n","\n","Here is an example of creating a custom dataset:\n","```python\n","from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data, transforms=None):\n","        self.data = data\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        sample = self.data[idx]\n","        if self.transforms:\n","            sample = self.transforms(sample)\n","        return sample\n","```\n","\n","### TensorDataset\n","`TensorDataset` is a specific implementation of the `Dataset` abstract class that wraps tensors. When initialized with one or more tensors, it provides a way to access slices of these tensors as samples. This is particularly useful when your dataset is already in memory, in the form of multiple large tensors, but you want to access it through the convenient Dataset interface used by PyTorch's `DataLoader` for batching, shuffling, etc.\n","\n","`TensorDataset` assumes that each tensor you provide as input corresponds to a dataset dimension or feature, and it will index these tensors along the first dimension to form samples. This is ideal for situations where you have features and targets already loaded in tensors and you want to iterate through them efficiently.\n","\n","Here is an example of using `TensorDataset`:\n","```python\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch\n","\n","# Example features and labels\n","features = torch.randn(100, 10)  # 100 samples, 10 features each\n","labels = torch.randn(100, 1)  # 100 samples, 1 target each\n","\n","# Create TensorDataset\n","dataset = TensorDataset(features, labels)\n","\n","# Create DataLoader for batching\n","dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n","\n","# Usage example\n","for batch_features, batch_labels in dataloader:\n","    # Process batches here\n","    pass\n","```\n","\n","### Summary\n","- **Dataset**: An abstract class for making datasets available in PyTorch in a flexible and customizable way, requiring you to define how items are accessed.\n","- **TensorDataset**: A convenient class for handling datasets already loaded into tensors, allowing you to use them directly in the training pipeline with minimal setup.\n","\n","Using `Dataset` allows for greater flexibility and is useful for handling complex data-loading scenarios, while `TensorDataset` is straightforward and efficient for datasets already in tensor form."],"metadata":{"id":"QB2lneh8tY1f"}},{"cell_type":"code","source":[],"metadata":{"id":"Jf4ha8Matfe-"},"execution_count":null,"outputs":[]}]}