{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP8bwdTSuZ6LbkSY8F37ace"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Early Stopping during Learning\n","Early stopping is a form of regularization used to avoid overfitting when training a machine learning model. It works by monitoring the model's performance on a validation dataset and stopping the training process if the model's performance ceases to improve after a certain number of epochs. this technique not only helps in preventing overfitting but also can save computational resources by stopping the training early if further training does not lead to better results.\n"],"metadata":{"id":"TzKgKtXnp9H4"}},{"cell_type":"markdown","source":["## Implementing Early Stopping in PyTorch\n","PyTorch doesn't have built-in early stopping support like some other libraries (e.g., Keras), but it can be impleneted easily with a few lines of custom code. Here's a basic outline of how you can implenet early stopping:\n","\n","1. **Monitor a performance metric** on a validation set.\n","2. **Stop training** if this metirc does not improve for a set number of epochs.\n","3. Optionally, **restore the weights** from when the validation loss was at its minimum.\n","\n","Here's how you could implenet this:"],"metadata":{"id":"GvCfss4RqhEE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJcmp39up1yu"},"outputs":[],"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define your model\n","model = nn.Linear(1, 1)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Assuming x_val and y_val are your validation dataset\n","def validate(model, data_loader):\n","    model.eval()  # Set model to evaluation mode\n","    total_loss = 0\n","    with torch.no_grad():  # No need to track gradients\n","        for x_batch, y_batch in data_loader:\n","            y_pred = model(x_batch)\n","            loss = criterion(y_pred, y_batch)\n","            total_loss += loss.item()\n","    return total_loss / len(data_loader)\n","\n","# Training setup\n","num_epochs = 100\n","patience = 10\n","best_loss = np.inf\n","trigger_times = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()  # Set model to training mode\n","    # Training code (forward, loss, backward, step)\n","    # ...\n","\n","    # Validate the model\n","    val_loss = validate(model, val_data_loader)\n","    print(f'Epoch {epoch}, Validation loss: {val_loss}')\n","\n","    # Check if current validation loss is less than the best loss\n","    if val_loss < best_loss:\n","        print(f\"Validation loss decreased {best_loss} -> {val_loss}\")\n","        best_loss = val_loss\n","        best_model_wts = model.state_dict()  # Save the best model weights\n","        trigger_times = 0  # reset trigger times\n","    else:\n","        trigger_times += 1\n","        print(f\"Validation loss did not decrease, count: {trigger_times}\")\n","\n","    # Early stopping condition\n","    if trigger_times >= patience:\n","        print(\"Early stopping!\")\n","        model.load_state_dict(best_model_wts)  # Restore best model weights\n","        break\n","\n","# Further code, e.g., testing or saving the model\n"]},{"cell_type":"markdown","source":["** Key Components of the Early stopping Logic**:\n","* **Validation Loss Calculation**: The current loss is evaluated on the validation dataset after each epoch.\n","* **Loss improvement Check**: the current loss is compared with the best observed loss so far. If it's better, the model weights are saved, and the patience couter reset.\n","* **Patience Counter**: If the validation loss doesn't improve for a given number of consecutive epochs (**patience**), the training stops.\n","* **Model State Restoration**: If early stopping is triggered, the model's weights are restored to the state when it achieved the best validation loss.\n","\n","\n","This approach allows you to integrate early stopping into your training loop, providing control over how long you allow training to continue without improvement and ensuring you keep the best performing model as judged by the validation loss."],"metadata":{"id":"KeXAUITdr16m"}},{"cell_type":"code","source":[],"metadata":{"id":"z-o053dDtSms"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# YouTube\n","* https://www.youtube.com/watch?v=lS0vvIWiahU&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi&index=15\n","\n","* https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_03_4_early_stop.ipynb"],"metadata":{"id":"ItbyZQJmChKt"}},{"cell_type":"code","source":["# Make use of a GPU if one is available\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_CRpgzNCkQ4","executionInfo":{"status":"ok","timestamp":1715216413948,"user_tz":-540,"elapsed":7248,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"8a1e8d23-1bda-43e5-e29d-2740ebb8d103"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["Because PyTorch does not include a built-in early stopping function, we must define one of our own. We will use the following **EarlyStopping** class throughout this course.\n","\n","We can provide several parameters to the **EarlyStopping** object:\n","\n","* **min_delta**: This value should be kept small; it specifies the minimum change that should be considered an improvement. Setting it even smaller will not likely have a great deal of impact.\n","* **patience**: How long should the training wait for the validation error to improve?\n","* **restore_best_weights**: You should usually set this to ture, as it resotores the weights to the values they were at when the validation set is the highest."],"metadata":{"id":"nV8WaiYoEsjs"}},{"cell_type":"code","source":["import copy\n","\n","class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.restore_best_weights = restore_best_weights\n","        self.best_model = None\n","        self.best_loss = None\n","        self.counter = 0\n","        self.status = \"\"\n","\n","    def __call__(self, model, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","            self.best_model = copy.deepcopy(model.state_dict())\n","        elif self.best_loss - val_loss > self.min_delta:\n","            self.best_model = copy.deepcopy(model.state_dict())\n","            self.best_loss = val_loss\n","            self.counter = 0\n","            self.status = f\"Improvement found, counter reset to {self.counter}\"\n","        else:\n","            self.counter += 1\n","            self.status = f\"No improvement in the last {self.counter} epochs\"\n","            if self.counter >= self.patience:\n","                self.status = f\"Early stopping triggered after {self.counter} epochs\"\n","                if self.restore_best_weights:\n","                    model.load_state_dict(self.best_model)\n","                return True\n","        return False\n"],"metadata":{"id":"_jSoAem9DGQY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## explanation by gpt4 about above class\n","The **EarlyStopping** class is designed to halt the training process when the validation loss stops improving over a specified number of epochs. This is an important technique used to prevent overfitting, ensuring the model generalizes well to new, unseen data.\n","\n","Let's break down the **EarlyStopping** class step-by-step:\n","\n","### Constructor: `__init__`\n","* **patience**: Number of epochs to continue training without improvement in validation loss. If the validation loss does not decrease for this number of epochs, training is stopped.\n","* **min_delta**: The minimum change in the monitored quantity to qualify as as improvement, i.e., the change in loss must be greater than this value to count as improvement.\n","* **restore_best_weights**: If set to **True**, the model weights will be reverted(元に戻す) to the state when the validation loss was ata its lowest.\n","\n","### Instance Variables\n","* **best_model**: Stores the model weights when the validation loss was at its lowest.\n","* **best_loss**: The lowest recorded validation loss.\n","* **counter**: Counts the number of consecutive epochs without an improvement in validation loss.\n","* **status**: A message indicating the current status of early stopping (improvement found, no improvement, or early stopping triggered.)\n","\n","### Method: `__call__`\n","This method is called at the end of each epoch with the current model and the valdiation loss.\n","\n","* **Initialization**: If **best_loss** is **None** (first epoch), initialize it with the current validation loss and save the model state.\n","* **Improvement Check**:\n","    * If the validation loss decrease by more than **min_delta** from **best_loss**, update **best_loss**, save the new best model state, and reset the **counter** to zero. Update **status** to indeicate improvement.\n","    * If no improvement is seen, increase the **counter** by one and update the **status** to indicate no improvement.\n","* **Patience Check**:\n","    * If the **counter** reaches the **patience** limit, update the **status** to indicate that early stopping is triggered. If **restore_best_weights** is true, load the best model weights. Finally return **True** to indicate training should stop.\n","* **Return `False`** if the training should continue.\n","\n","\n","### Example Usage:\n","1. **Initiate EarlyStopping**: An instance lf **EarlyStopping** is created with default parameters.\n","2. **Training Loop**: During the training loop, after every epoch, the model's performance is evaluated on the validation set.\n","3. **Early Stopping Check**: After evaluating, the **EarlyStopping** instance is called with the current model and the validation loss. It will return **True** if training should stop, otherwise **False**.\n","\n","This mechanism helps in keeping the best performing model and stopping the training when the model starts to overfit. It's a widely used strategy in training deep learning models to ensure they perform well on unseen data."],"metadata":{"id":"MmBNLliAdyx5"}},{"cell_type":"markdown","source":["## Early Stopping with Classification\n","We will now see an example of classification training with early stopping. We will train the neural network until the error no longer improves on the validation set."],"metadata":{"id":"L_rU6hKmHH7Y"}},{"cell_type":"code","source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from torch.autograd import Variable\n","import tqdm"],"metadata":{"id":"HDwbZQGhNMfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set random seed for reproducibility\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","def load_data():\n","    df = pd.read_csv(\n","        \"https://data.heatonresearch.com/data/t81-558/iris.csv\", na_values=[\"NA\", \"?\"]\n","        )\n","\n","    le = LabelEncoder()\n","\n","    x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n","    y = le.fit_transform(df[\"species\"])\n","    species = le.classes_\n","\n","    # Split into validation and training sets\n","    x_train, x_test, y_train, y_test = train_test_split(\n","        x, y, test_size=0.25, random_state=42\n","        )\n","\n","    scaler = StandardScaler()\n","    x_train = scaler.fit_transform(x_train)\n","    x_test = scaler.transform(x_test)\n","\n","    # Numpy to Torch Tensor\n","    x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n","    y_train = torch.tensor(y_train, device=device, dtype=torch.long)\n","\n","    x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n","    y_test = torch.tensor(y_test, device=device, dtype=torch.long)\n","\n","    return x_train, x_test, y_train, y_test, species\n","\n","x_train, x_test, y_train, y_test, species = load_data()"],"metadata":{"id":"nqHaH2TzNszs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCNFn0QNO-k-","executionInfo":{"status":"ok","timestamp":1714033676136,"user_tz":-540,"elapsed":293,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"a006ea9a-4c42-4b73-ca40-1f49fa064e03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([112, 4])\n","torch.Size([112])\n","torch.Size([38, 4])\n","torch.Size([38])\n"]}]},{"cell_type":"code","source":["x_train[-1,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXGM7ispPHyC","executionInfo":{"status":"ok","timestamp":1714033678252,"user_tz":-540,"elapsed":399,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"68ce86d0-f92d-4b81-cbbc-6fcb818e06ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 1.5570, -0.0923,  1.2115,  1.1895])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Create datasets\n","BATCH_SIZE = 16\n","\n","dataset_train = TensorDataset(x_train, y_train)\n","dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","\n","dataset_test = TensorDataset(x_test, y_test)\n","dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Create model using nn.Sequential\n","model = nn.Sequential(\n","    nn.Linear(x_train.shape[1], 50),\n","    nn.ReLU(),\n","    nn.Linear(50, 25),\n","    nn.ReLU(),\n","    nn.Linear(25, len(species)),\n","    nn.LogSoftmax(dim=1),\n","    )\n","\n","model = torch.compile(model, backend=\"aot_eager\").to(device)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","es = EarlyStopping()"],"metadata":{"id":"Plz--VDQPPXi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 0\n","done = False\n","while epoch < 1000 and not done:\n","    epoch += 1\n","    steps = list(enumerate(dataloader_train))\n","    pbar = tqdm.tqdm(steps)\n","    model.train()\n","    for i, (x_batch, y_batch) in pbar:\n","        y_batch_pred = model(x_batch.to(device))\n","        loss = loss_fn(y_batch_pred, y_batch.to(device))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss, current = loss.item(), (i + 1) * len(x_batch)\n","        if i == len(steps) - 1: # 1epoch分のバッチ処理終了後に、eval処理\n","            model.eval()\n","            with torch.no_grad():\n","                pred = model(x_test)\n","                vloss = loss_fn(pred, y_test)\n","\n","            if es(model, vloss):\n","                done = True\n","            pbar.set_description(\n","                f\"Epoch {epoch:03d} | Loss: {loss:.4f}, vloss: {vloss:>7f}, {es.status}\")\n","        else:\n","            pbar.set_description(\n","                f\"Epoch {epoch:03d} | Loss: {loss:.4f}\"\n","                )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8JwZcf3U1e6","executionInfo":{"status":"ok","timestamp":1714033734522,"user_tz":-540,"elapsed":2327,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"a6e42647-2b7c-482a-b35a-b1ac14236c4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 001 | Loss: 0.6039, vloss: 0.463542, : 100%|██████████| 7/7 [00:00<00:00, 14.27it/s]\n","Epoch 002 | Loss: 0.2977, vloss: 0.255949, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 125.54it/s]\n","Epoch 003 | Loss: 0.0834, vloss: 0.191380, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 129.71it/s]\n","Epoch 004 | Loss: 0.2334, vloss: 0.127771, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 132.53it/s]\n","Epoch 005 | Loss: 0.1344, vloss: 0.081698, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 146.73it/s]\n","Epoch 006 | Loss: 0.0627, vloss: 0.058430, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 99.58it/s]\n","Epoch 007 | Loss: 0.1053, vloss: 0.047269, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 121.06it/s]\n","Epoch 008 | Loss: 0.0103, vloss: 0.026243, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 123.81it/s]\n","Epoch 009 | Loss: 0.0840, vloss: 0.017112, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 117.28it/s]\n","Epoch 010 | Loss: 0.0826, vloss: 0.020082, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 134.35it/s]\n","Epoch 011 | Loss: 0.0354, vloss: 0.021935, No improvement in the last 2 epochs: 100%|██████████| 7/7 [00:00<00:00, 135.79it/s]\n","Epoch 012 | Loss: 0.0808, vloss: 0.022856, No improvement in the last 3 epochs: 100%|██████████| 7/7 [00:00<00:00, 135.67it/s]\n","Epoch 013 | Loss: 0.0149, vloss: 0.012329, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 113.31it/s]\n","Epoch 014 | Loss: 0.0209, vloss: 0.009768, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 116.55it/s]\n","Epoch 015 | Loss: 0.0107, vloss: 0.013447, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 129.92it/s]\n","Epoch 016 | Loss: 0.0119, vloss: 0.012101, No improvement in the last 2 epochs: 100%|██████████| 7/7 [00:00<00:00, 114.27it/s]\n","Epoch 017 | Loss: 0.0588, vloss: 0.011913, No improvement in the last 3 epochs: 100%|██████████| 7/7 [00:00<00:00, 137.72it/s]\n","Epoch 018 | Loss: 0.0025, vloss: 0.013231, No improvement in the last 4 epochs: 100%|██████████| 7/7 [00:00<00:00, 132.51it/s]\n","Epoch 019 | Loss: 0.0108, vloss: 0.013574, Early stopping triggered after 5 epochs: 100%|██████████| 7/7 [00:00<00:00, 128.85it/s]\n"]}]},{"cell_type":"code","source":["pred = model(x_test)\n","vloss = loss_fn(pred, y_test)\n","print(f\"Loss = {vloss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gHF8JG_Xsn3","executionInfo":{"status":"ok","timestamp":1714033797167,"user_tz":-540,"elapsed":274,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"bbe6cf7a-480e-4e71-9ccf-f9f6072587dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss = 0.00976768508553505\n"]}]},{"cell_type":"markdown","source":["As you can see from above, we did not use the total number of requested epochs. The neural network training stopped once the validation set no longer improved."],"metadata":{"id":"qAqrB0oDYOYD"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","pred = model(x_test)\n","_, predict_classes = torch.max(pred, 1)\n","correct = accuracy_score(y_test.cpu(), predict_classes.cpu())\n","print(f\"Accuracy: {correct}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZaKflQ7YCP_","executionInfo":{"status":"ok","timestamp":1714033854290,"user_tz":-540,"elapsed":278,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"cbc0886b-9344-4124-ae36-93bf24bc6fa1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n"]}]},{"cell_type":"markdown","source":["# Merit of early stopping\n","\n","Early stopping is a regularization technique used to prevent overfitting in deep learning models. It involves monitoring the model's performance on a validation dataset and halting the training process when the performance stops improving. Here's how it works and its potential impact on predictive power:\n","\n","### How Early Stopping Works\n","\n","1. **Training and Validation Splits**: During training, the dataset is typically split into training and validation sets. The model is trained on the training set, and its performance is periodically evaluated on the validation set.\n","2. **Monitoring Performance**: A specific metric, such as validation loss or accuracy, is monitored. Early stopping keeps track of this metric over epochs (iterations of training).\n","3. **Patience Parameter**: A patience parameter is set, defining the number of epochs to wait for an improvement in the monitored metric before stopping the training. If no improvement is observed within the patience period, training is halted.\n","\n","### Impact on Predictive Power\n","\n","- **Preventing Overfitting**: Early stopping helps prevent overfitting, which occurs when a model performs well on the training data but poorly on unseen data. By stopping training before the model starts to overfit, early stopping aims to improve generalization to new, unseen data.\n","- **Optimal Performance**: The goal of early stopping is to find the point where the model performs best on the validation data, which is assumed to correlate with good performance on future data.\n","\n","### Will Predictive Power Decrease?\n","\n","The concern about predictive power on future data when using early stopping can be addressed as follows:\n","\n","- **Improved Generalization**: By preventing overfitting, early stopping usually improves the model's ability to generalize to new data. This means that, in most cases, the predictive power on future data should not become weaker but rather more reliable.\n","- **Validation Set Quality**: The effectiveness of early stopping heavily depends on the quality and representativeness of the validation set. If the validation set is not representative of future data, the benefits of early stopping might not fully materialize.\n","- **Appropriate Patience**: Setting the patience parameter appropriately is crucial. If the patience is too low, the model might stop training too early, leading to underfitting. If it's too high, the model might still overfit despite early stopping.\n","\n","### Practical Considerations\n","\n","- **Cross-Validation**: Using cross-validation can provide a more robust estimate of the model's performance and help in better tuning of the early stopping parameters.\n","- **Multiple Runs**: Running the training process multiple times with different random seeds and averaging the results can provide a more reliable assessment of the model's predictive power.\n","\n","In summary, when used appropriately, early stopping is designed to enhance the model's ability to generalize to future data, thus maintaining or even improving predictive power. However, careful tuning and validation are essential to ensure its effectiveness."],"metadata":{"id":"FVfgHkGpZg3w"}},{"cell_type":"code","source":[],"metadata":{"id":"XbtKiHgOZ4jf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Is it possible to use both train and validation data, afeter validation phase?\n","Your approach to re-train the model using both the training and validation data after the early stopping is a reasonable and sometimes practiced method, though it is **not always standard**. Let's break down the considerations and scenarios where this approach may or may not be used.\n","\n","### Standard Practice\n","The typical workflow involves the following steps:\n","1. **Training Phase**: The model is trained using the training data, and its performance is monitored on the validation data.\n","2. **Validation Phase**: Hyperparameters and early stopping criteria are tuned based on the validation performance.\n","3. **Final Evaluation**: The best model configuration (based on validation performance) is evaluated on a separate test set to estimate its generalization performance.\n","\n","### Using Validation Data for Final Training\n","Once the best hyperparameters and early stopping point are determined, re-training the model using both the training and validation data can potentially improve the model's performance. This is because the model can benefit from the additional data provided by the validation set.\n","\n","#### Pros\n","- **Utilizing More Data**: By incorporating the validation data, you increase the amount of data available for training, which can lead to better model performance, especially if the dataset is small.\n","- **Improved Model**: The final model may generalize better because it has been trained on more data.\n","\n","#### Cons\n","- **Validation Bias**: There's a risk of introducing bias because the model has been influenced by the validation data used during hyperparameter tuning and early stopping.\n","- **No True Validation**: By using the validation data for training, you lose the validation set's independent assessment. This makes it crucial to have a separate test set to evaluate the final model.\n","\n","### Practical Scenarios\n","1. **When to Retrain**: Retraining using both training and validation data is more common when:\n","   - **Data is Limited**: When the dataset is small and the benefit of more training data outweighs the risk of validation bias.\n","   - **Final Model Deployment**: When deploying a final model in production, leveraging as much data as possible can be advantageous.\n","\n","2. **When Not to Retrain**: It might not be ideal to retrain in scenarios where:\n","   - **Abundant Data**: If there is ample training data, the gains from adding validation data might be minimal.\n","   - **Evaluation Integrity**: If a separate, large, and representative test set is available, maintaining the integrity of the validation set for hyperparameter tuning and early stopping is more critical.\n","\n","### Implementation Steps\n","1. **Initial Training**: Train the model using the training data and determine the optimal hyperparameters and early stopping criteria based on the validation set.\n","2. **Retraining with Combined Data**:\n","   - Combine the training and validation data.\n","   - Retrain the model using the combined dataset with the previously determined hyperparameters and stopping criteria.\n","3. **Final Evaluation**: Use a separate test set to evaluate the final model's performance.\n","\n","### Summary\n","Re-training the model using both training and validation data can be beneficial in scenarios where additional data is needed to improve model performance. However, it should be done with caution, considering the potential introduction of validation bias. Ensuring a separate test set is available for the final evaluation is crucial to maintain an unbiased estimate of the model's generalization performance."],"metadata":{"id":"WE6xjhyTZrRD"}},{"cell_type":"code","source":[],"metadata":{"id":"rDt7W7c3YQRG"},"execution_count":null,"outputs":[]}]}