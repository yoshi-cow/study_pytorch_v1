{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPOkWuRhlX/31qqRV01XStA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Learnin_Rate_Schedules\n","* https://www.youtube.com/watch?v=lMMlbmfvKDQ&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi&index=18\n","* https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_04_2_schedule.ipynb"],"metadata":{"id":"fl-jKdJEf-Xv"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"fkvHq21D5ktg","executionInfo":{"status":"ok","timestamp":1714713679832,"user_tz":-540,"elapsed":9,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"X-R8GMyQfqFm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714711496042,"user_tz":-540,"elapsed":5031,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"0ab9898c-508e-4aff-9b8e-f0107e66149d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Note: using Google CoLab\n","Using device: cpu\n"]}],"source":["import copy\n","import torch\n","\n","try:\n","    import google.colab\n","\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False\n","\n","# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n","import torch\n","has_mps = torch.backends.mps.is_built()\n","device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","source":["## Early Stopping Class"],"metadata":{"id":"gSSubytAxRg3"}},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.restore_best_weights = restore_best_weights\n","        self.best_model = None\n","        self.best_loss = None\n","        self.counter = 0\n","        self.status = \"\"\n","\n","    def __call__(self, model, val_loss):\n","        if self.best_model is None:\n","            self.best_model = copy.deepcopy(model.state_dict())\n","            self.best_loss = val_loss\n","        elif self.best_loss - val_loss > self.min_delta:\n","            self.best_model = copy.deepcopy(model.state_dict())\n","            self.best_loss = val_loss\n","            self.counter = 0\n","            self.status = f\"Improvement found, counter reset to {self.counter}\"\n","        else:\n","            self.counter += 1\n","            self.status = f\"No improvement in the last {self.counter} epochs\"\n","            if self.counter >= self.patience:\n","                print(f\"Early stopping after {self.counter} epochs\")\n","                if self.restore_best_weights:\n","                    model.load_state_dict(self.best_model)\n","                return True\n","        return False"],"metadata":{"id":"qwfxueKYxQ24","executionInfo":{"status":"ok","timestamp":1714711826455,"user_tz":-540,"elapsed":11,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Training Schedules for PyTorch\n","Learning rate schedules are mechanisms used during the training of neural networks to adjust the learning rate over time. They're designed to decrease the learning rate as the training progresses, allowing the network to make large adjustments in the initial stages of training, when the weights are likely far from their optimal values, and then make smaller adjustments as the training progresses, to fine-tune the weights. This adjustment helps mitigate the risk of overshooting the minimum point of the loss function and helps to reach convergence more smoothly.\n","\n","\n","\n","In PyTorch, one of the learning rate scheduling tools is the **StepLR** class, found in the **torch.optim.lr_scheduler** module. **StepLR** is a type of learning rate schedule that decreases the learining rate by a certain factor every few epochs. This allows the learning rate to decrease in a step-wise fashion rather than continuoulsy, which can be beneficial in some cases, as it gives the model time to 'settle' into areas of the loss landscape before the learning rate is reduced further.\n","\n","\n","StepLR takes three parameters:\n","* **optimizer**: The optimizer you're using to train your model (e.g., SGD, Adam)\n","* **step_size**: This is the number of epochs after which you want to reduce the learining rate. For instance, if step_size=10, then the learning rate will be reduced every 10 epochs.\n","* **gamma**: This is the factor by which the learning rate will be reduced at each step. For instance, if gamma=0.1, the learning rate will be multiplied by 0.1 at each step. effectively reducing it by 90%.\n","\n","\n","\n","The **StepLR** scheduler is used during the training loop. After each step of the optimizer (after **optimizer.step()**), you call **scheduler.step()** to adjust the learning rate according to the schedule.\n","\n","\n","\n","It's worth noting that the choice of **step_size** and gamma can be important, and may need to be tuned based on your specific problem and dataset. <u>Too large a **step_size** and the learning may not reduce quickly enough</u>; <u>too small and it may reduce too quickly</u>. Similarly, a gamma <u>too close 1 may not reduce the learning rate significantly enough, while a gamma too small may reduce it too quickly</u>.\n","\n","\n","\n","We now apply a learning rate to the k-fold cross validation example from the previous section."],"metadata":{"id":"UJjLcTxhyiWO"}},{"cell_type":"code","source":["import pandas as pd\n","from scipy.stats import zscore\n","from sklearn.model_selection import train_test_split\n","\n","# Read the data set\n","df = pd.read_csv(\n","    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n","    na_values=['NA','?'])\n","\n","# Generate dummies for job\n","df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\",dtype=int)],axis=1)\n","df.drop('job', axis=1, inplace=True)\n","\n","# Generate dummies for area\n","df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\",dtype=int)],axis=1)\n","df.drop('area', axis=1, inplace=True)\n","\n","# Generate dummies for product\n","df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\",dtype=int)],axis=1)\n","df.drop('product', axis=1, inplace=True)\n","\n","# Missing values for income\n","med = df['income'].median()\n","df['income'] = df['income'].fillna(med)\n","\n","# Standardize ranges\n","df['income'] = zscore(df['income'])\n","df['aspect'] = zscore(df['aspect'])\n","df['save_rate'] = zscore(df['save_rate'])\n","df['subscriptions'] = zscore(df['subscriptions'])\n","\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"6lXwmDqDygxQ","executionInfo":{"status":"ok","timestamp":1714712845764,"user_tz":-540,"elapsed":3272,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"ff06d84b-b914-4f7f-c045-28b554b821cd"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id    income    aspect  subscriptions  dist_healthy  save_rate  \\\n","0   1 -0.607550 -0.664918      -0.208449      9.017895  -0.215764   \n","1   2  0.338053 -0.207748       0.839031      7.766643   0.196869   \n","2   3 -0.184205  1.127906      -0.208449      3.632069  -0.714362   \n","3   4 -0.526467 -0.440815      -0.208449      5.372942  -0.542432   \n","4   5 -2.851675  1.638861       1.886511      3.822477  -0.473660   \n","\n","   dist_unhealthy  age  pop_dense  retail_dense  ...  area_b  area_c  area_d  \\\n","0       11.738935   49   0.885827      0.492126  ...       0       1       0   \n","1        6.805396   51   0.874016      0.342520  ...       0       1       0   \n","2       13.671772   44   0.944882      0.724409  ...       0       1       0   \n","3        4.333286   50   0.889764      0.444882  ...       0       1       0   \n","4        5.967121   38   0.744094      0.661417  ...       0       0       1   \n","\n","   product_a  product_b  product_c  product_d  product_e  product_f  product_g  \n","0          0          1          0          0          0          0          0  \n","1          0          0          1          0          0          0          0  \n","2          0          1          0          0          0          0          0  \n","3          0          1          0          0          0          0          0  \n","4          1          0          0          0          0          0          0  \n","\n","[5 rows x 55 columns]"],"text/html":["\n","  <div id=\"df-08737256-404b-4158-8cc9-dfa201c4a0b9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>income</th>\n","      <th>aspect</th>\n","      <th>subscriptions</th>\n","      <th>dist_healthy</th>\n","      <th>save_rate</th>\n","      <th>dist_unhealthy</th>\n","      <th>age</th>\n","      <th>pop_dense</th>\n","      <th>retail_dense</th>\n","      <th>...</th>\n","      <th>area_b</th>\n","      <th>area_c</th>\n","      <th>area_d</th>\n","      <th>product_a</th>\n","      <th>product_b</th>\n","      <th>product_c</th>\n","      <th>product_d</th>\n","      <th>product_e</th>\n","      <th>product_f</th>\n","      <th>product_g</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>-0.607550</td>\n","      <td>-0.664918</td>\n","      <td>-0.208449</td>\n","      <td>9.017895</td>\n","      <td>-0.215764</td>\n","      <td>11.738935</td>\n","      <td>49</td>\n","      <td>0.885827</td>\n","      <td>0.492126</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.338053</td>\n","      <td>-0.207748</td>\n","      <td>0.839031</td>\n","      <td>7.766643</td>\n","      <td>0.196869</td>\n","      <td>6.805396</td>\n","      <td>51</td>\n","      <td>0.874016</td>\n","      <td>0.342520</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>-0.184205</td>\n","      <td>1.127906</td>\n","      <td>-0.208449</td>\n","      <td>3.632069</td>\n","      <td>-0.714362</td>\n","      <td>13.671772</td>\n","      <td>44</td>\n","      <td>0.944882</td>\n","      <td>0.724409</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>-0.526467</td>\n","      <td>-0.440815</td>\n","      <td>-0.208449</td>\n","      <td>5.372942</td>\n","      <td>-0.542432</td>\n","      <td>4.333286</td>\n","      <td>50</td>\n","      <td>0.889764</td>\n","      <td>0.444882</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>-2.851675</td>\n","      <td>1.638861</td>\n","      <td>1.886511</td>\n","      <td>3.822477</td>\n","      <td>-0.473660</td>\n","      <td>5.967121</td>\n","      <td>38</td>\n","      <td>0.744094</td>\n","      <td>0.661417</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 55 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08737256-404b-4158-8cc9-dfa201c4a0b9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-08737256-404b-4158-8cc9-dfa201c4a0b9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-08737256-404b-4158-8cc9-dfa201c4a0b9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7b01502a-9f00-43c2-847a-f41d2c74e92a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b01502a-9f00-43c2-847a-f41d2c74e92a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7b01502a-9f00-43c2-847a-f41d2c74e92a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Now that the feature vector is created a 5-fold cross-validation can be performed to generate out-of-sample predictions. We will assume 500 epochs and not use early stopping. Later we will see how we can estimate a more optimal poch count."],"metadata":{"id":"eXI6R0pn2ekW"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"T55AsjkT2Y6_","executionInfo":{"status":"ok","timestamp":1714712974476,"user_tz":-540,"elapsed":330,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Convert to PyTorch tensors\n","x_columns = df.columns.drop(['age', 'id'])\n","x = torch.tensor(df[x_columns].values, dtype=torch.float32, device=device)\n","y = torch.tensor(df['age'].values, dtype=torch.float32, device=device)\n","\n","torch.manual_seed(42)\n","\n","# Cross-Validation\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Early stopping parameters\n","patience = 10\n","\n","fold = 0\n","for train_index, test_index in kf.split(x):\n","    fold += 1\n","    print(f\"Fold {fold}\")\n","\n","    x_train, x_test = x[train_index], x[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    # PyTorch DataLoader\n","    train_dataset = TensorDataset(x_train, y_train)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","    # Create the model and optimizer\n","    model = nn.Sequential(\n","        nn.Linear(x.shape[1], 64),\n","        nn.ReLU(),\n","        nn.Linear(64, 32),\n","        nn.ReLU(),\n","        nn.Linear(32, 1)\n","    )\n","    model = torch.compile(model, backend=\"aot_eager\").to(device)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=0.01)\n","    # adjust learning rate every 50 epochs\n","    scheduler = StepLR(optimizer, step_size=50, gamma=0.90)\n","    loss_fn = nn.MSELoss()\n","\n","    # Early Stopping variables\n","    best_loss = float('inf')\n","    early_stopping_counter = 0\n","\n","    # Training loop\n","    EPOCHS = 500\n","    epoch = 0\n","    done = False\n","    es = EarlyStopping()\n","\n","    while not done and epoch < EPOCHS:\n","        epoch += 1\n","        model.train()\n","        for x_batch, y_batch in train_loader:\n","            optimizer.zero_grad()\n","            output = model(x_batch)\n","            loss = loss_fn(output, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","        scheduler.step() # apply learning rate schedule\n","        # Print learning rate\n","        print(f\"Epoch {epoch}, LR: {scheduler.get_last_lr()}\")\n","\n","        # Validation\n","        model.eval()\n","        with torch.no_grad():\n","            val_output = model(x_test)\n","            val_loss = loss_fn(val_output, y_test)\n","\n","        # Check Early Stopping\n","        if es(model, val_loss):\n","            done = True\n","\n","    print(f\"Epoch {epoch}/{EPOCHS}, Validation Loss: {val_loss.item()}, {es.status}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hBgKN7125DP","executionInfo":{"status":"ok","timestamp":1714715511853,"user_tz":-540,"elapsed":12208,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"e2c7d322-f5ea-4d0c-f0ea-9da5ecab693c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Epoch 1, LR: [0.01]\n","Epoch 2, LR: [0.01]\n","Epoch 3, LR: [0.01]\n","Epoch 4, LR: [0.01]\n","Epoch 5, LR: [0.01]\n","Epoch 6, LR: [0.01]\n","Epoch 7, LR: [0.01]\n","Epoch 8, LR: [0.01]\n","Epoch 9, LR: [0.01]\n","Epoch 10, LR: [0.01]\n","Epoch 11, LR: [0.01]\n","Epoch 12, LR: [0.01]\n","Epoch 13, LR: [0.01]\n","Epoch 14, LR: [0.01]\n","Epoch 15, LR: [0.01]\n","Epoch 16, LR: [0.01]\n","Epoch 17, LR: [0.01]\n","Early stopping after 5 epochs\n","Epoch 17/500, Validation Loss: 14.946890830993652, No improvement in the last 5 epochs\n","Fold 2\n","Epoch 1, LR: [0.01]\n","Epoch 2, LR: [0.01]\n","Epoch 3, LR: [0.01]\n","Epoch 4, LR: [0.01]\n","Epoch 5, LR: [0.01]\n","Epoch 6, LR: [0.01]\n","Epoch 7, LR: [0.01]\n","Epoch 8, LR: [0.01]\n","Epoch 9, LR: [0.01]\n","Epoch 10, LR: [0.01]\n","Epoch 11, LR: [0.01]\n","Early stopping after 5 epochs\n","Epoch 11/500, Validation Loss: 17.777740478515625, No improvement in the last 5 epochs\n","Fold 3\n","Epoch 1, LR: [0.01]\n","Epoch 2, LR: [0.01]\n","Epoch 3, LR: [0.01]\n","Epoch 4, LR: [0.01]\n","Epoch 5, LR: [0.01]\n","Epoch 6, LR: [0.01]\n","Epoch 7, LR: [0.01]\n","Epoch 8, LR: [0.01]\n","Epoch 9, LR: [0.01]\n","Epoch 10, LR: [0.01]\n","Epoch 11, LR: [0.01]\n","Epoch 12, LR: [0.01]\n","Epoch 13, LR: [0.01]\n","Epoch 14, LR: [0.01]\n","Epoch 15, LR: [0.01]\n","Epoch 16, LR: [0.01]\n","Epoch 17, LR: [0.01]\n","Epoch 18, LR: [0.01]\n","Epoch 19, LR: [0.01]\n","Epoch 20, LR: [0.01]\n","Epoch 21, LR: [0.01]\n","Early stopping after 5 epochs\n","Epoch 21/500, Validation Loss: 14.276761054992676, No improvement in the last 5 epochs\n","Fold 4\n","Epoch 1, LR: [0.01]\n","Epoch 2, LR: [0.01]\n","Epoch 3, LR: [0.01]\n","Epoch 4, LR: [0.01]\n","Epoch 5, LR: [0.01]\n","Epoch 6, LR: [0.01]\n","Epoch 7, LR: [0.01]\n","Epoch 8, LR: [0.01]\n","Epoch 9, LR: [0.01]\n","Epoch 10, LR: [0.01]\n","Epoch 11, LR: [0.01]\n","Epoch 12, LR: [0.01]\n","Epoch 13, LR: [0.01]\n","Epoch 14, LR: [0.01]\n","Epoch 15, LR: [0.01]\n","Epoch 16, LR: [0.01]\n","Epoch 17, LR: [0.01]\n","Epoch 18, LR: [0.01]\n","Epoch 19, LR: [0.01]\n","Early stopping after 5 epochs\n","Epoch 19/500, Validation Loss: 16.710840225219727, No improvement in the last 5 epochs\n","Fold 5\n","Epoch 1, LR: [0.01]\n","Epoch 2, LR: [0.01]\n","Epoch 3, LR: [0.01]\n","Epoch 4, LR: [0.01]\n","Epoch 5, LR: [0.01]\n","Epoch 6, LR: [0.01]\n","Epoch 7, LR: [0.01]\n","Epoch 8, LR: [0.01]\n","Epoch 9, LR: [0.01]\n","Epoch 10, LR: [0.01]\n","Epoch 11, LR: [0.01]\n","Epoch 12, LR: [0.01]\n","Epoch 13, LR: [0.01]\n","Epoch 14, LR: [0.01]\n","Epoch 15, LR: [0.01]\n","Epoch 16, LR: [0.01]\n","Epoch 17, LR: [0.01]\n","Epoch 18, LR: [0.01]\n","Epoch 19, LR: [0.01]\n","Epoch 20, LR: [0.01]\n","Epoch 21, LR: [0.01]\n","Epoch 22, LR: [0.01]\n","Epoch 23, LR: [0.01]\n","Early stopping after 5 epochs\n","Epoch 23/500, Validation Loss: 13.688310623168945, No improvement in the last 5 epochs\n"]}]},{"cell_type":"code","source":["# Final evaluation\n","model.eval()\n","with torch.no_grad():\n","    oos_pred = model(x_test)\n","score = torch.sqrt(loss_fn(oos_pred, y_test))\n","print(f\"Fold score (RMSE): {score.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rte_tAt56nH0","executionInfo":{"status":"ok","timestamp":1714715532540,"user_tz":-540,"elapsed":262,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"7fea72f0-8706-4e24-818b-ecf5bdaa997e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold score (RMSE): 3.5678391456604004\n"]}]},{"cell_type":"code","source":["scheduler.get_last_lr()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yV2_fYT97baB","executionInfo":{"status":"ok","timestamp":1714715422265,"user_tz":-540,"elapsed":244,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"e1286f8e-b1f5-429e-be71-3c9c84b7960f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.01]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# explanation by gpt4\n","**StepLR** is a learning rate scheduler available in PyTorch's **torch.optim.lr_scheduler** module. It is used to adjust the learning rate during training by decreasing it at specified intervals. This can help in fine-tuning the model's training process, potentially leading to better performance and faster convergence.\n","\n","## How `StepLR` Works\n","**StepLR** reduces the learning rate of each parameter group by a factor of **gamma** every **step_size** epochs. The idea is to decrease the learning rate by some factor after a certain number of epochs, which can help in getting coloser to the global minimum of the loss function.\n","\n","## Basic Usage of `StepLR`\n","Here's how you typically set up and use **StepLR**\n","1. **Initialize Your Optimizer**: First, define an optimizer (like SGD, Adam, etc.) which will update the model's weights.\n","2. **Define the Scheduler**: Set up the **StepLR** shceduler by specifying the optimizer, the **step_size** (number of epochs after which to adjust the learning rate), and **gamma** (the factor by which the learning rate is reduced).\n","3. **Training Loop**: During the training loop, you execute the optimizer to update the weights, and then you step the scheduler ata the end of each epoch (or at another specified point).\n","\n","Here is a simple example in code:"],"metadata":{"id":"_yNdgoMl9REV"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","\n","# Sample model\n","model = nn.Linear(10, 2)\n","\n","# Optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# Scheduler\n","scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n","\n","# Example training loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    # Training code here\n","    # model.train()\n","    # loss.backward()\n","    # optimizer.step()\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Print learning rate\n","    print(f\"Epoch {epoch+1}, LR: {scheduler.get_last_lr()}\")"],"metadata":{"id":"qfX1x0Fq9VMa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this example:\n","* Ther learning rate starts at 0.1.\n","* After every 30 epochs, ot is reduced to 10% of its previous value (**gamma=0.1**).\n","* **scheduler.get_last_lr()** is used to check the learning rate at each epoch."],"metadata":{"id":"khJq0hUp_zh7"}},{"cell_type":"markdown","source":["## Example code"],"metadata":{"id":"H6opsQ1WAxaV"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","import numpy as np\n","\n","# Setting random seed for reproducibility\n","torch.manual_seed(0)\n","np.random.seed(0)"],"metadata":{"id":"BFnraMLBAytR","executionInfo":{"status":"ok","timestamp":1714715604260,"user_tz":-540,"elapsed":263,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Synthetic data generation\n","# 100 data points, 1 feature each\n","x = np.random.rand(100, 1).astype(np.float32)  # Feature\n","y = 3 * x + np.random.randn(100, 1).astype(np.float32) * 0.1  # Target\n","display(x[:10])\n","display(y[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"P_Ci7q71A7KJ","executionInfo":{"status":"ok","timestamp":1714715630057,"user_tz":-540,"elapsed":277,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"f592011f-95a7-4d1b-9fed-ecb6cd876a0a"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["array([[0.5488135 ],\n","       [0.71518934],\n","       [0.60276335],\n","       [0.5448832 ],\n","       [0.4236548 ],\n","       [0.6458941 ],\n","       [0.4375872 ],\n","       [0.891773  ],\n","       [0.96366274],\n","       [0.3834415 ]], dtype=float32)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["array([[1.5299256],\n","       [2.2356505],\n","       [1.8548563],\n","       [1.4810251],\n","       [1.4197896],\n","       [2.1272714],\n","       [1.4306395],\n","       [2.6573265],\n","       [2.7839131],\n","       [1.2557697]], dtype=float32)"]},"metadata":{}}]},{"cell_type":"code","source":["# Convert numpy array to torch tensors\n","x_train = torch.from_numpy(x)\n","y_train = torch.from_numpy(y)\n","\n","# Model definition (simple linear regression)\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super(LinearRegressionModel, self).__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","model = LinearRegressionModel()\n","\n","# Loss function\n","criterion = nn.MSELoss()\n","\n","# Optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# Learning rate scheduler\n","scheduler = StepLR(optimizer, step_size=10, gamma=0.9)"],"metadata":{"id":"SBwb1asRBBda","executionInfo":{"status":"ok","timestamp":1714715748429,"user_tz":-540,"elapsed":2293,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    # Forward pass\n","    output = model(x_train)\n","    loss = criterion(output, y_train)\n","\n","    # Backward pass and optimization\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    if (epoch+1) % 5 == 0:\n","        current_lr = scheduler.get_last_lr()[0]\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, LR: {current_lr:.4f}\")\n","\n","# Check the final parameters of the model\n","print(\"Final parameters:\")\n","for name, param in model.named_parameters():\n","    print(f\"{name}: {param.data}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlT_8UVhBdjk","executionInfo":{"status":"ok","timestamp":1714715942031,"user_tz":-540,"elapsed":262,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"a0e5cfcb-7d51-471f-9284-ad3bad1a3bc4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 5/50, Loss: 0.4610, LR: 0.0900\n","Epoch 10/50, Loss: 0.4035, LR: 0.0900\n","Epoch 15/50, Loss: 0.3582, LR: 0.0810\n","Epoch 20/50, Loss: 0.3214, LR: 0.0810\n","Epoch 25/50, Loss: 0.2891, LR: 0.0729\n","Epoch 30/50, Loss: 0.2625, LR: 0.0729\n","Epoch 35/50, Loss: 0.2388, LR: 0.0656\n","Epoch 40/50, Loss: 0.2190, LR: 0.0656\n","Epoch 45/50, Loss: 0.2014, LR: 0.0590\n","Epoch 50/50, Loss: 0.1864, LR: 0.0590\n","Final parameters:\n","linear.weight: tensor([[1.5580]])\n","linear.bias: tensor([0.7498])\n"]}]},{"cell_type":"markdown","source":["* The model is trained on a synthetic dataset where the true relationship is **y = 3x + noise**.\n","* **StepLR** decrease the learning rate by 10 % every 10 epochs, helping in potentially finer adjustments towards the end of training.\n","* The training loop points the loss and the current learning rate every 5 epochs."],"metadata":{"id":"7Z3KzBYXCZkI"}},{"cell_type":"code","source":[],"metadata":{"id":"tTY5oZvTCNmw"},"execution_count":null,"outputs":[]}]}