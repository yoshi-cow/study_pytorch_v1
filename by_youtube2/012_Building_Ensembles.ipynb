{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIGfZDqxd9yCIXwga0HAur"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# # Building Ensembles with Scikit-Learn and PyTorch\n","* https://www.youtube.com/watch?v=przbLRCRL24&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi&index=39\n","* https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_08_2_pytorch_ensembles.ipynb\n","\n","\n"],"metadata":{"id":"gN3UJb3UW2yl"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WK0tGB6WxZi","executionInfo":{"status":"ok","timestamp":1716605199880,"user_tz":-540,"elapsed":19320,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"57757067-6ac7-49e3-a742-ea29547aff03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"]},{"cell_type":"code","source":["# Notice formatted time string\n","def hms_string(sec_elapsed):\n","    h = int(sec_elapsed / (60 * 60))\n","    m = int((sec_elapsed % (60 * 60)) / 60)\n","    s = sec_elapsed % 60\n","    return f\"{h}:{m}:{round(s,1)}\""],"metadata":{"id":"Z0djCKieXKm0","executionInfo":{"status":"ok","timestamp":1716605201690,"user_tz":-540,"elapsed":243,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Early stopping\n","import copy\n","class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.restore_best_weights = restore_best_weights\n","        self.best_model = None\n","        self.best_loss = None\n","        self.counter = 0\n","        self.status = \"\"\n","\n","    def __call__(self, model, val_loss):\n","        if self.best_model is None:\n","            self.best_model = copy.deepcopy(model.state_dict())\n","            self.best_loss = val_loss\n","        elif self.best_loss - val_loss > self.min_delta:\n","            self.best_model = copy.deepcopy(model.state_dict())\n","            self.best_loss = val_loss\n","            self.counter = 0\n","            self.status = f\"Improvement found, counter reset to {self.counter}\"\n","        else:\n","            self.counter += 1\n","            self.status = f\"No improvement in the last {self.counter} epochs\"\n","            if self.counter >= self.patience:\n","                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n","                if self.restore_best_weights:\n","                    model.load_state_dict(self.best_model)\n","                return True\n","        return False\n","\n","\n","# Make use of a GPU or cpu\n","import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qj_pU5BnXe3j","executionInfo":{"status":"ok","timestamp":1716605203608,"user_tz":-540,"elapsed":229,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"e45df08f-808e-4860-8dcc-b01fc538b2ac"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["## Evaluating Feature Importance\n","Feature importance tells us how important each feature (from the feature/import vector) is to predicting a neural network or another model. There are many different ways to evaluate the feature importance of neural networks. The following paper presents an excellent (and readable) overview of the varios means of assessing the significance of neural network inputs/features.\n","    * An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data [http://depts.washington.edu/oldenlab/wordpress/wp-content/uploads/2013/03/EcologicalModelling_2004.pdf]. Ecological Modelling, 178(3), 389-397.\n","\n","In summary, the following methods are available to neural networks:\n","* Connection Weights Algorithm\n","* Partial Derivatives\n","* Input Perturbation\n","* Sensitivity Analysis\n","* Forward Stepwise Addition\n","* Improved Stepwise Selection 1\n","* Backward Stepwise Elimination\n","* Improved Stepwise Selection\n","\n","For this chapter, we will use the input Perturbation feature ranking algorithm. This algorithm will work with any regression or claasification network. In the next section, I provide an implementation of the input perturbation algorithm for scikit-learn. This code implements a function below that will work with any scikit-learn model.\n","\n","\n","Leo Breiman provided this algorithm in his seminal paper on random forests. Althourh he presented this algorithm in conjunction with random forests, it is model-independent and appropriate for any supervised learning model. This algorithm, known as the input perturbation algorithm, works by evaluating a trained model's accuracy with each input individually shuffled from a data set.\n","Shuffling an input causes it to become useless -- effectivvely removing it from the model. More important inputs will produce a less accurate score when they are removed by shuffling them. This process makes sense because important features will contribute to the model's accuracy.\n","    * Early stabilizing feature importance for TensorFlow deep neural networks [https://www.heatonresearch.com/dload/phd/IJCNN%202017-v2-final.pdf]\n","\n","This algorithm will use log loss to evaluate a classification problem and RMSE for regression.\n"],"metadata":{"id":"QmdWjMvfYdrZ"}},{"cell_type":"code","source":["from sklearn import metrics\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"jn_B05rSYbx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def perturbation_rank(device, model, x, y, names, regression):\n","    model.to(device)\n","    model.eval() # Set the model to evaluation mode\n","\n","    errors = []\n","\n","    for i in range(x.shape[1]):\n","        hold = x[:, i].clone() # 元の列値を保存\n","        # i列の値を乱数で置き換える\n","        x[:, i] = torch.randperm(x.shape[0]).to(device) # randperm:整数の順列を生成\n","\n","        with torch.no_grad():\n","            pred = model(x)\n","\n","        if regression:\n","            loss_fn = nn.MSELoss()\n","            error = loss_fn(pred, y).item()\n","        else:\n","            # pred should be probabilities: apply softmax if not done in model's forward method\n","            if len(pred.shape) == 2 and pred.shape[1] > 1: # 分類数が2以上ならsoftmax\n","                pred = F.softmax(pred, dim=1)\n","                loss_fn = nn.CrossEntropyLoss()\n","                error = loss_fn(pred, y.long()).item()\n","            else:\n","                loss_fn = nn.MSELoss() # Mean Square Loss\n","                error = loss_fn(pred, y).item()\n","\n","        errors.append(error)\n","        x[:, i] = hold\n","\n","    # feature importanceの算出\n","    max_error = max(errors)\n","    importances = [e / max_error for e in errors]\n","\n","    data = {'name': names, 'error':errors, 'importance':importances}\n","    result = pd.DataFrame(data, columns=[ 'name', 'error', 'importance'])\n","    result = result.sort_values(by='importance', ascending=False)\n","    result.reset_index(inplace=True, drop=True)\n","    return result"],"metadata":{"id":"VvOi3C0obyn7","executionInfo":{"status":"ok","timestamp":1716605703702,"user_tz":-540,"elapsed":255,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Classification and Input Perturbation Ranking\n","We now look at the code to perform perturbation ranking for a classification neural network. The implementation technique is slightly diffferent for classification vs. regression, so I must provide two different implementaions. The primary difference between classification and regression is how we evaluate the accuracy of the neural network in each of these two network types. We will use the Root Mean Square (RMSE) error calculatuion, whereas we will use log loss for classirfication."],"metadata":{"id":"cWk71vaOfj14"}},{"cell_type":"code","source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import tqdm\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from torch import nn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"Rvx5LjgCenaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from os import XATTR_CREATE\n","# Set random seed for reproducibility\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","def load_data():\n","    df = pd.read_csv(\n","        \"https://data.heatonresearch.com/data/t81-558/iris.csv\", na_values=[\"NA\", \"?\"]\n","    )\n","\n","    le = LabelEncoder() # transform category to numbers\n","\n","    x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n","    y = le.fit_transform(df[\"species\"])\n","    species = le.classes_\n","\n","    # Split into validation and training stes\n","    x_train, x_test, y_train, y_test = train_test_split(\n","        x, y, test_size=0.25, random_state=42\n","    )\n","\n","    scaler = StandardScaler()\n","    x_train = scaler.fit_transform(x_train)\n","    x_test = scaler.transform(x_test)\n","\n","    # Numpy to Torch Tensor\n","    x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n","    y_train = torch.tensor(y_train, device=device, dtype=torch.long)\n","\n","    x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n","    y_test = torch.tensor(y_test, device=device, dtype=torch.long)\n","\n","    return x_train, x_test, y_train, y_test, species, df.columns\n","\n","x_train, x_test, y_train, y_test, species, columns = load_data()\n","columns = list(columns)\n","columns.remove(\"species\") # remove the target(y)"],"metadata":{"id":"tEbGax7Qgbnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create datasets\n","BATCH_SIZE = 16\n","\n","dataset_train = TensorDataset(x_train, y_train)\n","dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","\n","dataset_test = TensorDataset(x_test, y_test)\n","dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Create model using nn.Sequenctial\n","model = nn.Sequential(\n","    nn.Linear(x_train.shape[1], 50),\n","    nn.ReLU(),\n","    nn.Linear(50, 25),\n","    nn.ReLU(),\n","    nn.Linear(25, len(species)),\n","    nn.LogSoftmax(dim=1),\n",")\n","\n","model = torch.compile(model, backend=\"aot_eager\").to(device)\n","\n","# Set loss\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Set optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","# Set early stopping\n","es = EarlyStopping()\n","\n","epoch = 0\n","done = False\n","while epoch < 1000 and not done:\n","    epoch += 1\n","    steps = list(enumerate(dataloader_train))\n","    pbar = tqdm.tqdm(steps)\n","    model.train()\n","    for i, (x_batch, y_batch) in pbar:\n","        y_batch_pred = model(x_batch.to(device))\n","        loss = loss_fn(y_batch_pred, y_batch.to(device))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss, current = loss.item(), (i + 1) * len(x_batch)\n","        if i == len(steps) - 1:\n","            model.eval()\n","            with torch.no_grad():\n","                pred = model(x_test.to(device))\n","                vloss = loss_fn(pred, y_test.to(device))\n","                if es(model, vloss):\n","                    done = True\n","                pbar.set_description(\n","                    f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, {es.status}\"\n","                )\n","        else:\n","            pbar.set_description(f\"Epoch: {epoch}, tloss: {loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSFjZMEWj1WP","executionInfo":{"status":"ok","timestamp":1716470173308,"user_tz":-540,"elapsed":2354,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"92750718-0572-482d-8054-f57bd1cb49aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch: 1, tloss: 0.7962242960929871, vloss: 0.607716, : 100%|██████████| 7/7 [00:00<00:00, 13.25it/s]\n","Epoch: 2, tloss: 0.2632836103439331, vloss: 0.254798, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 143.22it/s]\n","Epoch: 3, tloss: 0.1994396448135376, vloss: 0.159267, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 149.91it/s]\n","Epoch: 4, tloss: 0.18039251863956451, vloss: 0.096190, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 128.36it/s]\n","Epoch: 5, tloss: 0.0985158309340477, vloss: 0.062836, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 137.68it/s]\n","Epoch: 6, tloss: 0.16301701962947845, vloss: 0.045974, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 150.73it/s]\n","Epoch: 7, tloss: 0.02891465462744236, vloss: 0.035409, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 164.05it/s]\n","Epoch: 8, tloss: 0.030066024512052536, vloss: 0.024942, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 161.55it/s]\n","Epoch: 9, tloss: 0.03914439678192139, vloss: 0.020477, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 157.50it/s]\n","Epoch: 10, tloss: 0.030633065849542618, vloss: 0.016798, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 154.74it/s]\n","Epoch: 11, tloss: 0.014532243832945824, vloss: 0.018231, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 141.48it/s]\n","Epoch: 12, tloss: 0.01648210734128952, vloss: 0.025751, No improvement in the last 2 epochs: 100%|██████████| 7/7 [00:00<00:00, 153.57it/s]\n","Epoch: 13, tloss: 0.06064366549253464, vloss: 0.024878, No improvement in the last 3 epochs: 100%|██████████| 7/7 [00:00<00:00, 166.91it/s]\n","Epoch: 14, tloss: 0.04101092368364334, vloss: 0.018499, No improvement in the last 4 epochs: 100%|██████████| 7/7 [00:00<00:00, 162.87it/s]\n","Epoch: 15, tloss: 0.046192675828933716, vloss: 0.012727, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 157.56it/s]\n","Epoch: 16, tloss: 0.010899770073592663, vloss: 0.011212, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 154.86it/s]\n","Epoch: 17, tloss: 0.02252686396241188, vloss: 0.012401, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 147.13it/s]\n","Epoch: 18, tloss: 0.03171501308679581, vloss: 0.011783, No improvement in the last 2 epochs: 100%|██████████| 7/7 [00:00<00:00, 168.08it/s]\n","Epoch: 19, tloss: 0.009481927379965782, vloss: 0.012010, No improvement in the last 3 epochs: 100%|██████████| 7/7 [00:00<00:00, 170.16it/s]\n","Epoch: 20, tloss: 0.009991859085857868, vloss: 0.010436, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 164.23it/s]\n","Epoch: 21, tloss: 0.10992459207773209, vloss: 0.010044, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 169.18it/s]\n","Epoch: 22, tloss: 0.013172534294426441, vloss: 0.010518, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 159.97it/s]\n","Epoch: 23, tloss: 0.01253864448517561, vloss: 0.011897, No improvement in the last 2 epochs: 100%|██████████| 7/7 [00:00<00:00, 145.64it/s]\n","Epoch: 24, tloss: 0.03169569373130798, vloss: 0.011526, No improvement in the last 3 epochs: 100%|██████████| 7/7 [00:00<00:00, 173.47it/s]\n","Epoch: 25, tloss: 0.006008796859532595, vloss: 0.010473, No improvement in the last 4 epochs: 100%|██████████| 7/7 [00:00<00:00, 156.83it/s]\n","Epoch: 26, tloss: 0.0107010118663311, vloss: 0.009187, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 169.66it/s]\n","Epoch: 27, tloss: 0.1295660436153412, vloss: 0.009740, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 185.32it/s]\n","Epoch: 28, tloss: 0.0021880674175918102, vloss: 0.008963, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 172.97it/s]\n","Epoch: 29, tloss: 0.0031072518322616816, vloss: 0.007448, Improvement found, counter reset to 0: 100%|██████████| 7/7 [00:00<00:00, 144.17it/s]\n","Epoch: 30, tloss: 0.004220014438033104, vloss: 0.008109, No improvement in the last 1 epochs: 100%|██████████| 7/7 [00:00<00:00, 167.47it/s]\n","Epoch: 31, tloss: 0.0003137270687147975, vloss: 0.013140, No improvement in the last 2 epochs: 100%|██████████| 7/7 [00:00<00:00, 161.53it/s]\n","Epoch: 32, tloss: 0.13367265462875366, vloss: 0.015228, No improvement in the last 3 epochs: 100%|██████████| 7/7 [00:00<00:00, 128.55it/s]\n","Epoch: 33, tloss: 0.020383430644869804, vloss: 0.014174, No improvement in the last 4 epochs: 100%|██████████| 7/7 [00:00<00:00, 164.04it/s]\n","Epoch: 34, tloss: 0.02645985037088394, vloss: 0.012105, Early stopping triggered after 5 epochs.: 100%|██████████| 7/7 [00:00<00:00, 151.80it/s]\n"]}]},{"cell_type":"markdown","source":["Next, we evaluate the accuracy of the trained model. Here we see that the neural network performs great with an accuracy of 1.0. We might fear overfitting with such high accuracy for a more complex dataset. However, for this example, we are more interested in determining the importance of each column."],"metadata":{"id":"1zRbD6zRmIsK"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","pred = model(x_test)\n","_, predict_classes = torch.max(pred, dim=1)\n","print('Accuracy:')\n","accuracy_score(y_test.cpu().numpy(), predict_classes.cpu().numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCOTHAthmAdv","executionInfo":{"status":"ok","timestamp":1716470280637,"user_tz":-540,"elapsed":269,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"bdd1c979-dc57-4753-f1e1-2144b402b9be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:\n"]},{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["We are now ready to call the input perturbation algorithm. First, we extract the column names and remove the target column. The target column is not important, as it is the objective, not one of the inputs. In supervised learning, the target is of the utmost importance.\n","\n","\n","We can see importance displayed in the following table. The most important column is always 1.0, and lessor columns will continue in a downward trend. The least important column will have the lowest rank."],"metadata":{"id":"iV24D45Jm0RA"}},{"cell_type":"code","source":["# Rank the features\n","from IPython.display import display, HTML\n","\n","rank = perturbation_rank(device, model, x_test, y_test, columns, False)\n","display(rank)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"XL1FUSr7mbvm","executionInfo":{"status":"ok","timestamp":1716470548733,"user_tz":-540,"elapsed":313,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"a6eb4bcf-3dc4-42be-ce41-60a0c7ba82b9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["      name     error  importance\n","0  petal_w  1.205691    1.000000\n","1  petal_l  1.197067    0.992847\n","2  sepal_w  1.081718    0.897176\n","3  sepal_l  0.968614    0.803368"],"text/html":["\n","  <div id=\"df-8d3feec2-9718-435f-8f4b-1f08eb5625bb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>error</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>petal_w</td>\n","      <td>1.205691</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>petal_l</td>\n","      <td>1.197067</td>\n","      <td>0.992847</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sepal_w</td>\n","      <td>1.081718</td>\n","      <td>0.897176</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sepal_l</td>\n","      <td>0.968614</td>\n","      <td>0.803368</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d3feec2-9718-435f-8f4b-1f08eb5625bb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8d3feec2-9718-435f-8f4b-1f08eb5625bb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8d3feec2-9718-435f-8f4b-1f08eb5625bb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7f5f7543-d435-441d-8da8-c3a512ca65dc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f5f7543-d435-441d-8da8-c3a512ca65dc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7f5f7543-d435-441d-8da8-c3a512ca65dc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_3d0259c4-aded-4bf0-a04c-a57fce34cb77\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rank')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3d0259c4-aded-4bf0-a04c-a57fce34cb77 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('rank');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"rank","summary":"{\n  \"name\": \"rank\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"petal_l\",\n          \"sepal_l\",\n          \"petal_w\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11178043334073762,\n        \"min\": 0.968613862991333,\n        \"max\": 1.2056913375854492,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.1970670223236084,\n          0.968613862991333,\n          1.2056913375854492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09271065475562942,\n        \"min\": 0.8033680203186214,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9928469957500797,\n          0.8033680203186214,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Regression and Input Perturbation Ranking\n","We now see how to use input perturbation ranking for a regression neural network. we will use the MPG dataset as a demonstration. The code below loads the MPG dataset and creates a regression neural network for this dataset. The code trains the neural network and calculates an RMSE evaluation."],"metadata":{"id":"GS8fHsnvomDb"}},{"cell_type":"code","source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import tqdm\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"TXHYijXVnW2-","executionInfo":{"status":"ok","timestamp":1716605161363,"user_tz":-540,"elapsed":284,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Read the MPG dataset.\n","df = pd.read_csv(\n","    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", na_values=[\"NA\", \"?\"]\n",")\n","\n","cars = df[\"name\"]\n","\n","# Handle missing value\n","df[\"horsepower\"] = df[\"horsepower\"].fillna(df[\"horsepower\"].median())\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"id":"MbXELpvxobGT","executionInfo":{"status":"ok","timestamp":1716605163920,"user_tz":-540,"elapsed":256,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"94983c09-68e4-4dec-dd64-3fab0cde4510"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n","0  18.0          8         307.0       130.0    3504          12.0    70   \n","1  15.0          8         350.0       165.0    3693          11.5    70   \n","2  18.0          8         318.0       150.0    3436          11.0    70   \n","3  16.0          8         304.0       150.0    3433          12.0    70   \n","4  17.0          8         302.0       140.0    3449          10.5    70   \n","\n","   origin                       name  \n","0       1  chevrolet chevelle malibu  \n","1       1          buick skylark 320  \n","2       1         plymouth satellite  \n","3       1              amc rebel sst  \n","4       1                ford torino  "],"text/html":["\n","  <div id=\"df-700ed903-69a4-4dd0-9675-11e8b6ad3e08\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mpg</th>\n","      <th>cylinders</th>\n","      <th>displacement</th>\n","      <th>horsepower</th>\n","      <th>weight</th>\n","      <th>acceleration</th>\n","      <th>year</th>\n","      <th>origin</th>\n","      <th>name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18.0</td>\n","      <td>8</td>\n","      <td>307.0</td>\n","      <td>130.0</td>\n","      <td>3504</td>\n","      <td>12.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>chevrolet chevelle malibu</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15.0</td>\n","      <td>8</td>\n","      <td>350.0</td>\n","      <td>165.0</td>\n","      <td>3693</td>\n","      <td>11.5</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>buick skylark 320</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18.0</td>\n","      <td>8</td>\n","      <td>318.0</td>\n","      <td>150.0</td>\n","      <td>3436</td>\n","      <td>11.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>plymouth satellite</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>16.0</td>\n","      <td>8</td>\n","      <td>304.0</td>\n","      <td>150.0</td>\n","      <td>3433</td>\n","      <td>12.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>amc rebel sst</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17.0</td>\n","      <td>8</td>\n","      <td>302.0</td>\n","      <td>140.0</td>\n","      <td>3449</td>\n","      <td>10.5</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>ford torino</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-700ed903-69a4-4dd0-9675-11e8b6ad3e08')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-700ed903-69a4-4dd0-9675-11e8b6ad3e08 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-700ed903-69a4-4dd0-9675-11e8b6ad3e08');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-784af939-01ef-4bb4-b08c-94bddc3f12b3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-784af939-01ef-4bb4-b08c-94bddc3f12b3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-784af939-01ef-4bb4-b08c-94bddc3f12b3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 398,\n  \"fields\": [\n    {\n      \"column\": \"mpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.815984312565782,\n        \"min\": 9.0,\n        \"max\": 46.6,\n        \"num_unique_values\": 129,\n        \"samples\": [\n          17.7,\n          30.5,\n          30.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cylinders\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          5,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"displacement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.26983817119591,\n        \"min\": 68.0,\n        \"max\": 455.0,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          122.0,\n          307.0,\n          360.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"horsepower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38.22262486810867,\n        \"min\": 46.0,\n        \"max\": 230.0,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          112.0,\n          93.5,\n          78.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 846,\n        \"min\": 1613,\n        \"max\": 5140,\n        \"num_unique_values\": 351,\n        \"samples\": [\n          3730,\n          1995,\n          2215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acceleration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.757688929812676,\n        \"min\": 8.0,\n        \"max\": 24.8,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          14.7,\n          18.0,\n          14.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 70,\n        \"max\": 82,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          81,\n          79,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"origin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 305,\n        \"samples\": [\n          \"mazda rx-4\",\n          \"ford f108\",\n          \"buick century luxus (sw)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Pandas to Numpy\n","x = df[\n","    [\n","        \"cylinders\",\n","        \"displacement\",\n","        \"horsepower\",\n","        \"weight\",\n","        \"acceleration\",\n","        \"year\",\n","        \"origin\",\n","    ]\n","].values\n","y = df[\"mpg\"].values  # regression\n","\n","# Split into validation and training sets\n","x_train, x_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.25, random_state=42\n",")\n","\n","# Numpy to Torch Tensor\n","x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n","y_train = torch.tensor(y_train, device=device, dtype=torch.float32)\n","\n","x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n","y_test = torch.tensor(y_test, device=device, dtype=torch.float32)\n","\n","\n","# Create datasets\n","BATCH_SIZE = 16\n","\n","dataset_train = TensorDataset(x_train, y_train)\n","dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n","\n","dataset_test = TensorDataset(x_test, y_test)\n","dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"Uy0yzbKaojgd","executionInfo":{"status":"ok","timestamp":1716605211171,"user_tz":-540,"elapsed":221,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create model\n","model = nn.Sequential(\n","    nn.Linear(x_train.shape[1], 50),\n","    nn.ReLU(),\n","    nn.Linear(50, 25),\n","    nn.ReLU(),\n","    nn.Linear(25, 1)\n",")\n","model = torch.compile(model, backend=\"aot_eager\").to(device)\n","\n","# Set loss function for regression\n","loss_fn = nn.MSELoss()\n","\n","# Set optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","# Set early stopping\n","es = EarlyStopping()\n","\n","\n","epoch = 0\n","done = False\n","while epoch < 1000 and not done:\n","    epoch += 1\n","    steps = list(enumerate(dataloader_train))\n","    pbar = tqdm.tqdm(steps)\n","    model.train()\n","    for i, (x_batch, y_batch) in pbar:\n","        y_batch_pred = model(x_batch.to(device)).flatten()\n","        loss = loss_fn(y_batch_pred, y_batch.to(device))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss, current = loss.item(), (i + 1) * len(x_batch)\n","        if i == len(steps) - 1:\n","            model.eval()\n","            with torch.no_grad():\n","                pred = model(x_test.to(device)).flatten()\n","                vloss = loss_fn(pred, y_test.to(device))\n","                if es(model, vloss):\n","                    done = True\n","                pbar.set_description(\n","                    f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, {es.status}\"\n","                )\n","        else:\n","            pbar.set_description(f\"Epoch: {epoch}, tloss: {loss}\")\n","\n","from sklearn import metrics\n","\n","# Measure RMSE error.\n","pred = model(x_test)\n","score = torch.sqrt(torch.nn.functional.mse_loss(pred.flatten(), y_test))\n","print(f\"RMSE: {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w_IijHgUo28J","executionInfo":{"status":"ok","timestamp":1716605577937,"user_tz":-540,"elapsed":9129,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"80f2291f-6206-46d8-aaf1-c0ce39ce753b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch: 1, tloss: 216.49368286132812, vloss: 456.890594, : 100%|██████████| 19/19 [00:01<00:00, 18.40it/s]\n","Epoch: 2, tloss: 317.75323486328125, vloss: 242.168182, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 99.67it/s] \n","Epoch: 3, tloss: 191.02847290039062, vloss: 191.179001, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 112.12it/s]\n","Epoch: 4, tloss: 91.01396179199219, vloss: 132.316315, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 35.11it/s]\n","Epoch: 5, tloss: 230.85031127929688, vloss: 99.294991, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 30.25it/s]\n","Epoch: 6, tloss: 103.84315490722656, vloss: 75.213066, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 55.16it/s]\n","Epoch: 7, tloss: 61.395042419433594, vloss: 71.006981, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 122.55it/s]\n","Epoch: 8, tloss: 108.26927185058594, vloss: 59.867733, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 122.17it/s]\n","Epoch: 9, tloss: 83.05687713623047, vloss: 44.233597, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 132.52it/s]\n","Epoch: 10, tloss: 40.376041412353516, vloss: 51.935596, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 125.14it/s]\n","Epoch: 11, tloss: 65.17689514160156, vloss: 49.989941, No improvement in the last 2 epochs: 100%|██████████| 19/19 [00:00<00:00, 108.04it/s]\n","Epoch: 12, tloss: 52.78339767456055, vloss: 39.248398, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 131.85it/s]\n","Epoch: 13, tloss: 85.906982421875, vloss: 30.393948, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 116.57it/s]\n","Epoch: 14, tloss: 38.7747802734375, vloss: 30.500032, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 122.49it/s]\n","Epoch: 15, tloss: 18.845876693725586, vloss: 26.342768, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 118.64it/s]\n","Epoch: 16, tloss: 62.637184143066406, vloss: 26.662970, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 125.52it/s]\n","Epoch: 17, tloss: 62.38875198364258, vloss: 24.917740, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 116.09it/s]\n","Epoch: 18, tloss: 18.576326370239258, vloss: 21.463614, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 112.75it/s]\n","Epoch: 19, tloss: 59.55481719970703, vloss: 22.652550, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 114.54it/s]\n","Epoch: 20, tloss: 48.48143768310547, vloss: 20.888521, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 111.15it/s]\n","Epoch: 21, tloss: 27.804073333740234, vloss: 25.664202, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 121.89it/s]\n","Epoch: 22, tloss: 13.265886306762695, vloss: 45.086388, No improvement in the last 2 epochs: 100%|██████████| 19/19 [00:00<00:00, 119.65it/s]\n","Epoch: 23, tloss: 22.12651252746582, vloss: 26.779924, No improvement in the last 3 epochs: 100%|██████████| 19/19 [00:00<00:00, 120.46it/s]\n","Epoch: 24, tloss: 26.656335830688477, vloss: 15.351737, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 127.65it/s]\n","Epoch: 25, tloss: 14.303378105163574, vloss: 16.784157, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 124.25it/s]\n","Epoch: 26, tloss: 60.8364372253418, vloss: 70.325966, No improvement in the last 2 epochs: 100%|██████████| 19/19 [00:00<00:00, 131.94it/s]\n","Epoch: 27, tloss: 21.100690841674805, vloss: 14.269979, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 125.03it/s]\n","Epoch: 28, tloss: 59.82828903198242, vloss: 18.622408, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 133.18it/s]\n","Epoch: 29, tloss: 36.92853927612305, vloss: 13.348475, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 117.77it/s]\n","Epoch: 30, tloss: 26.278972625732422, vloss: 27.824385, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 109.85it/s]\n","Epoch: 31, tloss: 16.138423919677734, vloss: 11.368303, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 104.75it/s]\n","Epoch: 32, tloss: 11.77750015258789, vloss: 9.298229, Improvement found, counter reset to 0: 100%|██████████| 19/19 [00:00<00:00, 112.27it/s]\n","Epoch: 33, tloss: 7.755146026611328, vloss: 10.447659, No improvement in the last 1 epochs: 100%|██████████| 19/19 [00:00<00:00, 112.06it/s]\n","Epoch: 34, tloss: 20.34096908569336, vloss: 13.249640, No improvement in the last 2 epochs: 100%|██████████| 19/19 [00:00<00:00, 107.36it/s]\n","Epoch: 35, tloss: 6.039215564727783, vloss: 29.150244, No improvement in the last 3 epochs: 100%|██████████| 19/19 [00:00<00:00, 110.50it/s]\n","Epoch: 36, tloss: 35.073822021484375, vloss: 43.679985, No improvement in the last 4 epochs: 100%|██████████| 19/19 [00:00<00:00, 123.48it/s]\n","Epoch: 37, tloss: 22.954559326171875, vloss: 15.724195, Early stopping triggered after 5 epochs.: 100%|██████████| 19/19 [00:00<00:00, 136.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["RMSE: 3.049299716949463\n"]}]},{"cell_type":"markdown","source":["Just as before, we extract the column names and discard the target. We can now create a ranking of the importancee of each of the input features. The feature with a ranking of 1.0 is the most important."],"metadata":{"id":"I4whZyXJqolP"}},{"cell_type":"code","source":["# Rank the features\n","from IPython.display import display, HTML\n","\n","names = list(df.columns) # x+y column names\n","names.remove(\"name\")\n","names.remove(\"mpg\") # remove the target(y)\n","rank = perturbation_rank(device, model, x_test, y_test, names, True)\n","display(rank)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"i8ZqslXrqYKZ","executionInfo":{"status":"ok","timestamp":1716605708303,"user_tz":-540,"elapsed":376,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"3c61fe46-161e-4aca-9c2d-d314ba471aef"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"display_data","data":{"text/plain":["           name       error  importance\n","0        weight  618.877869    1.000000\n","1        origin  545.104797    0.880795\n","2          year  313.514557    0.506586\n","3     cylinders  160.791000    0.259811\n","4  acceleration  152.779205    0.246865\n","5  displacement  115.985611    0.187413\n","6    horsepower  101.247238    0.163598"],"text/html":["\n","  <div id=\"df-ff21f031-03e1-4378-b157-8e48992c8da3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>error</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>weight</td>\n","      <td>618.877869</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>origin</td>\n","      <td>545.104797</td>\n","      <td>0.880795</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>year</td>\n","      <td>313.514557</td>\n","      <td>0.506586</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cylinders</td>\n","      <td>160.791000</td>\n","      <td>0.259811</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>acceleration</td>\n","      <td>152.779205</td>\n","      <td>0.246865</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>displacement</td>\n","      <td>115.985611</td>\n","      <td>0.187413</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>horsepower</td>\n","      <td>101.247238</td>\n","      <td>0.163598</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff21f031-03e1-4378-b157-8e48992c8da3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ff21f031-03e1-4378-b157-8e48992c8da3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ff21f031-03e1-4378-b157-8e48992c8da3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f18910bc-a042-4cbc-8b2f-a6bd61468a7c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f18910bc-a042-4cbc-8b2f-a6bd61468a7c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f18910bc-a042-4cbc-8b2f-a6bd61468a7c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_8021e5d9-6be9-4fe1-9e7b-d61203185af1\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rank')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8021e5d9-6be9-4fe1-9e7b-d61203185af1 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('rank');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"rank","summary":"{\n  \"name\": \"rank\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"weight\",\n          \"origin\",\n          \"displacement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.14866370800132,\n        \"min\": 101.24723815917969,\n        \"max\": 618.8778686523438,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          618.8778686523438,\n          545.1047973632812,\n          115.98561096191406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.346027341669734,\n        \"min\": 0.16359809146133095,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          0.8807954282648541,\n          0.18741276241543756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Biological Response with Neural Network\n","The following sections will demonstrate how to use feature importance ranking and ensumbling with a more complex dataset. Ensumbling is the process where you combine multiple models for greater accuracy. Kaggle competition winners frequently make use of ensumbling for high-ranking solution.\n","\n","\n","We will use the biological response dataset, a Kaggle dataset, where there is an unusually high number of columns. **Because of the large number of columns, it is essential to use feature ranking to determine the importance of these columns.** We begin by loading the dataset and preprocessing. This Kaggle dataset is a binary classification problem. You must predict if certain conditions will cause a biological response."],"metadata":{"id":"3q3QeCZUrMid"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import metrics\n","from scipy.stats import zscore\n","from sklearn.model_selection import KFold\n","from IPython.display import HTML, display\n","\n","URL = \"https://data.heatonresearch.com/data/t81-558/kaggle/\"\n","\n","df_train = pd.read_csv(\n","    URL+\"bio_train.csv\",\n","    na_values=['NA', '?'])\n","\n","df_test = pd.read_csv(\n","    URL+\"bio_test.csv\",\n","    na_values=['NA', '?'])\n","\n","activity_classes = df_train['Activity']"],"metadata":{"id":"zVIubUJ5rB96","executionInfo":{"status":"ok","timestamp":1716606037289,"user_tz":-540,"elapsed":5792,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(df_train.shape)\n","display(df_train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"bsWNwWmGsVP2","executionInfo":{"status":"ok","timestamp":1716606080369,"user_tz":-540,"elapsed":945,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"9ac66e3d-943d-4bf8-c7ba-4e84164c9633"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(3751, 1777)\n"]},{"output_type":"display_data","data":{"text/plain":["   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n","0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n","1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n","2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n","3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n","4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n","\n","         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n","0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n","1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n","2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n","3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n","4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n","\n","   D1774  D1775  D1776  \n","0      0      0      0  \n","1      0      1      0  \n","2      0      0      0  \n","3      0      0      0  \n","4      0      0      0  \n","\n","[5 rows x 1777 columns]"],"text/html":["\n","  <div id=\"df-d311e436-e36a-417d-b80f-3b58bed6b892\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Activity</th>\n","      <th>D1</th>\n","      <th>D2</th>\n","      <th>D3</th>\n","      <th>D4</th>\n","      <th>D5</th>\n","      <th>D6</th>\n","      <th>D7</th>\n","      <th>D8</th>\n","      <th>D9</th>\n","      <th>...</th>\n","      <th>D1767</th>\n","      <th>D1768</th>\n","      <th>D1769</th>\n","      <th>D1770</th>\n","      <th>D1771</th>\n","      <th>D1772</th>\n","      <th>D1773</th>\n","      <th>D1774</th>\n","      <th>D1775</th>\n","      <th>D1776</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.497009</td>\n","      <td>0.10</td>\n","      <td>0.0</td>\n","      <td>0.132956</td>\n","      <td>0.678031</td>\n","      <td>0.273166</td>\n","      <td>0.585445</td>\n","      <td>0.743663</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.366667</td>\n","      <td>0.606291</td>\n","      <td>0.05</td>\n","      <td>0.0</td>\n","      <td>0.111209</td>\n","      <td>0.803455</td>\n","      <td>0.106105</td>\n","      <td>0.411754</td>\n","      <td>0.836582</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.033300</td>\n","      <td>0.480124</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.209791</td>\n","      <td>0.610350</td>\n","      <td>0.356453</td>\n","      <td>0.517720</td>\n","      <td>0.679051</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.538825</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","      <td>0.196344</td>\n","      <td>0.724230</td>\n","      <td>0.235606</td>\n","      <td>0.288764</td>\n","      <td>0.805110</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.100000</td>\n","      <td>0.517794</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.494734</td>\n","      <td>0.781422</td>\n","      <td>0.154361</td>\n","      <td>0.303809</td>\n","      <td>0.812646</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1777 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d311e436-e36a-417d-b80f-3b58bed6b892')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d311e436-e36a-417d-b80f-3b58bed6b892 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d311e436-e36a-417d-b80f-3b58bed6b892');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7fe2a506-4d7c-4b6b-8100-d428ac63ea6d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fe2a506-4d7c-4b6b-8100-d428ac63ea6d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7fe2a506-4d7c-4b6b-8100-d428ac63ea6d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}]},{"cell_type":"markdown","source":["A large number of columns is evident when we display the shape of the dataset.\n","\n","\n","\n","The following code constructs a classification neural network and trains it for the biological response dataset. Once trained, the accuracy is measured."],"metadata":{"id":"9x1dRBnUsh9o"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import sklearn\n","from sklearn import metrics\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"rl3RdFLbsY9d","executionInfo":{"status":"ok","timestamp":1716606533650,"user_tz":-540,"elapsed":382,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Assuming df_train and df_test are predefined\n","x_columns = df_train.columns.drop('Activity')\n","x = torch.tensor(df_train[x_columns].values, dtype=torch.float32)\n","y = torch.tensor(df_train['Activity'].values, dtype=torch.float32).view(-1, 1) # For binary cross entropy\n","x_submit = torch.tensor(df_test[x_columns].values, dtype=torch.float32)"],"metadata":{"id":"eDHCrOrduMQq","executionInfo":{"status":"ok","timestamp":1716606705487,"user_tz":-540,"elapsed":683,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxUU7TK9utjG","executionInfo":{"status":"ok","timestamp":1716606711074,"user_tz":-540,"elapsed":374,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"28cb6faf-5e66-4437-d30c-a56c1c50520f"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3751, 1])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# Split into train/test\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n","\n","# Move to GPU if available\n","x_train, y_train, x_test, y_test = map(lambda t: t.clone().detach().to(device), (x_train, y_train, x_test, y_test))\n","\n","train_dataset = TensorDataset(x_train, y_train)\n","test_dataset = TensorDataset(x_test, y_test)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define model using Sequential\n","model = nn.Sequential(\n","    nn.Linear(x_train.shape[1], 25),\n","    nn.ReLU(),\n","    nn.Linear(25, 10),\n","    nn.Linear(10, 1),\n","    nn.Sigmoid()\n",").to(device)\n","\n","# Loss and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"q8jxsAdlut9u","executionInfo":{"status":"ok","timestamp":1716608013143,"user_tz":-540,"elapsed":951,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Training with early stopping\n","best_loss = float('inf')\n","patience = 5\n","no_improvements = 0\n","for epoch in range(1000):\n","    model.train()\n","    for batch in train_loader:\n","        input, lables = batch\n","\n","        optimizer.zero_grad()\n","        outputs = model(input)\n","        loss = criterion(outputs, lables)\n","        loss.backward()\n","        optimizer.step()\n","\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = sum(criterion(model(inputs), labels) for inputs, labels in test_loader)\n","        if val_loss < best_loss - 1e-3:\n","            best_loss = val_loss\n","            no_improvements = 0\n","        else:\n","            no_improvements += 1\n","        if no_improvements >= patience:\n","            print(\"Early stopping\")\n","            break\n","\n","\n","# Prediction\n","with torch.no_grad():\n","    pred = model(x_test).cpu().numpy().flatten()\n","    pred = np.clip(pred, a_min=1e-6, a_max=1-1e-6)\n","\n","    print(\"Validation logloss: {}\".format(sklearn.metrics.log_loss(y_test.cpu(), pred)))\n","\n","    pred_binary = (pred > 0.5).astype(int)\n","    score = metrics.accuracy_score(y_test.cpu().numpy(), pred_binary)\n","    print(\"Validation accuracy score: {}\".format(score))\n","\n","    pred_submit = model(x_submit.to(device)).cpu().numpy().flatten()\n","    pred_submit = np.clip(pred_submit, a_min=1e-6, a_max=1-1e-6)\n","\n","    submit_df = pd.DataFrame({'MoleculeId': [x+1 for x in range(len(pred_submit))], 'PredictedProbability': pred_submit})\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5dnV2J2z7ly","executionInfo":{"status":"ok","timestamp":1716608290440,"user_tz":-540,"elapsed":3178,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"9659329e-f397-45c3-ada9-777a0f26724d"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Early stopping\n","Validation logloss: 0.5600866362644804\n","Validation accuracy score: 0.767590618336887\n"]}]},{"cell_type":"markdown","source":["### What Features/Columns are Important\n","The following uses perturbation ranking to evaluate the neural network."],"metadata":{"id":"SrnB57W11AEd"}},{"cell_type":"code","source":["# Rank the features\n","from IPython.display import display, HTML\n","\n","names = list(df_train.columns) # x+y column names\n","names.remove(\"Activity\") # remove the target(y)\n","rank = perturbation_rank(device, model, x_test, y_test, names, False)\n","display(rank[0:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"zYdURtzu03ww","executionInfo":{"status":"ok","timestamp":1716608357813,"user_tz":-540,"elapsed":10809,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"06f69450-3646-4a73-c543-93222750b3b4"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["   name     error  importance\n","0  D603  0.571014    1.000000\n","1  D129  0.570891    0.999785\n","2  D179  0.570877    0.999761\n","3  D149  0.570474    0.999055\n","4  D490  0.570162    0.998508\n","5  D240  0.570091    0.998385\n","6  D827  0.570015    0.998250\n","7  D887  0.569835    0.997935\n","8  D273  0.569802    0.997879\n","9  D850  0.569619    0.997557"],"text/html":["\n","  <div id=\"df-df4aa1bf-2568-47a3-a368-8ca706c6a7d7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>error</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>D603</td>\n","      <td>0.571014</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D129</td>\n","      <td>0.570891</td>\n","      <td>0.999785</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>D179</td>\n","      <td>0.570877</td>\n","      <td>0.999761</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D149</td>\n","      <td>0.570474</td>\n","      <td>0.999055</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>D490</td>\n","      <td>0.570162</td>\n","      <td>0.998508</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>D240</td>\n","      <td>0.570091</td>\n","      <td>0.998385</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>D827</td>\n","      <td>0.570015</td>\n","      <td>0.998250</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>D887</td>\n","      <td>0.569835</td>\n","      <td>0.997935</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>D273</td>\n","      <td>0.569802</td>\n","      <td>0.997879</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>D850</td>\n","      <td>0.569619</td>\n","      <td>0.997557</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4aa1bf-2568-47a3-a368-8ca706c6a7d7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-df4aa1bf-2568-47a3-a368-8ca706c6a7d7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-df4aa1bf-2568-47a3-a368-8ca706c6a7d7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7158f77e-90a6-4d6b-a051-c437bb33e222\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7158f77e-90a6-4d6b-a051-c437bb33e222')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7158f77e-90a6-4d6b-a051-c437bb33e222 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(rank[0:10])\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"D273\",\n          \"D129\",\n          \"D240\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005043579603163517,\n        \"min\": 0.569618821144104,\n        \"max\": 0.5710137486457825,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5698024034500122,\n          0.5708912014961243,\n          0.5700913071632385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.000883267629741835,\n        \"min\": 0.997557103476078,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9978786059028472,\n          0.9997853866917411,\n          0.9983845546893895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Neural Network Ensemble\n","A neural network ensemble combines neural network predictions with other models. The program determines the exact blend of these models by logistic regression. The following code performs this blend for a classification."],"metadata":{"id":"Fm__THem4um1"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","import pandas as pd\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"jeCMKNvY1Kms","executionInfo":{"status":"ok","timestamp":1716609396571,"user_tz":-540,"elapsed":753,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["SHUFFLE = False\n","FOLDS = 10\n","\n","# Using nn.Sequential to define the model\n","def build_ann(input_size, classes, neurons):\n","    model = nn.Sequential(\n","        nn.Linear(input_size, neurons),\n","        nn.ReLU(),\n","        nn.Linear(neurons, 1),\n","        nn.Linear(1, classes),\n","        nn.Softmax(dim=1)\n","    )\n","    return model\n","\n","def mlogloss(y_test, preds):\n","    epsilon = 1e-15\n","    sum = 0\n","    for row in zip(preds,y_test):\n","        x = row[0][row[1]]\n","        x = max(epsilon,x)\n","        x = min(1-epsilon,x)\n","        sum+=math.log(x)\n","    return( (-1/len(preds))*sum)\n","\n","def stretch(y):\n","    return (y - y.min()) / (y.max() - y.min())\n","\n","def blend_ensemble(x, y, x_submit):\n","    kf = StratifiedKFold(FOLDS)\n","    folds = list(kf.split(x,y))\n","\n","    models = [\n","        build_ann(x.shape[1], 2, 20),\n","        KNeighborsClassifier(n_neighbors=3),\n","        RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n","        RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n","        ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n","        ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n","        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)\n","    ]\n","\n","    dataset_blend_train = np.zeros((x.shape[0], len(models)))\n","    dataset_blend_test = np.zeros((x_submit.shape[0], len(models)))\n","\n","    for j, model in enumerate(models):\n","        print(\"Model: {} : {}\".format(j, model))\n","        fold_sums = np.zeros((x_submit.shape[0], len(folds)))\n","        total_loss = 0\n","        for i, (train, test) in enumerate(folds):\n","            x_train = torch.tensor(x[train], dtype=torch.float32)\n","            y_train = torch.tensor(y[train].values, dtype=torch.int64)\n","            x_test = torch.tensor(x[test], dtype=torch.float32)\n","            y_test = torch.tensor(y[test].values, dtype=torch.int64)\n","\n","            if isinstance(model, nn.Module):  # Check if the model is a PyTorch model\n","                optimizer = optim.Adam(model.parameters())\n","                criterion = nn.CrossEntropyLoss()\n","\n","                # Training\n","                optimizer.zero_grad()\n","                outputs = model(x_train)\n","                loss = criterion(outputs, y_train)\n","                loss.backward()\n","                optimizer.step()\n","\n","                # Prediction\n","                with torch.no_grad():\n","                    outputs_test = model(x_test)\n","                    _, predicted = outputs_test.max(1)\n","                    pred = F.softmax(outputs_test, dim=1).numpy()\n","                    outputs_submit = model(torch.tensor(x_submit, dtype=torch.float32))\n","                    pred2 = F.softmax(outputs_submit, dim=1).numpy()\n","            else:\n","                model.fit(x_train, y_train)\n","                pred = np.array(model.predict_proba(x_test))\n","                pred2 = np.array(model.predict_proba(x_submit))\n","\n","            dataset_blend_train[test, j] = pred[:, 1]\n","            fold_sums[:, i] = pred2[:, 1]\n","            loss = mlogloss(y_test, pred)\n","            total_loss+=loss\n","            print(\"Fold #{}: loss={}\".format(i,loss))\n","        print(\"{}: Mean loss={}\".format(model.__class__.__name__, total_loss/len(folds)))\n","        dataset_blend_test[:, j] = fold_sums.mean(1)\n","\n","    print()\n","    print(\"Blending models.\")\n","    blend = LogisticRegression(solver='lbfgs')\n","    blend.fit(dataset_blend_train, y)\n","    return blend.predict_proba(dataset_blend_test), dataset_blend_train, dataset_blend_test"],"metadata":{"id":"g_Jv32VV5KqS","executionInfo":{"status":"ok","timestamp":1716610381658,"user_tz":-540,"elapsed":243,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["np.random.seed(42)  # seed to shuffle the train set\n","\n","print(\"Loading data...\")\n","URL = \"https://data.heatonresearch.com/data/t81-558/kaggle/\"\n","\n","df_train = pd.read_csv(URL+\"bio_train.csv\", na_values=['NA', '?'])\n","df_submit = pd.read_csv(URL+\"bio_test.csv\", na_values=['NA', '?'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZapJm-E8OZn","executionInfo":{"status":"ok","timestamp":1716610483211,"user_tz":-540,"elapsed":1963,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"f67bc1c5-42a0-4154-c326-a36abf36b79d"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data...\n"]}]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"WsyQWZJD8fiR","executionInfo":{"status":"ok","timestamp":1716610272738,"user_tz":-540,"elapsed":241,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"c8812da7-9020-44e6-dd7f-e824248eb86d"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n","0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n","1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n","2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n","3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n","4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n","\n","         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n","0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n","1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n","2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n","3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n","4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n","\n","   D1774  D1775  D1776  \n","0      0      0      0  \n","1      0      1      0  \n","2      0      0      0  \n","3      0      0      0  \n","4      0      0      0  \n","\n","[5 rows x 1777 columns]"],"text/html":["\n","  <div id=\"df-7d68cb5f-fba6-4503-9d75-4a99db676582\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Activity</th>\n","      <th>D1</th>\n","      <th>D2</th>\n","      <th>D3</th>\n","      <th>D4</th>\n","      <th>D5</th>\n","      <th>D6</th>\n","      <th>D7</th>\n","      <th>D8</th>\n","      <th>D9</th>\n","      <th>...</th>\n","      <th>D1767</th>\n","      <th>D1768</th>\n","      <th>D1769</th>\n","      <th>D1770</th>\n","      <th>D1771</th>\n","      <th>D1772</th>\n","      <th>D1773</th>\n","      <th>D1774</th>\n","      <th>D1775</th>\n","      <th>D1776</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.497009</td>\n","      <td>0.10</td>\n","      <td>0.0</td>\n","      <td>0.132956</td>\n","      <td>0.678031</td>\n","      <td>0.273166</td>\n","      <td>0.585445</td>\n","      <td>0.743663</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.366667</td>\n","      <td>0.606291</td>\n","      <td>0.05</td>\n","      <td>0.0</td>\n","      <td>0.111209</td>\n","      <td>0.803455</td>\n","      <td>0.106105</td>\n","      <td>0.411754</td>\n","      <td>0.836582</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.033300</td>\n","      <td>0.480124</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.209791</td>\n","      <td>0.610350</td>\n","      <td>0.356453</td>\n","      <td>0.517720</td>\n","      <td>0.679051</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.538825</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","      <td>0.196344</td>\n","      <td>0.724230</td>\n","      <td>0.235606</td>\n","      <td>0.288764</td>\n","      <td>0.805110</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.100000</td>\n","      <td>0.517794</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.494734</td>\n","      <td>0.781422</td>\n","      <td>0.154361</td>\n","      <td>0.303809</td>\n","      <td>0.812646</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1777 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d68cb5f-fba6-4503-9d75-4a99db676582')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7d68cb5f-fba6-4503-9d75-4a99db676582 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7d68cb5f-fba6-4503-9d75-4a99db676582');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-590e23dd-2a7d-435f-9225-e9c72d819749\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-590e23dd-2a7d-435f-9225-e9c72d819749')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-590e23dd-2a7d-435f-9225-e9c72d819749 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_train"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["df_train['Activity'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c5LT86H4DnNw","executionInfo":{"status":"ok","timestamp":1716612151692,"user_tz":-540,"elapsed":391,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"9a207c7d-6066-4074-a024-c054fea31ee3"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["predictors = list(df_train.columns.values)\n","predictors.remove('Activity')\n","x = df_train[predictors].values\n","y = df_train['Activity']\n","x_submit = df_submit.values\n","\n","if SHUFFLE:\n","    idx = np.random.permutation(y.size)\n","    x = x[idx]\n","    y = y[idx]\n","\n","submit_data, dataset_blend_train, dataset_blend_test = blend_ensemble(x, y, x_submit)\n","submit_data = stretch(submit_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"AjXyBG-18gn2","executionInfo":{"status":"ok","timestamp":1716610812236,"user_tz":-540,"elapsed":297190,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"e20af14f-402b-403e-d6b4-92ac052112d8"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: 0 : Sequential(\n","  (0): Linear(in_features=1776, out_features=20, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=20, out_features=1, bias=True)\n","  (3): Linear(in_features=1, out_features=2, bias=True)\n","  (4): Softmax(dim=1)\n",")\n","Fold #0: loss=0.6958829953342398\n","Fold #1: loss=0.6941009778087774\n","Fold #2: loss=0.6927663971013983\n","Fold #3: loss=0.6913332873280058\n","Fold #4: loss=0.6905866068713171\n","Fold #5: loss=0.6904894890764086\n","Fold #6: loss=0.6880869763879794\n","Fold #7: loss=0.6873027566818372\n","Fold #8: loss=0.6851593466737296\n","Fold #9: loss=0.6805799294265442\n","Sequential: Mean loss=0.6896288762690237\n","Model: 1 : KNeighborsClassifier(n_neighbors=3)\n","Fold #0: loss=3.606678388314123\n","Fold #1: loss=2.2256421551487593\n","Fold #2: loss=3.6815437059542186\n","Fold #3: loss=2.416161292225968\n","Fold #4: loss=4.442472310149748\n","Fold #5: loss=4.321350530738247\n","Fold #6: loss=3.400455469543658\n","Fold #7: loss=3.1724147110842513\n","Fold #8: loss=2.117356283193681\n","Fold #9: loss=3.0532135963322586\n","KNeighborsClassifier: Mean loss=3.243728844268491\n","Model: 2 : RandomForestClassifier(n_jobs=-1)\n","Fold #0: loss=0.4657177982691548\n","Fold #1: loss=0.4346825805694879\n","Fold #2: loss=0.4593868993445528\n","Fold #3: loss=0.41674899522216713\n","Fold #4: loss=0.4851849131056564\n","Fold #5: loss=0.48473291073937\n","Fold #6: loss=0.41274608628217674\n","Fold #7: loss=0.47405291219252377\n","Fold #8: loss=0.44974230059938286\n","Fold #9: loss=0.46340159258241087\n","RandomForestClassifier: Mean loss=0.45463969889068834\n","Model: 3 : RandomForestClassifier(criterion='entropy', n_jobs=-1)\n","Fold #0: loss=0.4511847247326708\n","Fold #1: loss=0.42707704254926593\n","Fold #2: loss=0.5550335199035183\n","Fold #3: loss=0.42186970733328516\n","Fold #4: loss=0.4794331756190797\n","Fold #5: loss=0.4730559509802762\n","Fold #6: loss=0.41116235817215196\n","Fold #7: loss=0.46835919493314265\n","Fold #8: loss=0.4496144890690015\n","Fold #9: loss=0.4625902934553457\n","RandomForestClassifier: Mean loss=0.4599380456747738\n","Model: 4 : ExtraTreesClassifier(n_jobs=-1)\n","Fold #0: loss=0.45496751079363495\n","Fold #1: loss=0.5013051157905043\n","Fold #2: loss=0.5886179891724027\n","Fold #3: loss=0.41646902160044674\n","Fold #4: loss=0.4957910697444236\n","Fold #5: loss=0.4773401028797005\n","Fold #6: loss=0.41935061504547827\n","Fold #7: loss=0.5757908399174205\n","Fold #8: loss=0.4585195863412778\n","Fold #9: loss=0.6210675972963805\n","ExtraTreesClassifier: Mean loss=0.500921944858167\n","Model: 5 : ExtraTreesClassifier(criterion='entropy', n_jobs=-1)\n","Fold #0: loss=0.44825346440152214\n","Fold #1: loss=0.40764412171784686\n","Fold #2: loss=0.5819367378417363\n","Fold #3: loss=0.4140589874942631\n","Fold #4: loss=0.4923489720481471\n","Fold #5: loss=0.5744429921555051\n","Fold #6: loss=0.42334390524742155\n","Fold #7: loss=0.6409291880353659\n","Fold #8: loss=0.45627884947155956\n","Fold #9: loss=0.466653395317917\n","ExtraTreesClassifier: Mean loss=0.49058906137312847\n","Model: 6 : GradientBoostingClassifier(learning_rate=0.05, max_depth=6, n_estimators=50,\n","                           subsample=0.5)\n","Fold #0: loss=0.4789324034433162\n","Fold #1: loss=0.4573129674704844\n","Fold #2: loss=0.47057741836357014\n","Fold #3: loss=0.447803074821278\n","Fold #4: loss=0.4883293501002484\n","Fold #5: loss=0.4843521206311074\n","Fold #6: loss=0.4436043855503229\n","Fold #7: loss=0.45950746911784374\n","Fold #8: loss=0.46632256794136323\n","Fold #9: loss=0.4676684170721868\n","GradientBoostingClassifier: Mean loss=0.46644101745117217\n","\n","Blending models.\n"]}]},{"cell_type":"code","source":["# Build submit file\n","ids = [id+1 for id in range(submit_data.shape[0])]\n","submit_df = pd.DataFrame({'MoleculeId': ids, 'PredictedProbability': submit_data[:, 1]}, columns=['MoleculeId','PredictedProbability'])"],"metadata":{"id":"srdyH8uJ9vek","executionInfo":{"status":"ok","timestamp":1716610842206,"user_tz":-540,"elapsed":242,"user":{"displayName":"yo it","userId":"02303648966403166717"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["display(submit_data.shape)\n","display(dataset_blend_train.shape)\n","display(dataset_blend_test.shape)\n","display(submit_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"wMt6wFxf-sk7","executionInfo":{"status":"ok","timestamp":1716611967662,"user_tz":-540,"elapsed":564,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"36aec048-14f4-43b6-dda7-26e757fccb79"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["(2501, 2)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(3751, 7)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(2501, 7)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["      MoleculeId  PredictedProbability\n","0              1              0.950695\n","1              2              0.963416\n","2              3              0.419992\n","3              4              0.985059\n","4              5              0.066068\n","...          ...                   ...\n","2496        2497              0.260016\n","2497        2498              0.065480\n","2498        2499              0.978737\n","2499        2500              0.782989\n","2500        2501              0.169387\n","\n","[2501 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-cc0539c5-a146-43c0-8b5b-1cc9d9719ddd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MoleculeId</th>\n","      <th>PredictedProbability</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.950695</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.963416</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.419992</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.985059</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.066068</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2496</th>\n","      <td>2497</td>\n","      <td>0.260016</td>\n","    </tr>\n","    <tr>\n","      <th>2497</th>\n","      <td>2498</td>\n","      <td>0.065480</td>\n","    </tr>\n","    <tr>\n","      <th>2498</th>\n","      <td>2499</td>\n","      <td>0.978737</td>\n","    </tr>\n","    <tr>\n","      <th>2499</th>\n","      <td>2500</td>\n","      <td>0.782989</td>\n","    </tr>\n","    <tr>\n","      <th>2500</th>\n","      <td>2501</td>\n","      <td>0.169387</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2501 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc0539c5-a146-43c0-8b5b-1cc9d9719ddd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cc0539c5-a146-43c0-8b5b-1cc9d9719ddd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cc0539c5-a146-43c0-8b5b-1cc9d9719ddd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c68dcc51-1d55-4eb4-af6f-573350c05e07\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c68dcc51-1d55-4eb4-af6f-573350c05e07')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c68dcc51-1d55-4eb4-af6f-573350c05e07 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_772a1b7e-81c0-4151-baa7-929915fadf4d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('submit_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_772a1b7e-81c0-4151-baa7-929915fadf4d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('submit_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"submit_df","summary":"{\n  \"name\": \"submit_df\",\n  \"rows\": 2501,\n  \"fields\": [\n    {\n      \"column\": \"MoleculeId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 722,\n        \"min\": 1,\n        \"max\": 2501,\n        \"num_unique_values\": 2501,\n        \"samples\": [\n          1106,\n          2056,\n          1387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PredictedProbability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35772561482292053,\n        \"min\": 0.0,\n        \"max\": 0.9948226600126027,\n        \"num_unique_values\": 2501,\n        \"samples\": [\n          0.9319457158811078,\n          0.7056502912066157,\n          0.9520718644162036\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["dataset_blend_train\n","# 行ごとに、各モデルの予測値(バイナリclassificationの1の確率)が入っている"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4uYqyroCX_T","executionInfo":{"status":"ok","timestamp":1716611822203,"user_tz":-540,"elapsed":265,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"29e6f3d1-3376-4305-c89d-0921e2cc6382"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.60081685, 0.66666667, 0.9       , ..., 0.88      , 0.8       ,\n","        0.8474707 ],\n","       [0.60228235, 1.        , 1.        , ..., 0.99      , 1.        ,\n","        0.88462191],\n","       [0.59956253, 0.        , 0.18      , ..., 0.22      , 0.13      ,\n","        0.18570176],\n","       ...,\n","       [0.55831301, 0.33333333, 0.33      , ..., 0.5       , 0.39      ,\n","        0.25553465],\n","       [0.57499862, 0.66666667, 0.88      , ..., 0.88      , 0.91      ,\n","        0.79543032],\n","       [0.57660043, 0.        , 0.1       , ..., 0.03      , 0.02      ,\n","        0.1344547 ]])"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["dataset_blend_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1r8uSX9DCtDT","executionInfo":{"status":"ok","timestamp":1716611902579,"user_tz":-540,"elapsed":333,"user":{"displayName":"yo it","userId":"02303648966403166717"}},"outputId":"12bc745d-d761-4050-9699-50fdf7c8ad14"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.60081685, 0.66666667, 0.9       , ..., 0.88      , 0.8       ,\n","        0.8474707 ],\n","       [0.60228235, 1.        , 1.        , ..., 0.99      , 1.        ,\n","        0.88462191],\n","       [0.59956253, 0.        , 0.18      , ..., 0.22      , 0.13      ,\n","        0.18570176],\n","       ...,\n","       [0.55831301, 0.33333333, 0.33      , ..., 0.5       , 0.39      ,\n","        0.25553465],\n","       [0.57499862, 0.66666667, 0.88      , ..., 0.88      , 0.91      ,\n","        0.79543032],\n","       [0.57660043, 0.        , 0.1       , ..., 0.03      , 0.02      ,\n","        0.1344547 ]])"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["### The function of `mlogloss`\n","```python\n","def mlogloss(y_test, preds):\n","    epsilon = 1e-15\n","    sum = 0\n","    for row in zip(preds,y_test):\n","        x = row[0][row[1]]\n","        x = max(epsilon,x)\n","        x = min(1-epsilon,x)\n","        sum += math.log(x)\n","    return (-1/len(preds)) * sum\n","```\n","#### Purpose:\n","The `mlogloss` function calculates the multi-class logarithmic loss, also known as log loss. Log loss is a performance metric for classification models, particulary useful for probabilistic models where the output is a probability distribution over classes.\n","\n","#### Explanation:\n","* `epsilon` is a small value to ensure numerical stability and avoil log(0).\n","* The function iterates over each prediction and the corresponding true label.\n","* For each prediction, it retrieves the predicted probability of the true class label.\n","* The prediction probability is clipped between `epsilon` and `1-epsilon` to avoid log(0) errors.\n","* The log of this probability is summed over all samples.\n","* Finally, the sum is normalized by the number of predictions and negated(否定された) to give the final log loss value."],"metadata":{"id":"-n0RsjpX_0WM"}},{"cell_type":"markdown","source":["### Function `stretch`\n","```python\n","def stretch(y):\n","    return (y - y.min()) / (y.max() - y.min())\n","```\n","\n","#### Purpose:\n","The `stretch` function normalizes an array of values to the range [0, 1]. This is often useful in machine learning to ensure that all features have the same scale, which can improve the performance of many models.\n","\n","#### Explanation:\n","* `y.min()` and `y.max()` are the minimum and maximum values in the array `y`.\n","* The function scales the values in `y` such that the minimum value becomes 0 and the maximum value becomes 1.\n","* This is done by subtracting the minimum value from each element and then dividing by the range (max - min)."],"metadata":{"id":"EL_r71QmBcxb"}},{"cell_type":"markdown","source":["### Function `blend_ensemble`\n","#### Purpose:\n","The `blend_ensemble` function performs model blending, an ensemble technique where multiple models are trained and their predicitons are combined to produce a final prediction. This often improves the overall performance by leveraging the strengths of different models.\n","\n","### Explanation:\n","* `StratifiedKFold` is used to create stratified folds cross-validation, ensuring each fold has the same proportion of class labels as original dataset.\n","* A list of models (including neural networks and varions ensemble classifiers) is created.\n","* Two arrays, `dataset_blend_train` and `dataset_blend_test`, are initialized to store the blended predictions.\n","* For each model, cross-validation is performed:\n","     * If the model is a PyTorch model, it is trained using Adam optimizer and cross-entropy loss.\n","    * If the model is a scikit-learn model, it is trained using its fit method.\n","    * Predictions are made for both the validation set and the submission set.\n","    * Log loss is calculated for the validation set predictions.\n","* After all folds, the mean predictions for the submission set are stored in `dataset_blend_test`.\n","* Finally, a logistic regression model is trained on the blended training predictions and used to make the final predicitons for the submission set."],"metadata":{"id":"cMHiob3iDDWA"}},{"cell_type":"code","source":[],"metadata":{"id":"DfwN0qizP4bD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### detail of `mlogloss` function\n","```python\n","def mlogloss(y_test, preds):\n","    epsilon = 1e-15\n","    sum = 0\n","    for row in zip(preds, y_test):\n","        x = row[0][row[1]]\n","        x = max(epsilon, x)\n","        x = min(1 - epsilon, x)\n","        sum += math.log(x)\n","    return (-1 / len(preds)) * sum\n","```\n","\n","#### Purpose:\n","The `mlogloss` function calculates the multi-class logarithmic loss, a performance metric often used in classification problems to measure the accuracy of probabilistic predictions.\n","\n","### Detailed Breakdown:\n","1. **Intialize `epsilon` and `sum`:\n","```python\n","epsilon = 1e-15\n","sum = 0\n","```\n","* `epsilon` is set to a very smal value (**1e-15`**). This is used to avoid issue with taking the logarithm of zero or one, which would result in underfined or infinite values.\n","* `sum` is initialized to zero and will accumulate the log loss values for each prediction.\n","\n","2. **Loop over each prediction and true label pair**:\n","```python\n","for row in zip(preds, y_test):\n","```\n","* The `zip(preds y_test)` function pairs each prediction (from `preds`) with its corresponding true label (from `y_test`)\n","* The loop iterates over these pairs, processing one pair at a time.\n","\n","3. **Extract the predicted probability for the true class**\n","```python\n","x = row[0][row[1]]\n","```\n","* `row[0]` is the predicted probability distribution (an array) for a particular sample.\n","* `row[1]` is the true class labels for that sample.\n","* `row[0][row[1]]` extracts the predicted probability of the true class label.\n","\n","4. **Clip the predicted probability to avoid log(0) and log(1)**:\n","```python\n","x = max(epsilon, x)\n","x = min(1 - epsilon, x)\n","```\n","* The predicted probability `x` is adjusted to ensure it is within the range `[epsilon, 1 - epsilon]`.\n","* This prevents `x` from being exactly 0 or 1, which would cause isssues when taking the logarithm.\n","\n","5. **Accumulated the log loss**:\n","```python\n","sum += math.log(x)\n","```\n","* The natural logarithm of the cipped predicted probability `x` is added to the cumulative `sum`.\n","\n","6. **Calculate the average log loss**:\n","```python\n","return (-1 / len(preds)) * sum\n","```\n","* The cumulative log loss `sum` is divided by the number of predictions (`len(preds)`) to get the average log loss.\n","* The result is negated to ensure the log loss is a positive value (since the log of probabilities between 0 and 1 is negative).\n","\n","\n","### Summary:\n","The `mlogloss` function cumputes the log loss for a set of predictions, providing a measure of how well the predicted probabilities match the true class labels. It ensures numerical stabitily by clipping the predicted probabilities and returns the average log loss over all samples. This metric is useful for evaluating the performance of probabilistic classification models, with lower values indicating better performance.\n"],"metadata":{"id":"9DFbQKLSP4ui"}},{"cell_type":"code","source":[],"metadata":{"id":"V9HU4ZQoP6-j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# About Logarithmic loss\n","Logarithmic loss, often abbreviated as log loss, is a performance metric used to evaluate the accuracy of probabilistic classification models. It measures the uncertainty of predictions and penalizes both false classifications and confident but incorrect predictions. Log loss is particularly useful for models that provide probability estimates rather than just class labels.\n","\n","## Key Points of Log Loss\n","1. **Probabilistic Predictions**:\n","    * Log loss evaluates the predicted probabilities of each class rather than the predicted class labels.\n","    * A good probabilistic model assigns high probabilities to the correct classes and low probabilities to the incorrect classes.\n","2. **Penalty for Incorrect Predictions**:\n","    * Incorrect predictions are penalized based on their confidence. For example, predicting a high probability for the wrong class results in a higher penalty than predicting a low probability for the wrong class.\n","3. **Range and Interpretation**:\n","    * Log loss values range from 0 to infinity, where 0 indicates perfect predictions and higher values indicate worse performance.\n","    * Lower log loss values are better, indicating more accurate and confident predictions.\n","\n","## Formula for Log Loss:\n","For a set of $N$ samples, the log loss is calculated as:\n","$$\n","\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{M} y_{ij} \\log(p_{ij})\n","$$\n","\n","where:\n","* $N$ is the number of samples.\n","* $M$ is the number of classes.\n","* $y_{ij}$ is a binary indicator (0 or 1) if the true class label of sample $i$ is $j$.\n","* $p_{ij}$ is the predicted probability thta sample $i$ belongs to class $j$.\n","\n","## Example Calculation\n","Consider a binary classification problem with two classes (0 and 1). Suppose we have three samples with the following true labels and predicted probabilities:\n","\n","| Sample | True Label | Predicted Probability (Class 0) | Predicted Probability (Class 1) |\n","|--------|------------|----------------------------------|----------------------------------|\n","| 1      | 0          | 0.8                              | 0.2                              |\n","| 2      | 1          | 0.4                              | 0.6                              |\n","| 3      | 1          | 0.1                              | 0.9                              |\n","\n","<br>\n","\n","The log loss for each sample is calculated as:\n","\n","- Sample 1: $-\\log(0.8)$\n","- Sample 2: $-\\log(0.6)$\n","- Sample 3: $-\\log(0.9)$\n","\n","Then, the overall log loss is the average of these individual log losses:\n","\n","$$\n","\\text{Log Loss} = -\\frac{1}{3} \\left[ \\log(0.8) + \\log(0.6) + \\log(0.9) \\right]\n","$$\n","\n","Using a calculator to find the logarithms:\n","\n","- $$\\log(0.8) \\approx -0.223$$\n","- $$\\log(0.6) \\approx -0.511$$\n","- $$\\log(0.9) \\approx -0.105$$\n","\n","So,\n","$$\n","\\text{Log Loss} = -\\frac{1}{3} \\left[ -0.223 + -0.511 + -0.105 \\right] \\approx 0.279\n","$$\n","\n","## Significance:\n","* **Model Evaluation**: Log loss provides a way to evaluate how well a model's predictd probabiilities align with the true class labels.\n","* **Model Comparison**: It allows for the comparison of different models, especially in scenarios where models output probabilistic predictions.\n","* **Hyperparameter Tuning**: Log loss can be used as a metric for optimizing model hyperparameters to improve probabilistic accuracy.\n","\n","In summary, log loss is a crucial metric for evaluating and comparing the performance of probabilistic classification models, emphasizing the importance of both correct and cofident predictions.\n","\n","\n","\n","\n"],"metadata":{"id":"tSjax6nAFLwK"}},{"cell_type":"code","source":[],"metadata":{"id":"1SNqhZDk-5Ie"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Logarithmic loss, often abbreviated as log loss, is a performance metric used to evaluate the accuracy of probabilistic classification models. It measures the uncertainty of predictions and penalizes both false classifications and confident but incorrect predictions. Log loss is particularly useful for models that provide probability estimates rather than just class labels.\n","\n","### Key Points of Log Loss:\n","\n","1. **Probabilistic Predictions:**\n","   - Log loss evaluates the predicted probabilities of each class rather than the predicted class labels.\n","   - A good probabilistic model assigns high probabilities to the correct classes and low probabilities to the incorrect classes.\n","\n","2. **Penalty for Incorrect Predictions:**\n","   - Incorrect predictions are penalized based on their confidence. For example, predicting a high probability for the wrong class results in a higher penalty than predicting a low probability for the wrong class.\n","\n","3. **Range and Interpretation:**\n","   - Log loss values range from 0 to infinity, where 0 indicates perfect predictions and higher values indicate worse performance.\n","   - Lower log loss values are better, indicating more accurate and confident predictions.\n","\n","### Formula for Log Loss:\n","\n","For a set of \\( N \\) samples, the log loss is calculated as:\n","\n","\\[ \\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{M} y_{ij} \\log(p_{ij}) \\]\n","\n","where:\n","- \\( N \\) is the number of samples.\n","- \\( M \\) is the number of classes.\n","- \\( y_{ij} \\)\n","- \\( p_{ij} \\) is the predicted probability that sample \\( i \\) belongs to class \\( j \\).\n","\n","### Example Calculation:\n","\n","Consider a binary classification problem with two classes (0 and 1). Suppose we have three samples with the following true labels and predicted probabilities:\n","\n","\n","### Significance:\n","\n","- **Model Evaluation:** Log loss provides a way to evaluate how well a model's predicted probabilities align with the true class labels.\n","- **Model Comparison:** It allows for the comparison of different models, especially in scenarios where models output probabilistic predictions.\n","- **Hyperparameter Tuning:** Log loss can be used as a metric for optimizing model hyperparameters to improve probabilistic accuracy.\n","\n","In summary, log loss is a crucial metric for evaluating and comparing the performance of probabilistic classification models, emphasizing the importance of both correct and confident predictions."],"metadata":{"id":"9DgCNIztMwNV"}},{"cell_type":"code","source":[],"metadata":{"id":"tmnVl3Z2UAfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The reason of using Logistic Regression for Model Blending\n","\n","Using `LogisticRegression(solver='lbfgs')` to blend models in an ensemble approach is a technique known as **stacking** or **stacked generalization**. The idea is to use a meta-model to learn how to best combine the predictions of several base models. Here's a detailed explanation of why this approach is used:\n","\n","## Why Use Logistic Regression for Blending:\n","1. **Combining Predictions**:\n","    * When we have multiple models, each providing their own predictions, the goal is to combine these predictions in a way that leverages the strengths of each model.\n","    * Logistic regression is a simple yet powerful algorithm that can learn the optimal weights for combining these predictions. It essentially learns weighted sum of the base model predictions to produce the final prediction.\n","\n","2. **Handling Probalistic Outputs**:\n","    * Logistic regression works well with probabilistic outputs, which is often the case in classfication problems. Each base model provides a probability distribution over the classes.\n","    * Logistic regression can take these probabilities as input features and learn how to combine them to maximize the accuracy of the final predictions.\n","\n","3. **Flexibility and Simplicity**:\n","    * Logisitic regression is relatively simple and computationally efficient, making it suitable for blending even when the number of base models is large.\n","    * It doesn't require extensive hyperparameter tuning compared to more complex models, which simplifies the stacking process.\n","\n","## Detailed Process in the Code:\n","1. **Create Base Models**:\n","```python\n","models = [\n","    build_ann(x.shape[1], 2, 20),\n","    KNeighborsClassifier(n_neighbors=3),\n","    RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n","    RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n","    ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n","    ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n","    GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50)\n","]\n","```\n","    * A list of diverse models is created, including neural networks and several ensemble classifiers.\n","\n","2. **Training Base Models and Collecting Predictions**:\n","```python\n","dataset_blend_train = np.zeros((x.shape[0], len(models)))\n","dataset_blend_test = np.zeros((x_submit.shape[0], len(models)))\n","```\n","    * Two arrays are initialized to store the predictions from each base model for both the training and submission datasets.\n","\n","3. **Cross-Validation and Blending**:\n","```python\n","for j, model in enumerate(models):\n","    ...\n","    for i, (train, test) in enumerate(folds):\n","        ...\n","        if isinstance(model, nn.Module):\n","            ...\n","        else:\n","            model.fit(x_train, y_train)\n","            pred = np.array(model.predict_proba(x_test))\n","            pred2 = np.array(model.predict_proba(x_submit))\n","            \n","        dataset_blend_train[test, j] = pred[:, 1]\n","        fold_sums[:, i] = pred2[:, 1]\n","        ...\n","    dataset_blend_test[:, j] = fold_sums.mean(1)\n","```\n","    * Each base model is trained using cross-validation.\n","    * Predictions for both training and submission datasets are stored in `dataset_blend_train` and `dataset_blend_test`.\n","\n","4. **Blending with Logistic Regression**:\n","```python\n","blend = LogisticRegression(solver='lbfgs')\n","blend.fit(dataset_blend_train, y)\n","return blend.predict_proba(dataset_blend_test)\n","```\n","    * Logistic regression is used as the meta-model to blend the predicitons from the base models.\n","    * It learns the optimal weights for combining the base model predictios to produce the final prediction.\n","\n","\n","## Intuition Behind Using Logistic Regression:\n","* **Ensemble Learning**: Combining the predicitons of multiple models generally leads to better performance than any individual model. Each model's errors tend to be uncorrelated, so the ensemble can average out these errors.\n","* **Weight Learning**: Logistic regression effectively learns the importance of each base model's predictions. It can assign higher weights to more accurate models and lower weights to less accurate ones.\n","* **Regulariztion**: The `lbfgs` solver includes regularizaion by default, which helps prevent overfitting when combining the predictions.\n","\n","\n","By using logistic regression to blend the outputs of multiple models, we leverage the strengths of each model, mitigate their individual weaknesses, and produce a more robust final prediction. This method of stacking with logistic regression is a practical and effective way to improve predictive performance."],"metadata":{"id":"b-fUoOvbUBFq"}},{"cell_type":"markdown","source":["## Difference between `Logistic Regression` and `Simple Average` of ensemble model\n","\n","The key difference between using Logistic Regression to blend ensemble model predicitons and simply calculating the mean of all predictions lies in the flexibility and learning capability of the two approaches:\n","\n","### 1. Logistic Regression for Blending:\n","Losistic Regression is a supervised learning algorithm that learns the optimal weights for combining predictions from different models. Here's how it works:\n","* **Learning Weights**:\n","    * Logistic Regression learns different weights for each model's predictions based on how well each model performs on the training data. Models that are more accurate will receive higher weights.\n","    * It effectively adjusts the contribution of each model's prediction to the final ensemble prediction.\n","\n","* **Handling Probabilities**:\n","    * It works well with probabilistic outputs (i.e., predicted probabilities from each model) and can learn the best way to combine these probabilities to minimize log loss or another suitable metric.\n","\n","* **Regularization**:\n","    * Logistic Regression can include regularization (like L1 or L2 regularization) to prevent overfitting, especially useful when there are many base models.\n","\n","### 2. Calculating the Mean of All Model Predictions:\n","Averaging predictions is a simpler approach where each model's prediction is given equal weight. Here's how it works:\n","* **Equal Weighting**:\n","    * Each model's prediction contributes equally to the final predicitons. No learning or adjustment of weights occurs based on model performance.\n","    * The final prediction is simply the average of all model predictions.\n","\n","* **Simplicity**:\n","    * This approach is straightforward an doesn't require a meta-model or additional training.\n","    * It's easy to implement and computationally less intensive since no additional learning step is involved.\n","\n","### Comparison:\n","**Felexibility and Adaptiveness**:\n","* **Logistic Regression**: Adapts to the strengths and weaknesses of individual models by learning weights based on their performance. This can lead to better overall performance as the ensemble can give more weight to more accurate models.\n","* **Mean Averaging**: Assumes all models are equally good, which might not be true in practice. It doesn't adapt to the varying performance levels of different models.\n","\n","**Handling Probabilities**:\n","* **Logistic Regression**: Can efffectively handle and combine probabilstic outputs from models, making it more suitable for tasks where probabilistic predicitons are crucial.\n","* **Mean Avraging**: simply averages the probabilities, which might not always lead to the optimal combination of predictions.\n","\n","**Overfitting and Regularization**:\n","* **Logistic Regression**: Can include regularization to prevent overfitting, making it robust, especially with many models or small datasets.\n","* **Mean Averaging**: Doesn't inherently include any mechanism to prevent overfitting. If some models overfit, their influence is not adjusted.\n","\n","\n","### When to Use Each Approach:\n","* **Logistic Regression**:\n","    * When you have a diverse set of models with varying performance.\n","    * When the task benefits from learning the optimal combination of model predictions.\n","    * When you need a more sophisticated and potentially more accurate ensemble method.\n","    * when you can afford the additional computational cost and complexity.\n","\n","* **Mean Average**:\n","    * When simplicity and ease of implementation are priorites.\n","    * When you have models of similar performance and want a quick way to ensemble them.\n","    * When computational resources are limited.\n","    * When you want a baseline ensemble method to compare against more complex methods.\n","\n","### Example to Illustrate:\n","Suppose we have three models with the following predicted probabilities for a binary classification problem (Class 1):\n","\n","| Sample | Model 1 | Model 2 | Model 3 |\n","|--------|---------|---------|---------|\n","| 1      | 0.7     | 0.8     | 0.6     |\n","| 2      | 0.4     | 0.5     | 0.3     |\n","| 3      | 0.9     | 0.7     | 0.8     |\n","\n","\n","**Mean Averaging:**\n","- For Sample 1: $$ (0.7 + 0.8 + 0.6) / 3 = 0.7\\ $$\n","- For Sample 2: $$ (0.4 + 0.5 + 0.3) / 3 = 0.4\\ $$\n","- For Sample 3: $$ (0.9 + 0.7 + 0.8) / 3 = 0.8\\ $$\n","\n","**Logistic Regression:**\n","- Logistic regression might learn weights **(e.g., 0.5, 0.3, 0.2)** based on model performance.\n","- For Sample 1: \\$$ 0.7 \\times 0.5 + 0.8 \\times 0.3 + 0.6 \\times 0.2) = 0.74\\ $$\n","- For Sample 2: $$ (0.4 \\times 0.5 + 0.5 \\times 0.3 + 0.3 \\times 0.2) = 0.43\\ $$\n","- For Sample 3: $$(0.9 \\times 0.5 + 0.7 \\times 0.3 + 0.8 \\times 0.2) = 0.81\\ $$\n","\n","\n","In summary, using Logistic Regression allows the ensemble to be more adaptive and potentially more accurate by learning the best combination of model predicitons, while meann averaging is a simpler and less adaptive approach.\n"],"metadata":{"id":"oZmYwSJKcf2O"}},{"cell_type":"code","source":[],"metadata":{"id":"cseoNOqAbLmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# How to Combine predictions of ensemble models for Regression\n","\n","When dealing with regression problems and using ensemble models, there are several ways to combine the predictions of all models. Here are some common ensemble methods for regression:\n","\n","### 1. Simple Averaging\n","\n","In simple averaging, the predictions from each model are given equal weight, and the final prediction is the mean of these predictions.\n","\n","**Formula:**\n","$$ \\hat{y} = \\frac{1}{M} \\sum_{m=1}^{M} \\hat{y}_m $$\n","\n","where $\\hat{y}_m$ is the prediction from the $m$-th model and $M$ is the total number of models.\n","\n","**Implementation:**\n","```python\n","import numpy as np\n","\n","predictions = [model1.predict(X_test), model2.predict(X_test), model3.predict(X_test)]\n","final_prediction = np.mean(predictions, axis=0)\n","```\n","\n","### 2. Weighted Averaging\n","\n","In weighted averaging, different models' predictions are given different weights based on their performance or importance. The final prediction is a weighted sum of the individual predictions.\n","\n","**Formula:**\n","$$ \\hat{y} = \\sum_{m=1}^{M} w_m \\hat{y}_m $$\n","\n","where $w_m$ is the weight assigned to the $m$-th model's prediction.\n","\n","**Implementation:**\n","```python\n","weights = [0.5, 0.3, 0.2]\n","predictions = [model1.predict(X_test), model2.predict(X_test), model3.predict(X_test)]\n","final_prediction = np.average(predictions, axis=0, weights=weights)\n","```\n","\n","### 3. Stacking\n","\n","Stacking involves using a meta-model to learn how to best combine the predictions of the base models. The predictions of the base models are used as input features to the meta-model.\n","\n","**Steps:**\n","1. Train each base model on the training data.\n","2. Use each base model to make predictions on the training and test data.\n","3. Use these predictions as features to train a meta-model on the training data predictions.\n","4. Use the meta-model to make the final prediction on the test data predictions.\n","\n","**Implementation:**\n","```python\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=5)\n","train_meta_features = np.zeros((X_train.shape[0], len(models)))\n","test_meta_features = np.zeros((X_test.shape[0], len(models)))\n","\n","for i, model in enumerate(models):\n","    for train_idx, valid_idx in kf.split(X_train):\n","        model.fit(X_train[train_idx], y_train[train_idx])\n","        train_meta_features[valid_idx, i] = model.predict(X_train[valid_idx])\n","    test_meta_features[:, i] = model.predict(X_test)\n","\n","meta_model = LinearRegression()\n","meta_model.fit(train_meta_features, y_train)\n","final_prediction = meta_model.predict(test_meta_features)\n","```\n","\n","### 4. Bagging (Bootstrap Aggregating)\n","\n","Bagging involves training multiple instances of the same model on different subsets of the data and averaging their predictions. Random Forest is a common example of bagging applied to decision trees.\n","\n","**Implementation:**\n","```python\n","from sklearn.ensemble import BaggingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","\n","model = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n","model.fit(X_train, y_train)\n","final_prediction = model.predict(X_test)\n","```\n","\n","### 5. Boosting\n","\n","Boosting involves training models sequentially, with each model focusing on correcting the errors of the previous one. The final prediction is a weighted sum of all model predictions. Gradient Boosting and AdaBoost are common examples.\n","\n","**Implementation:**\n","```python\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n","model.fit(X_train, y_train)\n","final_prediction = model.predict(X_test)\n","```\n","\n","### 6. Voting Regressor\n","\n","Voting regressor is a simple ensemble method where multiple different regressors are trained, and their predictions are averaged to produce the final prediction.\n","\n","**Implementation:**\n","```python\n","from sklearn.ensemble import VotingRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","\n","model1 = LinearRegression()\n","model2 = DecisionTreeRegressor()\n","\n","voting_regressor = VotingRegressor(estimators=[('lr', model1), ('dt', model2)])\n","voting_regressor.fit(X_train, y_train)\n","final_prediction = voting_regressor.predict(X_test)\n","```\n","\n","### Summary\n","\n","Each of these ensemble methods has its own strengths and weaknesses, and the choice of method often depends on the specific problem and dataset. Simple and weighted averaging are straightforward and easy to implement, while stacking and boosting can provide more powerful and accurate predictions at the cost of increased complexity and computation. Bagging, such as Random Forest, is effective for reducing variance, while boosting is effective for reducing bias. Voting regressor is a simple and effective method for combining different types of regressors."],"metadata":{"id":"MfQsbVcijmzj"}},{"cell_type":"markdown","source":["## How to select each way from above\n","\n","Certainly! Here's a guide on the best situations for using each ensemble method in regression problems:\n","\n","### 1. Simple Averaging\n","\n","**Best Situation:**\n","- **Homogeneous Models:** When you have multiple models of similar type and performance.\n","- **Quick Ensemble:** When you need a simple and quick way to combine predictions.\n","- **Baseline:** When you want to establish a baseline ensemble method before trying more complex approaches.\n","\n","**Example:**\n","You have trained several linear regression models with slightly different parameters or features, and they perform similarly. Averaging their predictions can give you a robust baseline.\n","\n","### 2. Weighted Averaging\n","\n","**Best Situation:**\n","- **Heterogeneous Models:** When you have models of different types or varying performance.\n","- **Performance-Based Weighting:** When you can assign weights based on model performance, such as cross-validation scores or validation set errors.\n","- **Expert Knowledge:** When you have domain knowledge to justify the weights assigned to different models.\n","\n","**Example:**\n","You have trained a linear regression, a decision tree, and a neural network, and you want to combine their predictions by giving more weight to the neural network due to its better performance on validation data.\n","\n","### 3. Stacking\n","\n","**Best Situation:**\n","- **Complex Relationships:** When you believe that a meta-model can learn complex relationships between the base model predictions.\n","- **Diverse Models:** When you have a diverse set of base models (e.g., linear models, tree-based models, and neural networks).\n","- **Adequate Data:** When you have enough data to train both the base models and the meta-model effectively.\n","\n","**Example:**\n","You have several models trained on different subsets or features of the data. You use their predictions as input to a meta-model, such as a linear regression or another machine learning algorithm, to learn the optimal combination of predictions.\n","\n","### 4. Bagging (Bootstrap Aggregating)\n","\n","**Best Situation:**\n","- **Reducing Variance:** When your base models (e.g., decision trees) are prone to overfitting and you want to reduce variance.\n","- **Homogeneous Models:** When you can use the same model type but want to improve stability and accuracy.\n","- **Parallel Training:** When you can train multiple models in parallel to save time.\n","\n","**Example:**\n","You are using decision trees, which are known to be high-variance models. Using a Bagging Regressor (e.g., Random Forest) helps reduce overfitting by averaging the predictions of many decision trees trained on different bootstrap samples of the data.\n","\n","### 5. Boosting\n","\n","**Best Situation:**\n","- **Reducing Bias:** When you need to improve a model that is high-bias and underfitting the data.\n","- **Sequential Learning:** When you can afford sequential training of models to focus on correcting errors of previous models.\n","- **High Performance Needs:** When you need high performance and can manage the increased computational cost.\n","\n","**Example:**\n","You have a weak base learner, such as a shallow decision tree, and you use boosting (e.g., Gradient Boosting or AdaBoost) to sequentially train multiple models, each focusing on the errors of the previous ones, to create a strong predictive model.\n","\n","### 6. Voting Regressor\n","\n","**Best Situation:**\n","- **Diverse Models:** When you have a set of different regressors and you want to combine their predictions.\n","- **Simplicity:** When you want a straightforward way to ensemble models without the complexity of training a meta-model.\n","- **Equal Contribution:** When you want to give equal importance to all models in the ensemble.\n","\n","**Example:**\n","You have trained a linear regression, a decision tree regressor, and a k-nearest neighbors regressor. Using a Voting Regressor, you combine their predictions by averaging them, leveraging the strengths of each model type.\n","\n","### Summary\n","\n","- **Simple Averaging:** Best for homogeneous models with similar performance, or as a quick baseline.\n","- **Weighted Averaging:** Ideal for heterogeneous models with varying performance, when you can assign meaningful weights.\n","- **Stacking:** Suitable for diverse models with potential complex relationships between their predictions, and when you have enough data.\n","- **Bagging:** Effective for reducing variance in high-variance models like decision trees, providing stability and accuracy.\n","- **Boosting:** Powerful for reducing bias in weak learners, improving performance through sequential error correction.\n","- **Voting Regressor:** Great for combining different types of regressors in a simple, straightforward manner, giving equal importance to all models.\n","\n","By understanding the strengths and best-use scenarios of each method, you can choose the most appropriate ensemble technique for your specific regression problem and dataset."],"metadata":{"id":"3Hy-vKBNkhUq"}},{"cell_type":"code","source":[],"metadata":{"id":"CqfEPaxKkB6T"},"execution_count":null,"outputs":[]}]}