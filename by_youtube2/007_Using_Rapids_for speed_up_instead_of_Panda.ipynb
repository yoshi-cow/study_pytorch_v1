{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmAnOaWkLbGs1Bta1V3Cl6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Using Rapids for speed up instead of Pandas\n","* https://www.youtube.com/watch?v=KgoXuhG_kfs&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi&index=21\n","* https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_04_5_rapids.ipynb\n","\n"],"metadata":{"id":"WKody5yposXR"}},{"cell_type":"markdown","source":["We' re going to explore the use of NVIDIA RAPIDS, a suite of softwear libraries and APIs which enables us to execute end-to-end data science and analytics pipelines entirely on GPUs. This powerful tool leverages the compute capabilities of GPUs to provide significant performance improvements over traditional CPU-based workflows. However, it's important to note that to use RAPIS effectively, a compatible GPU is necessary. As we progress, we suggest that you run the example provided in Google Colab. Google Colab is a free cloud service that supports GPU-based computation, and our example has been crafted to run optimally in this environment.\n","\n","<br>\n","\n","If you wish to utilize RAPIDS in a different environment, be aware that this requires some specialized installation steps. This might involve installing appropriate GPU drivers, configuring CUDA (a parallel computing platform and API by NVIDIA), and installing RAPIDS libraries. While it is entirely possible to set up RAPIDS in such environments, it does require a certain level of familiarity with system administration and is beyond the scope of this book. We encourage you to follow the latest installation guides provided on the official RAPIDS website if you choose this route.\n","\n","The following code installs RAPIDS into Google Colab."],"metadata":{"id":"nyIYuzUep0nZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggqym5wEoiUJ"},"outputs":[],"source":["!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/pip-install.py"]},{"cell_type":"markdown","source":["## Deep Learning and Tabular Data: Not Always a Perfect Match\n","While deep learning has brought transformative changes in numerous fields, such as image recognition, natural language processing, and even playing board games, it has sometimes fallen short when applied to tabular data, especially in comparison to traditional machine learning algorithms.\n","\n","It's important to understand that neural networks, the core of deep learning, are entirely capable of performing regression and classification tasks on tabular data. By applying various network architectures and tuning hyperparameters, you can certainly train a deep learning model on such datasets.\n","\n","However, in many instances, more traditional models, such as XGBoost, Random Forests, and other Gradient Boosted Machines (GBMs) often outperform deep learning models on purely tabular datasets. These traditional models have shown their efficiency in handling tabular data due to their ability to better capture certain kinds of relationships and dependencies between variables that neural networks sometimes miss.\n","\n","Real-world evidence of this trend can be found in the results of various Kaggle competitions. Kaggle, a platform for predictive modelling and analytics competitions, offers a wealth of data on machine learning model performance. Many winners of these competitions, particularly those focused on tabular data, frequently utilize GBMs. For instance, the XGBoost algorithm, a scalable and accurate implementation of gradient boosting machines, has been a part of numerous winning solutions.\n","\n","One reason for this is that tabular data often has structured and hierarchical relationships, and gradient boosting algorithms excel at capturing these interactions. On the other hand, deep learning models, particularly those without specific architecture designs, might struggle with such data unless provided with large amounts of training data and carefully selected features.\n","\n","This is not to say that deep learning should be disregarded when dealing with tabular data. Rather, it's important to understand the strengths and weaknesses of each approach. In some cases, combining deep learning with traditional methods can result in very powerful models. However, for most tabular datasets, the traditional models have proven to be more reliable, accurate, and computationally efficient.\n","\n","It's essential to remember that in machine learning, there is no \"one size fits all\" solution. The effectiveness of a model depends on the nature of the problem, the quality and quantity of the data, and the computational resources available. As practitioners, our role is to navigate this landscape and select or design the best models for our specific needs."],"metadata":{"id":"X4xZaQ0nrQjw"}},{"cell_type":"markdown","source":["## NVIDIA RAPIDS and Random Forests for Tabular Prediction\n","As we a completly GPU-based pipeline, we're going to adapt a previous PyTorch neural network example to make use of NVIDIA RAPIDS. While neural networks have their strengths, there are cases where traditional models like Random Forests can outperform them, especially when dealing with certain types of tabular data. In our case, we've found that for the dataset we're working with, a Random Forest model indeed surpasses the previously used neural network in performance.\n","\n","In this section, we'll guide you step-by-step on how to replace our neural network with a Random Forest, demonstrating the flexibility and versatility that RAPIDS offers when it comes to choosing and changing machine learning models.\n","\n","A highlight of this adaptation will be the use of RAPIDS' cudf library. This is a powerful GPU-accelerated data manipulation library that allows us to perform all necessary preprocessing of our dataset entirely within GPU memory. One of the significant advantages here is that we can directly hand off our processed data to the Random Forest model without leaving GPU memory, enhancing the efficiency of our data science pipeline.\n","\n","We'll demonstrate how to take full advantage of these RAPIDS features, optimizing our model's performance and speed. By the end of this section, you'll not only have a stronger understanding of how to adapt different machine learning models within RAPIDS but also have gained hands-on experience in leveraging GPU memory for efficient data processing and modeling. This code is demonstrated here."],"metadata":{"id":"_g2DOXbsrX_q"}},{"cell_type":"code","source":["import cudf as pd\n","from cuml import train_test_split\n","from cuml.ensemble import RandomForestRegressor\n","from cuml.metrics import mean_squared_error\n","from cuml.preprocessing import StandardScaler\n","\n","\n","# Read the data set\n","df = pd.read_csv(\n","    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n","    na_values=[\"NA\", \"?\"],\n",")\n","\n","# Generate dummies for job\n","df = pd.concat([df, pd.get_dummies(df[\"job\"], prefix=\"job\", dtype=int)], axis=1)\n","df.drop(\"job\", axis=1, inplace=True)\n","\n","# Generate dummies for area\n","df = pd.concat([df, pd.get_dummies(df[\"area\"], prefix=\"area\", dtype=int)], axis=1)\n","df.drop(\"area\", axis=1, inplace=True)\n","\n","# Generate dummies for product\n","df = pd.concat([df, pd.get_dummies(df[\"product\"], prefix=\"product\", dtype=int)], axis=1)\n","df.drop(\"product\", axis=1, inplace=True)\n","\n","# Missing values for income\n","med = df[\"income\"].median()\n","df[\"income\"] = df[\"income\"].fillna(med)\n","\n","# Standardize ranges\n","scaler = StandardScaler()\n","df[\"income\"] = scaler.fit_transform(df[\"income\"].to_frame())\n","df[\"aspect\"] = scaler.fit_transform(df[\"aspect\"].to_frame())\n","df[\"save_rate\"] = scaler.fit_transform(df[\"save_rate\"].to_frame())\n","df[\"subscriptions\"] = scaler.fit_transform(df[\"subscriptions\"].to_frame())\n","\n","# Convert to cuDF DataFrame\n","x_columns = df.columns.drop([\"age\", \"id\"])\n","x = df[x_columns]\n","y = df[\"age\"]\n","x = x.astype(\"float32\")\n","y = y.astype(\"float32\")\n","\n","# Set random seed for reproducibility\n","import numpy as np\n","\n","np.random.seed(42)\n","\n","# Split into training and test datasets\n","x_train, x_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.2, random_state=42\n",")\n","\n","# Train the model with RandomForestRegressor\n","model = RandomForestRegressor(n_estimators=500, random_state=42, n_streams=1)\n","model.fit(x_train, y_train)\n","\n","# Test the model\n","y_pred = model.predict(x_test)\n","\n","# Compute RMSE\n","score = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","print(f\"Final score (RMSE): {score}\")"],"metadata":{"id":"fkj-TZN_rWco"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explanation by GPT4\n","\n","It sounds like you're referring to RAPIDS, which is a suite of open-source software libraries and APIs built on CUDA, a parallel computing platform and programming model developed by NVIDIA. RAPIDS enables data science and analytics pipelines to run on GPUs, which can significantly accelerate processing speeds compared to traditional CPU-bound libraries like pandas.\n","\n","### What is RAPIDS?\n","\n","RAPIDS is mainly composed of several key components designed to work together seamlessly:\n","\n","1. **cuDF**: This is a GPU DataFrame library similar to pandas but designed to run on NVIDIA GPUs. It provides a pandas-like API, so it's easy to adopt by those familiar with pandas.\n","\n","2. **cuML**: This is a suite of machine learning libraries that mirror the Scikit-learn API but utilize GPUs for their computations, offering much faster processing speeds.\n","\n","3. **cuGraph**: This is for graph analytics, providing a networkx-like API but optimized to run on GPUs.\n","\n","4. **cuDNN**: Although part of the broader NVIDIA CUDA library set and not RAPIDS per se, cuDNN provides GPU-accelerated primitives for deep learning networks.\n","\n","### Using RAPIDS with PyTorch\n","\n","While RAPIDS and PyTorch can both utilize GPUs, they serve somewhat different purposes and their direct integration is limited to data handling and preprocessing aspects. Here’s how you can utilize RAPIDS alongside PyTorch:\n","\n","1. **Data Preprocessing with cuDF**: You can use cuDF to preprocess your data on the GPU. Once preprocessing is done, you can convert cuDF dataframes into PyTorch tensors.\n","\n","2. **Data Loading**: PyTorch’s `DataLoader` can be used to handle cuDF dataframes by converting them into tensors, enabling efficient data loading for model training.\n","\n","Here’s a simple example of using cuDF with PyTorch:\n","\n","```python\n","import cudf\n","import torch\n","\n","# Create a simple cuDF DataFrame\n","df = cudf.DataFrame({'a': range(10), 'b': range(10, 20)})\n","\n","# Convert cuDF DataFrame to PyTorch tensor\n","tensor = torch.tensor(df.as_matrix(), dtype=torch.float32)\n","\n","# Now you can use this tensor in PyTorch for training\n","```\n","\n","### Installation\n","\n","To use RAPIDS, you need a compatible NVIDIA GPU and you should install RAPIDS through the conda package manager, which simplifies the installation of the necessary CUDA dependencies:\n","\n","```bash\n","conda create -n rapids-0.19 -c rapidsai -c nvidia -c conda-forge \\\n","    rapids=0.19 python=3.8 cudatoolkit=11.0\n","conda activate rapids-0.19\n","```\n","\n","Replace `0.19` and `11.0` with the latest versions suitable for your GPU and system.\n","\n","### Note:\n","\n","Keep in mind that using RAPIDS requires a significant GPU memory, so it's mostly advantageous for large datasets where CPU processing becomes a bottleneck.\n","\n","If you have any specific scenarios or datasets in mind, I can help you set up a workflow using RAPIDS and PyTorch together."],"metadata":{"id":"4TWmL-5Yr-pp"}},{"cell_type":"markdown","source":["Currently, RAPIDS is only supported on Linux operating systems. This is primarily because RAPIDS relies heavily on NVIDIA's CUDA technology, which is best supported and most robust on Linux systems. Additionally, the data science and machine learning ecosystem on Linux is highly developed, making it the preferred platform for these kinds of technologies.\n","\n","If you're using a different operating system, such as Windows or macOS, and you want to leverage the power of RAPIDS, you might consider setting up a Linux-based virtual machine or using a cloud service that provides Linux environments with pre-installed RAPIDS, like Google Cloud Platform, Amazon Web Services, or Microsoft Azure.\n","\n","If you need guidance on setting up a Linux environment or any other help regarding RAPIDS, feel free to ask!"],"metadata":{"id":"jwiETnmrsNyA"}},{"cell_type":"code","source":[],"metadata":{"id":"iIApLKHasA6N"},"execution_count":null,"outputs":[]}]}